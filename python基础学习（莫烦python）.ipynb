{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python学习与实战"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：莫烦python、官方文档"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说明：本文是依据莫烦老师的系列课程与相关模块的官方文档整理的一份python学习教程，由于GitHub的国内访问不稳定，所以有些读者难以获得莫烦老师课程中的代码。本文将python基础、数据分析（pandas、numpy）、可视化（matplotlib）与数据采集（爬虫技术）系列课程中的常用部分的内容整理在本文中，供读者学习参考。由于本人才疏学浅，出错在所难免，不正之处请多包涵，欢迎各位读者批评指正。\n",
    "\n",
    "<p align=\"right\"> ——王海诺"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分：python基础学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.变量与运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在任何程序语言中，最基本的一项功能就是设置变量。 通过对变量的运算，来实现程序功能。所以我们这次也是从变量开始， 了解程序的基本使用方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 变化的量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所谓设置一个变量，也就是设置一个可以变化的量。变量简单理解，就是我们给一个东西的名字。 或者说是为了暂时在计算机中存储一个东西，我们给这个东西取了一个名字。比如如果我们要做文件管理系统， 那么这个系统得有一个名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"文件管理系统\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里的 name 是我们为这个变量设置的名字，而 文件管理系统 则是这个变量 name 中的取值。 除了用英文双引号标识的字符，在Python中，我们还可以用下面两种方式来标识字符串。 第一种是用英文的单引号。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2 = '文件管理系统'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二种是用三个引号（可单/双引）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "name3 = \"\"\"文件管理系统\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而这种三个引号的在文本量比较多的情况下有一个好处，就是可以书写跨行的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = \"\"\"\n",
    "这是一段长文本，\n",
    "有多长的，\n",
    "是真的很长。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你快去在编辑框里试试如果这里只用一个引号来写多行文本，会有什么问题？\n",
    "\n",
    "在定义多个变量的时候，我们还有一些快捷写法，比如下面这样，等号两边逐个写出变量的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name1, name2, name3 = \"文件\", \"系统\", \"管理\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者你想一次性定义多个相同取值的变量，有一个简单的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = name2 = name3 = \"文件系统\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 打印 Print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来为了方便展示，我引入一个你常会使用到的打印功能，print。使用它，你就能一次性打出很多不同的变量内容。我们后面的操作就好做一些。 同时我也展示一下 print 的几种用法。在后面字符串的教学当中我将展示更多有趣的玩法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "莫烦Python最棒~\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\project\\vscode_jupyter\\python基础学习（莫烦python）.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project/vscode_jupyter/python%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%8E%AB%E7%83%A6python%EF%BC%89.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m莫烦Python最棒~\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/project/vscode_jupyter/python%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%8E%AB%E7%83%A6python%EF%BC%89.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project/vscode_jupyter/python%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%8E%AB%E7%83%A6python%EF%BC%89.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m莫烦Python的\u001b[39m\u001b[39m\"\u001b[39m, name, \u001b[39m\"\u001b[39m\u001b[39m业界顶呱呱\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project/vscode_jupyter/python%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%8E%AB%E7%83%A6python%EF%BC%89.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m我看着\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m莫烦\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m的教学长大的~\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"莫烦Python最棒~\")\n",
    "print(name)\n",
    "print(\"莫烦Python的\", name, \"业界顶呱呱\")\n",
    "print(\"我看着\", \"莫烦\", \"的教学长大的~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 数学运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了文本数据，我们使用变量还可以记录多种多样的信息。比如数字和列表，字典。 这节我们主要还是讲讲数字和基于数字的基本运算。列表和字典我们留在后面慢慢来。 文件管理系统中，和数字有关的比如文件时间（我们会在后续的datetime详细讲解）， 或者是文件版本号，文件数等。这里我们用文件数来过一遍数学运算的知识。\n",
    "\n",
    "很简单，运用上面变量的知识，你只需要给这个数字一个名字，比如我的系统里有十个文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我系统里有 10 个文件\n"
     ]
    }
   ],
   "source": [
    "num_of_files = 10\n",
    "print(\"我系统里有\", num_of_files, \"个文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些文件我要分成5组，每组多少个呢？这就是除法了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_of_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m分五组，每组\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnum_of_files\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m个\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_of_files' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"分五组，每组\", num_of_files / 5, \"个\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，我给大家整理了我们常用的一些运算符，你可以在上面的编辑框中尝试其他几种，看看会出现什么结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|运算符       |描述          |例子        |\n",
    "| ----------- | ----------- | -----------|\n",
    "|+|加|\t3+4=7|\n",
    "|-|减|\t3-4=-1|\n",
    "|*|乘|  3*4=12|\n",
    "|/|除|\t3/2=1.5|\n",
    "|%|取余|\t103%100=3|\n",
    "|**|幂|\t3**2=9|\n",
    "|//|取整除|10//3=3|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，其实字符串也是可以加起来的哦~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"文件\" + \"系统\"\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然文字能加，那么文字能不能用减法呢？或者文字能不能加减一个数字呢？你可以自己试一试。\n",
    "\n",
    "对了，有些简便的运算写法，你也可以先掌握，毕竟会编程的人，都喜欢偷懒。<br> 下面这几种写法是我们常用的及时修改变量的简便写法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "a += 1\n",
    "print(\"a += \", a)\n",
    "a -= 1\n",
    "print(\"a -= \", a)\n",
    "a *= 10\n",
    "print(\"a *= \", a)\n",
    "a /= 2 \n",
    "print(\"a /= \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.条件判断"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "判断是人类日常就会做的事情。 同样，判断也是程序最基础的核心功能。有了判断，程序才会有执行的逻辑。 就好比在我们这个文件管理项目中，判断的场景也随处可见。比如如果文件在垃圾桶中，那么文件就可以被彻底删除等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 if 如果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if 很好理解，就是判断的基石，如果什么样就做什么。我们就用 if 来复现一下刚刚提到的文件系统里垃圾桶场景吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_trash = True\n",
    "if in_trash:\n",
    "    print(\"可以被彻底删除\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以尝试一下，把上面的in_trash = True改成in_trash = False，看看会有什么样的结果。 下面，我们在 in_trash 前面加上一个 not 来表示 in_trash 的反面，也就是不在垃圾桶里的意思。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_trash = True\n",
    "if not in_trash:\n",
    "    print(\"不可以被彻底删除\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，你可以再尝试一下，把上面的in_trash = False改成in_trash = True，看看会有什么样的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 if-else 如果否则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实，如果又要判断正面又要判断反面的情况，我们完全可以一次性搞定，比如下面使用 if-else 这种结构。 简单明了地就同时判断了正反面应该做的两件不同的事情。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_trash = True\n",
    "if in_trash:\n",
    "    print(\"可以被彻底删除\")\n",
    "else:\n",
    "    print(\"不可以被彻底删除\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 判断条件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实除了 True / False 还有很多其他的间接判断条件。比如下面列出来的这些判断标准"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|判断|含义|\n",
    "|---|---|\n",
    "|a == b|a 是否等于 b|\n",
    "|a > b|a 是否大于 b|\n",
    "|a >= b|a 是否大于等于 b|\n",
    "|a < b|a 是否小于 b|\n",
    "|a <= b|a 是否小于等于 b|\n",
    "|a != b|a 是否不等于 b|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果是文字的话，也可以比较是否等于/不等于哦，其它那些大于小于都是用于数值判断的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = \"文件1\", \"文件2\"\n",
    "print(a == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2 < 3\", 2 < 3)\n",
    "print(\"3 < 2\", 3 < 2)\n",
    "print(\"2 != 2\", 2 != 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你还可以在这里尝试大把其他的判断，这些判断都会返回一个 True 后 False 的结果。甚至，你还可以叠加不同的判断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2 < 3 and 2 < 5)\n",
    "print(2 > 3 or 3 == 3)\n",
    "print(2 > 3 or not 3 == 3 and 5 < 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我在下面再列一张表，来说明这些 and or not 的含义："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|判断|\t含义|\n",
    "|---|---|\n",
    "|True and True|\t需要两边同时满足才能返回 True|\n",
    "|True or False|\t只要一边是 True 则返回 True|\n",
    "|not True|\t给出相反结果|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了这些工具，拿到最终的那个 True / False 后，你就能再套用在 if-else 的结构里啦，将判断依据与判断后的流程联通在一起。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 1, 2\n",
    "if a > b:\n",
    "    print(\"a 大于 b\")\n",
    "else:\n",
    "    print(\"a 不大于 b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 if-elif-else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有比 if-else 更强大的结构。因为有时候我们还需要多判断一些情况，比如周一要干嘛，周二要干嘛，周三要干嘛等等，这并不是一个非黑即白的判断，而是多重判断连在一起的。 所以我们必然有更好的方式去判断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = 4\n",
    "if today == 1:\n",
    "    print(\"周一\")\n",
    "elif today == 2:\n",
    "    print(\"周二\")\n",
    "elif today == 3:\n",
    "    print(\"周三\")\n",
    "else:\n",
    "    print(\"周一周二周三之外的一天\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "快来尝试一下其它的判断吧。比如你要判断多个数值区间你该怎么写呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.for 和 while 循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在程序设计的时候，我们最常用到的一项功能就是循环了。 而且这也是为什么我们喜欢机器的一个原因。想想如果有一个人无怨无悔，一直在帮你做着一件重复的劳动， 如果这个是真人的话，我想这世界上应该也没人愿意这么干。\n",
    "\n",
    "只有机器才能将我们从这种重复的劳动中释放出来。今天我们从文件管理系统的角度， 看看有哪些东西是可以被循环解决的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 for 循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在程序设计中，不管你使用哪种语言，其中都有一个叫 for 的循环种类。当你想要逐个把你书包里的书拿出来， 逐个将新书写上你自己的名字，这一类的重复事项，都可以让 for 来帮你。 下面我们来看看如果在文件系统中，我们想为文件名批量递增序号，应该怎么办。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(\"新文件-\" + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想必当你试完以后，你也发现了，这个 range() 会一次次给你放出 0，1，2，3，4 这些数，如果是 range(10) 它就会放出从0到9的一共10个数。 这个 range(10) 当中的 10 也就是从0开始一直到10之前的10个数。其实你还可以像下面这么写。 range(2,5) 表示从2开始，一直到5之前的 2,3,4 3个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 5):\n",
    "    print(\"新文件-\" + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一种写法，可以让你跳着走，有时候不一定你想所有数都放出来，比如你想间隔几个在出一个数，你可以这么写。 range(3, 10, 2) 就表示了，从3开始，一直到10之前，每2次出一次数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 10, 2):\n",
    "    print(\"新文件-\" + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面当我们学到列表和字典的时候，还有更多的玩法。 而且后面我们也会介绍关于 for 循环的偷懒用法~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 While 循环"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和 for 循环一样，while 循环在程序设计中也占据了大半江山。和 for 循环的最大不同点我列在下面的表格中："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||特点|\n",
    "|---|---|\n",
    "|for|\t天然适合在有限的循环中|\n",
    "|while\t|可以被用在无限循环中|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实我想表达的意思是，如果你脑海中想到的是要处理一个一开始就有明确长度的序列，那么你第一个想到的应该是 for 循环。 如果你脑海中这个序列你不知道要在什么时候停，或者它是无限长的一个序列，或者运行无限次数，那你第一个想到的应该要用 while 循环。 while 循环可以用条件来限制他的循环次数。\n",
    "\n",
    "比如下面这个循环，我想猜一个数字（现在悄悄告诉你是20），当我猜的和这个数字不同的时候，我就往猜的数字上加一。 guess_num += 1 这个运算在前面讲过, 是用来做及时累加的功能。\n",
    "\n",
    "注意，如果你不小心触发了死循环，程序一直在运行，你只能强行停止程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_num = 10\n",
    "while guess_num != 20:\n",
    "    guess_num += 1\n",
    "    print(guess_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 continue 和 break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们尝试过了按照一个条件来终止循环，但是我们还有一些小技巧，让循环更加好用，写得读着会更加舒服。 比如将要介绍的 break，它最主要的目的就是为了个性化的终止当前循环。如果你有改过上面那个 while 循环的代码， 而且正好碰到了死循环的状态，你有可能会尝试这样写，用一个 count 来计数，统计尝试的次数，避免死循环的发生。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "guess_num = 30\n",
    "while guess_num != 20 and count <= 10:\n",
    "    guess_num -= 1\n",
    "    count += 1\n",
    "    print(guess_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么 break 也能救你于水火之中，及时停止循环，而且 break 这个词在我看来，自带终止的含义，就是用来处理危险状况的~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "guess_num = 10\n",
    "while guess_num != 20:\n",
    "    guess_num += 1\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "    print(guess_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 for 循环中，也是可以用 break 的。反正 break 和 continue 只要是个循环，他们就能管用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        break\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，我们已经介绍了这个紧急刹车器 break，那么我们再来介绍一下它的孪生兄弟 continue。现在你可以简单的理解成这样："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||比喻|\n",
    "|---|---|\n",
    "|break|\t紧急弹出|\n",
    "|continue|\t算了，我接着来|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        continue    # 跳过偶数\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continue 在我自己的实践中，我很常把它用在判断一个数据如果不能被处理的话，我就把它跳过，接着处理下一个数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.数据种类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们的目标是构建一个文件管理系统，想象一下，我们的文件应该如何管理呢？ 你需要给每一个文件都命名，把文件都统一放入一个文件夹中进行管理，不同文件夹可能存放着不同文件批次， 这样的管理是不是更有效呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 List 列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列表是我们最常用的一种存储数据机制。它就像一个抽屉一样，存放着各种信息，每一格都是一个存储单元，每一格都可以单独获取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"f1.txt\", \"f2.txt\", \"f3.txt\", \"f4.txt\", \"f5.txt\"]\n",
    "print(\"files[0] \", files[0])\n",
    "print(\"files[3] \", files[3])\n",
    "print(\"files[-1] \", files[-1])\n",
    "print(\"files[-3] \", files[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在列表中，既然你已经把东西按顺序存放到抽屉中了，那你就可以按照顺序拿到你存放的东西。 在Python中，我们将上面的数字号叫做 index 索引。现实中第1个位置的东西，在Python中，是第0位。 所以Python的第一个索引永远都是 0。 除了正着来取东西，我们完全也可以反着来取东西，第一个反着取的序号是 -1。以此类推，-3 这个索引就是倒着数第三个。\n",
    "\n",
    "而且在Python中，还很方便的可以一次性拿到多个抽屉的结果。比如下面我们就来演示一下取从多少位到多少位的东西。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"files[:3] \", files[:3])\n",
    "print(\"files[2:4] \", files[2:4])\n",
    "print(\"files[-3:] \", files[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里，我们才只讲了怎么选取抽屉中的东西，但是我的心情变得比天还快，无时无刻都想换抽屉的东西，比如抽屉里的衣服每天都有变动。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"old files[1] \", files[1])\n",
    "files[1] = 12\n",
    "print(\"new files[1] \", files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然我们还没讲，但是从这个运行结果不难看出，在列表中，你可以存放不同类型的元素，字符，数字，甚至列表里还能有列表。 所以这个抽屉还挺万能的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1, \"file\", [\"2\", 3.2]]\n",
    "print(l)\n",
    "l[2][0] = \"new string\"\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再一次，虽然我们还没讲，但是你看我在上面改动了一下这个列表中的列表元素，在选取信息的时候，我做了两次索引。这在列表中是能被支持的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Dict 字典"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有像抽屉的这种列表 List 真好，我们就能有组织地存放好以后会要用到的数据了，而且相比一个变量一个变量的存储，明显要高效很多。 但是你有没有发现一个问题，我在找抽屉的时候，经常会忘了我东西放在哪个抽屉。面对一排抽屉， 我只有一个个打开，检查，才知道要用的东西是不是放在这个抽屉中。\n",
    "\n",
    "没事，好在人类是聪明的，我们发明了标签，给你的抽屉贴上一个标签，这样下次再找的时候，立马就能根据标签找到正确抽屉的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种标签抽屉的定位，就是Python中字典 Dict 的意思了。而且有意思的是，字典除了用一个词来代表一个存放坑位，另外，这个坑位也是多样的， 从下面的例子中你可以看到，files 中，每个元素都有一个标签，或者 Key，对应着这个 Key，存放着他们的值 Value。\n",
    "\n",
    "这个字典中的 key 都是唯一的，如果你的抽屉出现了重名，我相信你应该也不知道到底是哪个抽屉放着想要找的东西吧。 而 value 是多样的，你可以放一个字符，一个数字，甚至一个列表，甚至是另一个字典。当你想要索引的时候，用 key 就能找到里面的内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\"ID\": 111, \"passport\": \"my passport\", \"books\": [1,2,3]}\n",
    "print(files)\n",
    "print(files[\"books\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "快去尝试一下，如果在索引的时候，索引到了一个不存在的 key（比如news），会发生什么情况呢？\n",
    "\n",
    "同列表，字典也是可以修改的，通过 key 我们就能将对应的 value 进行修改。 注意哦，在字典中的元素不像列表，字典元素是没有顺序的， 如果你想要有顺序，Python里的 OrderedDict 是你想要搜索的关键词，我在这个教程里就不讲了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[\"ID\"] = 222\n",
    "print(files)\n",
    "files[\"ID\"] = [2,3,4]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本个教程的结尾我们还能看到更多字典和列表功能的用法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Tuple 元组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看过了列表和字典，我们再来介绍一下元组 Tuple，元组从使用频率上来说，并没有字典列表用得频繁。为什么呢？最终原因是元组没有他们那么多样， 他的功能比较单一，基本上用元组的地方都能用列表代替。但是元组有它一个唯一的独特性，就是它里面的东西不可变，定下来就定下来了，不让你变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = (\"file1\", \"file2\", \"file3\")\n",
    "print(files[1])\n",
    "files[1] = \"file4\"   # 这里会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么情况下，我们才会喜欢用元组这种模式呢？答案也很简单，就是如果我们不希望它的值被改变的时候，比如有些常数，或固定值， 我们就希望它不能改变，特别是你的代码要给别人使用的时候，你没法控制，也不希望他们改变你的这些固定值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Set 合集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set更有意思，我们很常用在去重的时候，因为 set 里面只会存在非重复的元素，不管你往里面加了多少相同元素，这些相同元素都会坍缩成一个。 这种特性，我们就可以运用它来做交集并集等操作。注意哦，在集合中的元素，其实是没有顺序的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_files = set([\"file1\", \"file2\", \"file3\"])\n",
    "print(my_files)\n",
    "my_files.add(\"file3\")\n",
    "print(my_files)\n",
    "my_files.add(\"file4\")\n",
    "print(my_files)\n",
    "my_files.remove(\"file3\")\n",
    "print(my_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在初始化 set 的时候还有个更简便的写法，它和字典长得很像。下面我们初始化另一个以后，拿它做些交集并集的操作吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"my_files\", my_files)\n",
    "your_files = {\"file1\", \"file3\", \"file5\"}\n",
    "print(\"your_files\", your_files)\n",
    "print(\"交集 \", your_files.intersection(my_files))\n",
    "print(\"并集 \", your_files.union(my_files))\n",
    "print(\"补集 \", your_files.difference(my_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set 还有很多功能，我这里就不一一列举了，常用的是上面这些，如果你需要更详细的内容，就自己去搜索一下官方文档吧~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 在循环中运用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这些，特别是列表和字典，是经常和循环一起用的，毕竟如果要手写对每一个元素的加工，那是一件相当复杂的工作。所以我们可以在循环中批量处理。 注意，下面的 len(files) 给出的是这个 files 列表的长度，我们常用在循环中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"f1.txt\", \"f2.txt\", \"f3.txt\", \"f4.txt\", \"f5.txt\"]\n",
    "for i in range(len(files)):\n",
    "    if files[i] == \"f3.txt\":\n",
    "        print(\"I got f3.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实还能再简化一些，直接将 files 放入循环里。这样我们就不需要再去索引一遍 files 而是直接将 files 里面的值在 for 的时候就一一拿出来了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"f1.txt\", \"f2.txt\", \"f3.txt\", \"f4.txt\", \"f5.txt\"]\n",
    "for f in files:\n",
    "    if f == \"f3.txt\":\n",
    "        print(\"I got f3.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，字典也能和 for 进行简化的应用。我们只需要调用 dict.items(), dict.keys(), dict.values() 分别取字典的某些部分就能简化 for 循环了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\"ID\": 111, \"passport\": \"my passport\", \"books\": [1,2,3]}\n",
    "for key in files.keys():\n",
    "    print(\"key:\", key)\n",
    "\n",
    "for value in files.values():\n",
    "    print(\"value:\", value)\n",
    "\n",
    "for key, value in files.items():\n",
    "    print(\"key:\", key, \", value:\", value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 自带功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "列表和字典远远还没有结束哦，他们的功能其实挺丰富的。和 for 一起循环，我们来演示一下常用的一些列表，字典的功能函数吧。 第一个要介绍的是怎么往列表里面添加和pop值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for i in range(5):\n",
    "    files.append(\"f\"+str(i)+\".txt\") # 添加\n",
    "    print(\"has\", files)\n",
    "\n",
    "for i in range(len(files)):\n",
    "    print(\"pop\", files.pop())   # 从最后一个开始 pop 出\n",
    "    print(\"remain\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然还有很多，我们下面一一举一些比较常用的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"f1.txt\", \"f2.txt\"]\n",
    "\n",
    "# 扩充入另一个列表\n",
    "files.extend([\"f3.txt\", \"f4.txt\"])\n",
    "print(\"extend\", files)\n",
    "\n",
    "# 按位置添加\n",
    "files.insert(1, \"file5.txt\")     # 添加入第1位（首位是0哦）\n",
    "print(\"insert\", files)\n",
    "\n",
    "# 移除某索引\n",
    "del files[1]\n",
    "print(\"del\", files)\n",
    "\n",
    "# 移除某值 \n",
    "files.remove(\"f3.txt\")\n",
    "print(\"remove\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字典也是，也有额外的一些常用功能，比如get(), update()等，我下面再补充一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\"ID\": 111, \"passport\": \"my passport\", \"books\": [1,2,3]}\n",
    "\n",
    "# 按key拿取，并在拿取失败的时候给一个设定好的默认值\n",
    "print('files[\"ID\"]:', files[\"ID\"])\n",
    "print('files.get(\"ID\"):', files.get(\"unknown ID\", \"不存在这个 ID\"))\n",
    "\n",
    "# 将另一个字典补充到当前字典\n",
    "files.update({\"files\": [\"1\", \"2\"]})\n",
    "print('update:', files)\n",
    "\n",
    "# pop 调一个item，和列表的 pop 类似\n",
    "popped = files.pop(\"ID\")\n",
    "print('popped:', popped)\n",
    "print(\"remain:\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Function 函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程序编写中，我常会重复写一些功能，比如查询文件时间，查询文件名字等等， 如果每次做这些操作的时候，我都需要重新写一遍这些基础功能，岂不是十分费力？ 有没有办法将这些基础功能复用起来，后续我只需要引用到这个功能，多省事。 好在Python中就有这样的做事方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 定义函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个可以被复用的函数是第一步，想象我没有函数的时候，对多个文件名进行一种规则性修改的时候， 我可能这样做。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = \"f1\"\n",
    "f2 = \"f2\"\n",
    "\n",
    "f1 += \".txt\"\n",
    "f1 = \"my_\" + f1\n",
    "f2 += \".txt\"\n",
    "f2 = \"my_\" + f2\n",
    "print(f1, f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要修改的文件少还好，我写两行就搞定，万一这种操作变多，我得写到什么时候？ 要不我就定义一个功能帮我减轻负担吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_name(filename):\n",
    "    filename += \".txt\"\n",
    "    filename = \"my_\" + filename\n",
    "    print(filename)\n",
    "\n",
    "modify_name(\"f1\")\n",
    "modify_name(\"f2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个里面，我们还运用到了函数的输入参数，其实一个函数也可以没有输入参数的，比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func():\n",
    "    filename = \"f1\"\n",
    "    ext = \".txt\"\n",
    "    total_name = filename + ext\n",
    "    print(total_name)\n",
    "\n",
    "my_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果像上面这样的功能，我们还想拿出来函数处理的结果，其实也就是让函数可以 return 出来一个值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_name(filename):\n",
    "    filename += \".txt\"\n",
    "    filename = \"my_\" + filename\n",
    "    return filename\n",
    "\n",
    "new_filename = modify_name(\"f1\")\n",
    "print(new_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实在数学运算中，函数的概念还是很常见的，比如你想得到一个一元二次方程的值，传入x得到y。 你可以留意下我下面的传参过程，你在参数多的时候最好把参数名也写上，避免自己搞混了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, a, b, c):\n",
    "    return a*x**2 + b*x + c*1\n",
    "\n",
    "print(f(2, 1, 1, 0))    # 忽略参数名，按顺序传参\n",
    "print(f(x=2, a=1, b=1, c=0)) # 写上参数名，按名字传参\n",
    "print(f(a=1, c=0, x=2, b=1)) # 若用参数名，可以打乱顺序传参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，有些函数的参数并不是一直变化的，我们还可以设置一个参数默认值，节省写代码的时间和代码量。 如果设置了这些默认值，那在调用函数的时候就不一定要给这个参数赋值了。 如果没有设置默认值，每个参数都要传入才能成功调用，不信你试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, a=1, b=1, c=0):\n",
    "    return a*x**2 + b*x + c*1\n",
    "\n",
    "print(f(2, a=2))\n",
    "print(f(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 全局和局部变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说到了函数这一节了，有个东西不得不提一下，就是全局变量和局部变量的概念。 不仅仅是函数中会使用到这个概念，在后面介绍 类 class 的时候， 全局变量和局部变量也是一样的使用逻辑。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|变量|\t特点|\n",
    "|---|---|\n",
    "|全局 global|\t函数里外都能用 （公用）|\n",
    "|局部 local|\t仅在函数内有用 （私有）|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们举个例子, 下面这种方式是会报错的。原因很简单，在函数里的 filename 是 modify_name() 自己的变量， modify_name() 这个函数比较抠门，他不愿意借给大家公用这个 filename 变量。所以在外面，我们是找不到 filename 的， 你只能在 modify_name() 自己家里 使用这个 局部变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_name():\n",
    "    filename = \"f1.txt\"\n",
    "    print(\"local filename:\", filename)\n",
    "\n",
    "modify_name()\n",
    "print(\"global filename:\", filename) # 这里会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么如果这个 filename 是公用的，每一个函数都能获取到的，我们怎么定义呢？ 其实你就把 filename 拎出来，放到外面就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"f1.txt\"\n",
    "def modify_name():\n",
    "    print(\"local filename:\", filename)\n",
    "\n",
    "modify_name()\n",
    "print(\"global filename:\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于上面的代码，你尝试一下，在 modify_name() 里面去修改一下 filename 的值，重新赋值一下 filename 看看会发生什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"f1.txt\"\n",
    "def modify_name():\n",
    "    filename = \"f2.txt\"\n",
    "    print(\"local filename:\", filename)\n",
    "modify_name()\n",
    "print(\"global filename:\", filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么我在 modify_name() 里面修改了 filename，而且在里面打印出来时，它的确也被修改了， 但是在外面打印 filename 的时候却没有变化？哈哈，因为自私的 modify_name() 想自己在内部搞一套标准， 你外面有啥不要紧，如果我自己也搞一个一样的东西，那我就觉得自己这个更重要，就不看外面的东西了。所以local的filename就是 modify_name() 自己那一套。\n",
    "\n",
    "在反过来看外面的 filename，公用的 filename 也并不在乎你小灶里头在搞什么奇怪的操作，我只要保证我给大家提供的公用值都还是公用就好了。 所以在 global 的 filename 没有被 local 的改变。\n",
    "\n",
    "不过我们还存在另一种情况，就是允许内部来修改外部的值。为了办这件事，modify_name() 必须先向外面打一个申请报告，向外面申请自己要去修改公用的 filename。 怎么打申请呢？就是用到了下面这种方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"f1.txt\"\n",
    "def modify_name():\n",
    "    global filename  # 提出申请\n",
    "    filename = \"f2.txt\"\n",
    "    print(\"local filename:\", filename)\n",
    "modify_name()\n",
    "print(\"global filename:\", filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "global 和 local 在Python中也有一些比较有趣的使用方法，不过在初学阶段， 并不一定有太多用，你们留一个印象，以后在纠结global和local的时候再搜就好了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Class 类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实只要我们有了函数之后，作为一个程序语言，也不缺啥了， 那为什么还要搞一个 类Class 出来呢？永远记住，搞出这个东西来，永远都只有一个目的，就是让用语言觉得更省事， 更方便地处理一些具体问题。\n",
    "\n",
    "那是发什么，才让工程师想要发明 class 这种用法呢？答案也很简单， 就是工程师们想要在程序中描述具体的一个物体了。 比如一只猫有哪些特征，它能做哪些动作。 工程师想出了一个在代码中设置猫特征和动作的办法， 这就有了 class 类的概念。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 定义 class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人类是一个对人的大统称，人类就是一个类。同样，如果推演到我们这个文件管理系统的背景，文件就是一个大类， 每个具体文件就是这个类下面的个体（每个人是人类下的个体）。\n",
    "\n",
    "根据这样的逻辑，如果要生出来一个人，就得先有人类这个大概念，如果想创建一个文件，就要有文件这个大概念。 用 class File 来创建一个大概念（类），注意我们通常约定类的名字要首字母大写。 然后用 my_file = File() 来创建一个具体的文件。 每个具体的个体都带有这个类的基本属性，如 create_time, name。就像每个人都会有人类这个类当中的性别，年龄一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self):\n",
    "        self.name = \"f1\"\n",
    "        self.create_time = \"today\"\n",
    "\n",
    "my_file = File()\n",
    "print(my_file.name)\n",
    "print(my_file.create_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了对类的基本理解，我们再具体说明一下Python中定义类的做法。比如这个 self 是啥意思？ self 是作为类自己的一个索引，不管你在定义类的时候，想要获取这个类的什么属性或功能，都可以通过 self 来获取。 比如这个 File 类中，获取类自己的 create_time，就写成了 self.create_time。之后在说类的功能的时候， 也是通过 self 来在类内部调用的。\n",
    "\n",
    "而这里的__init__() 是什么呢？每当你进行一次 my_file = File() 这种操作的时候，把类给实例化的时候， File 类都会触发一次__init__ 功能，所以这是一个功能，用于初始化一些设置。\n",
    "\n",
    "有了这些属性，我们除了就能获取属性，也能修改属性的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file.name = \"new_name\"\n",
    "print(my_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 class 的功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面提到了，其实这个最基础的__init__也是类的一个功能，那么就可以像函数功能教学 那样当成真正的功能来使用。比如在__init__里加上传入参数。并且在初始化 File() 的时候传入你要__init__的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self, name, create_time=\"today\"):\n",
    "        self.name = name\n",
    "        self.create_time = create_time\n",
    "\n",
    "my_file = File(\"my_file\")\n",
    "print(my_file.name)\n",
    "print(my_file.create_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了__init__() 这个功能，当然你还可以定义更多的功能，想象一下，作为一个文件类，他还能做什么？ 比如重命名？上面我们已经通过直接修改实例的名字来重命名，现在我们发现其实重命名是文件操作的一种基本功能， 所以我们将重命名标准化成一个类的功能，让所有实例都能用上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self, name, create_time=\"today\"):\n",
    "        self.name = name\n",
    "        self.create_time = create_time\n",
    "    \n",
    "    def change_name(self, new_name):\n",
    "        self.name = new_name\n",
    "\n",
    "my_file = File(\"my_file\")\n",
    "# 调用实例中，类的功能\n",
    "my_file.change_name(\"new_name\") \n",
    "print(my_file.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，类的功能也是可以有返回值的，比如我想定义一个获取文件信息的功能。类的功能定义，相比普通的函数定义， 除了多出了一个 self，其他的并没有多大区别，所以你可以参考我讲函数的那一节来学习。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self, name, create_time=\"today\"):\n",
    "        self.name = name\n",
    "        self.create_time = create_time\n",
    "    \n",
    "    def get_info(self):\n",
    "        return self.name + \"is created at\" + self.create_time\n",
    "\n",
    "my_file = File(\"my_file\")\n",
    "print(my_file.get_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 继承"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想象你就是开发Python语言的工程师，想象关于类，还可以更加偷懒吗？ 比如我有定义文本文件和视频文件，如果分开定义两个类，我可以这样写："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video:\n",
    "    def __init__(self, name, window_size=(1080, 720)):\n",
    "        self.name = name\n",
    "        self.window_size = window_size\n",
    "        self.create_time = \"today\"\n",
    "\n",
    "class Text:\n",
    "    def __init__(self, name, language=\"zh-cn\"):\n",
    "        self.name = name\n",
    "        self.language = language\n",
    "        self.create_time = \"today\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不过你有没有发现，这两种文件，其实是有共性的，比如他们都有 name，说到这里，我突然意识到，其实他们还可以抽象出一个更底层的类， 也就是文件类。这个文件类包含了属于文件所具备的共同属性和功能。 我们可以通过继承的方式，将细分类嵌入到抽象类中，减少共有属性/功能的重复开发。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self, name, create_time=\"today\"):\n",
    "        self.name = name\n",
    "        self.create_time = create_time\n",
    "    \n",
    "    def get_info(self):\n",
    "        return self.name + \"is created at\" + self.create_time\n",
    "\n",
    "class Video(File):  # 继承了 File 的属性和功能\n",
    "    def __init__(self, name, window_size=(1080, 720)):\n",
    "        # 将共用属性的设置导入 File 父类\n",
    "        super().__init__(name=name, create_time=\"today\") \n",
    "        self.window_size = window_size\n",
    "\n",
    "class Text(File): # 继承了 File 的属性和功能\n",
    "    def __init__(self, name, language=\"zh-cn\"):\n",
    "        # 将共用属性的设置导入 File 父类\n",
    "        super().__init__(name=name, create_time=\"today\") \n",
    "        self.language = language\n",
    "    \n",
    "    # 也可以在子类里复用父类功能\n",
    "    def get_more_info(self):\n",
    "        return self.get_info() + \", using language of \" + self.language\n",
    "\n",
    "v = Video(\"my_video\")\n",
    "t = Text(\"my_text\")\n",
    "print(v.get_info())     # 调用父类的功能\n",
    "print(t.create_time)    # 调用父类的属性\n",
    "print(t.language)       # 调用自己的属性\n",
    "print(t.get_more_info()) # 调用自己加工父类的功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 私有属性和功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面这一点内容，其实初学者并不要求掌握，有上面的理解，其实对于你在日常生活中，自己流畅地使用类，已经足够了。 我在这里稍微介绍一下为什么要有这些私有的东西，用法什么的，我不觉得在初学的时候会留下多少印象， 所有之后你们要用的时候自己再搜关键词就好。\n",
    "\n",
    "我们先来看一下私有的用法吧，然后我再来对着介绍一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File:\n",
    "    def __init__(self):\n",
    "        self.name = \"f1\"\n",
    "        self.__deleted = False  # 我不让别人用这个变量\n",
    "        self._type = \"txt\"      # 我不想别人使用这个变量\n",
    "    \n",
    "    def delete(self):\n",
    "        self.__force_delete()\n",
    "    \n",
    "    def __force_delete(self):  # 我不让别人使用这个功能\n",
    "        self.__deleted = True\n",
    "        return True\n",
    "        \n",
    "    def _soft_delete(self):     # 我不想让别人使用这个功能\n",
    "        self.__force_delete()   # 我自己可以在内部随便调用\n",
    "        return True\n",
    "\n",
    "f = File()\n",
    "print(f._type)      # 可以拿到值，但是这个类的作者不想让你直接这样拿到\n",
    "print(f._soft_delete())  # 可以调用，但是这个类的作者不想让你直接调用\n",
    "\n",
    "# 接下来的两个实验都会报错\n",
    "# f.__deleted\n",
    "# f.__force_delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么会有上面的实验现象呢？其实这种私有属性的东西，通常是你为别人开发项目的时候才要考虑的。 有的属性或者功能，你不需要让别人知道，也不需要让别人调用，纯属自己开发时才会用到的一些东西， 所以就可以用私有化，强隐藏或者弱隐藏起来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|私有|\t特点|\n",
    "|---|---|\n",
    "|_ 一个下划线开头|\t弱隐藏 不想让别人用 （别人在必要情况下还是可以用的）|\n",
    "|__ 两个下划线开头|\t强隐藏 不让别人用|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 特殊方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你有可能会在其他Python教程中看到类的一些特殊方法，但是我还是上面那句话，对于初学者，这些特殊方法是不需要掌握的， 我在这里稍微介绍一下为什么要有这些特殊方法，以及比较常用的是哪些，之后你们已经是Python高手的时候，要用到它们的时候自己搜关键词就好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|定义|\t含义|\n",
    "|---|---|\n",
    "|def __init__()|\t初始化实例|\n",
    "|def __repr__()\t|字符串的“官方”表现形式|\n",
    "|def __str__()\t|字符串的“非正式”值|\n",
    "|def __iter__()|\t遍历某个序列|\n",
    "|def __next__()|\t从迭代器中获取下一个值|\n",
    "|...还有很多\t|...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Module 模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，如果你的工程在一个脚本文件中就能写完搞定，那么就不用搞module这种概念， module主要是为了一个相对比较大的工程，涉及到多个文件之间的互相调用关系。 如果一个文件写所有的代码可能成千上万行，阅读起来一点也不友善， 所以我们更长是将大项目的长代码拆开成多个模块，用文件夹和多文件的方式管理起来，方便后期维护。 这就有了 module 模块的程序代码管理方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 文件中的代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是我们的大背景，如果我们要设定一个文件管理系统，这个系统中肯定有很多功能，有文件查找，文件修改，权限管理等等。 每一个可以被分类的功能都可以被放在特定的一个组里。我们就从最简单的module说起。\n",
    "\n",
    "假设我写好了一些功能，这些功能可以被其他人使用。 我是直接给一段代码给别人使用呢，还是给一个Python文件？我还是喜欢给文件的，因为管你写了什么代码， 你给我个文件，我对你的代码就无感知，我只需要按照功能从你的文件中调取出来特定功能就好了。 比如有人给了我一份 file.py 文件。这个文件里有 create_name() 的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file.py \n",
    "\n",
    "def create_name():\n",
    "    return \"new_file.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为这个功能的使用者，我不关心你 create_name() 里面的代码是怎么实现的，我只关心我可以用 create_name() 这个功能就好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，在这个教学中，在你本地实验的话，需要在同目录下创建一个 file.py 文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 引用 module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "引用 module，我们通常也可以说成 引用库，引用包，引用代码 等。总之就是引用一份已经写好的代码。 创建好 file.py 后，相当于别人给了你一个可被调用的文件后，我们怎么引用呢？\n",
    "\n",
    "当然，我们得有自己的一个 .py 文件，我就假设自己的这个Python文件叫做 me.py 吧。 所以你可以在同目录下，创建一个 me.py 并把这面这段代码写在你的 me.py 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.py\n",
    "\n",
    "import file\n",
    "print(file.create_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你点运行，就会发现，它能打印出你在 file.py 里定义的那个 new_file.txt 名字，这就证明我们能成功引用之前写的功能了。 也就意味着，我们引用 file.py 这个文件的写法是 import file。 而调用 file.py 里的 create_name() 的写法是 file.create_name()。熟悉 Python Class 的同学可能会立马发现。 这里调用模块功能的时候和调用Python类功能更有异曲同工之处。甚至下面我们换一种方式，你会觉得更像了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.py\n",
    "\n",
    "import file as f1\n",
    "print(\"f1:\", f1.create_name())\n",
    "\n",
    "class File:\n",
    "    def create_name(self):\n",
    "        return \"new_file.txt\"\n",
    "\n",
    "f2 = File()\n",
    "print(\"f2:\", f2.create_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，这两种用法简直了！一模一样，当我给 file 重命名时， import file as f1，就和 f2 = File() 简直一模一样，他俩你目前可以想是等价的。 然后使用它们的 create_name() 功能呢的方式也一模一样。\n",
    "\n",
    "长得像不是没有原因的，因为module的设计真的可以和class一模一样，我们在后面会继续讲到。\n",
    "\n",
    "上面在写 import file as f1 无意间，我就透露了另一个知识点，你可以给模块重命名的。好，接下来我们再多说几种引用的方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.py\n",
    "\n",
    "from file import create_name\n",
    "print(create_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的 file.py 里面有多个函数，你也可以一起写在 import 里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.py\n",
    "\n",
    "from file import create_name, create_time\n",
    "print(create_name())\n",
    "print(create_time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果函数真的很多，而且你也不想一一写出来，你可以有两种方式来达成简化的目的，前一种已经介绍了，后一种是新的方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.py\n",
    "\n",
    "# 第一种，之前介绍了\n",
    "import file\n",
    "print(\"1\", file.create_name())\n",
    "\n",
    "# 第二种更偷懒\n",
    "from file import *\n",
    "print(\"2\", create_name())\n",
    "print(\"2\", create_time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 大项目的模块管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在稍微大点的项目中，随着代码量增加，代码管理起来越来越困难。很多时候我都不知道要去哪找代码。 所以优秀的代码框架，好的模块定义成了增加开发效率的关键。比如这个文件管理系统，我再做一个架构，搞一下功能分区。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面刚开始讲解的时候我们不是提了一嘴 module 和 class 很像嘛， 现在我们就来看看到底有多像。\n",
    "\n",
    "正规的 module 中，我们常会看到一个__init__.py 文件，这个文件其实就有点像 class 里的 def__init__(self), 你可以在里面写上要如何初始化你的 files 目录。也可以设定目录中个元素的关系。\n",
    "\n",
    "我在__init__.py 中写下了下面这段话，待会我们来演示一下这段话的作用。 注意，下面这段代码会报错的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files/__init__.py\n",
    "\n",
    "from .video import get_video_size # 点运行会报错的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置好__init__.py 后，我们就能直接从 files 里 import get_video_size 这个属于 video.py 的功能了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.py\n",
    "\n",
    "from files import get_video_size\n",
    "print(get_video_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是和 video.py 同级的 text.py 就无法通过这种 import 方式获取到 text.py 的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.py\n",
    "\n",
    "from files import create_name    # 这里会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们要获取到 text.py 的功能，我们得这样 import："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.py\n",
    "\n",
    "import files.text\n",
    "print(files.text.create_name())\n",
    "\n",
    "# 或者这样：\n",
    "from files import text\n",
    "print(text.create_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，更复杂的代码，有更复杂的结构，不过也都是一层层嵌套上面这样的做法。有了这些基础，我相信你遇到大项目的时候， 应该都能迎刃而解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.读写文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不光是在我们的文件系统中，在运行Python时，有很多情况是需要我们对文件进行操作的， 比如生成一个文件，用来记录一些信息，读取文件获取信息等等。 这一次我们就来讲解这个文件管理系统大项目当中，必定会存在的文件读写的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 创建文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步当然是凭空创建一个文件啦，下面是一个标准的创建文件步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"new_file.txt\", \"w\")   # 创建并打开\n",
    "f.write(\"some text...\")         # 在文件里写东西\n",
    "f.close()                       # 关闭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个文件会被保存在哪呢？正常来说，他会保存在你脚本的当前目录下，比如所你运行的是 me.py 脚本， 那么 new_file.txt 就会被创建在这个脚本的同级目录中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "|- me.py\n",
    "|- new_file.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你觉得要写一个 f.close() 或者有时候你怕自己忘记要 close(), Python 人性化地提供了另外一种打开文件的方式。 这个方式把打开和关闭嵌入到了一个 with 架构中。所以再也不用担心忘记关闭文件了，这种 with 的模式也是我个人比较喜欢的模式。 下面这个案例，除了使用了 with 模式，我还换了一种写入数据的方式 writelines(), 当你传入的时候像列表样的数据时， 列表中的每个元素就是一行记录，数据会分行来写。\n",
    "\n",
    "注意，在列表里，每个元素最后都最好写一个\\n来表示要另起一行。不然读出来的时候就黏在一起了。不信你试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_file2.txt\", \"w\") as f:\n",
    "    f.writelines([\"some text for file2...\\n\", \"2nd line\\n\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 读文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在目录中创建好了这个文件，我们肯定有需要读它的时候，在读文件的时候，和写文件的方式是十分类似的，就把里面的 w 改成 r。 也就是说，其实 w 代表的是 write， r 代表的是 read。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"new_file2.txt\", \"r\")\n",
    "print(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面有演示如果你的记录是一个列表，你想在文件中每行记录列表当中的一个值，可以用 writelines()，那么在读文件的时候， 也可以 readlines() 直接读出来一个列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_file2.txt\", \"r\") as f:\n",
    "    print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习和大数据的时代，我们的数据往往是非常大的，很多都是以GB为单位。而如果一次性读取一个这么大的文件，很有可能你的内存都放不下。 怎么办呢？我们能不能一行一行读取，取代一次性读取，不让内存被一次性占满？当然可以，readline() 就来拯救你了。 注意哦，这个功能没有 s，不是上一个功能哦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_file2.txt\", \"r\") as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        print(line)\n",
    "        if not line:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 文件编码，中文乱码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在做中文项目的时候，有一个很头疼的事情，很有可能你的文件是从不同平台拿过来的，比如 Windows 的文件要在 MacOS 里打开。 英文的还好，一般不会有什么问题，但是中文的就很容易出现编码不一的情况，出现中文乱码。这时候我们怎么办呢？ 首先你要弄清楚原文件的编码，通常来说是 utf-8、gbk、gb2312其中的某一种。\n",
    "\n",
    "下面我模拟一下，有些文件在 Windows 存储的时候，是以 gbk 的格式存储的，下面的 chinese.txt 我就模拟用 gbk 编码保存。 注意这里我选用的写模式 w 还多了一个 b，合起来是 wb，意思是 write binary 形式，取代默认的 text 形式。所以我读的时候， 也加上了一个 b，变成了 rb，read binary。你点运行试试，他会给你出一段乱码，因为Python不识别这段编码后的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chinese.txt\", \"wb\") as f:\n",
    "    f.write(\"这是中文的，this is Chinese\".encode(\"gbk\"))\n",
    "\n",
    "with open(\"chinese.txt\", \"rb\", ) as f:\n",
    "    print(f.read())\n",
    "    #print(f.read().decode('gbk'))  # windows在本机尝试，可以试试这个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那如果我直接用原始的 r 来读文本呢？它甚至都会给我报一个错。读不了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面的代码会报错\n",
    "with open(\"chinese.txt\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "怎么办？方法还是有的，我们先确认是哪一种文件编码，然后在读的时候，需要传入一个 encoding 的参数，表示用这一种编码来读。 这样中文乱码的问题就顺利解决了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"chinese.txt\", \"r\", encoding=\"gbk\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 更多读写模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们已经说了几种读写的 mode，比如 w, r, wb, rb。下面我们列一个表，来看看还有多少种不同模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|mode|\t意思|\n",
    "|---|---|\n",
    "|w\t|（创建）写文本|\n",
    "|r|\t读文本，文件不存在会报错|\n",
    "|a|\t在文本最后添加|\n",
    "|wb|\t写二进制 binary|\n",
    "|rb|\t读二进制 binary|\n",
    "|ab|\t添加二进制|\n",
    "|w+|\t又可以读又可以（创建）写|\n",
    "|r+|\t又可以读又可以写, 文件不存在会报错|\n",
    "|a+|\t可读写，在文本最后添加|\n",
    "|x\t|创建|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来举几个例子，体验一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_file.txt\", \"r\") as f:\n",
    "    print(f.read())\n",
    "with open(\"new_file.txt\", \"r+\") as f:\n",
    "    f.write(\"text has been replaced\")\n",
    "    f.seek(0)       # 将开始读的位置从写入的最后位置调到开头\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_file.txt\", \"a+\") as f:\n",
    "    print(f.read())\n",
    "    f.write(\"\\nadd new line\")\n",
    "    f.seek(0)       # 将开始读的位置从写入的最后位置调到开头\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.文件目录管理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Python中，你少不了会遇到读写文件，判断目录等问题。我们现在已经有了读写文件的基础。 现在我们玩点更高级的，用Python中提供的 os 库来做文件操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 os库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os库是Python自带的一个非常有用的模块。如果你做一个系统性的东西，要处理文件输出，读入等问题， 那么你有80%概率会使用到os库中的一些功能。 os模块有非常多功能，我们今天就来侧重将一些你日常会经常使用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 文件目录操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先你得知道你在哪？此话怎讲？我当然知道我在那，就在电脑面前做着不可描述的事。 NONONO，我指的是你的当前目录是在哪。当你运行一个程序的时候，通常而言当前目录就是你运行这个程序的目录。 那我们来找找在这个交互式学Python的环境中，你的当前目录是哪？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "print(\"当前目录：\", os.getcwd())\n",
    "print(\"当前目录里有什么：\", os.listdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了方面我们的后续操作，我还是单独创建一个文件夹，让我们在这个文件夹中做练习吧。 下面我会创建一个 project 的文件夹，后面这个 exist_ok 的意思是当我检测到这个目录存在， 我就睁一只眼闭一只眼，当没事发生，不然这句指令会报错的。 不信你试试，点三次执行，第一遍不填 exist_ok（默认为False）, 第二遍也不填（给你报错）， 第三次填 exist_ok=True，第三次就不报错了。而且在创建完之后，我们也可通过 os.path.exists(\"project\") 来检测是否真的存在这个东西。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"project\", exist_ok=True)\n",
    "print(os.path.exists(\"project\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你有没有发现，我们无意见又使用了 os 的一个子模块 path，这个子模块也是很有用的，后面我们会详细介绍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 文件管理系统"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来以文件管理系统里面会遇到的情况举例。比如用户注册了我这个系统，我得为这个用户创建一个他的文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"user/mofan\"):\n",
    "    print(\"user exist\")\n",
    "else:\n",
    "    os.makedirs(\"user/mofan\")\n",
    "    print(\"user created\")\n",
    "print(os.listdir(\"user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果用户注销了，我是不是得把它的文件夹删掉？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"user/mofan\"):\n",
    "    os.removedirs(\"user/mofan\")\n",
    "    print(\"user removed\")\n",
    "else:\n",
    "    print(\"user not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是情况越来越复杂，如果你的文件夹里有文件，不为空，就会报错的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"user/mofan\", exist_ok=True)\n",
    "with open(\"user/mofan/a.txt\", \"w\") as f:\n",
    "    f.write(\"nothing\")\n",
    "os.removedirs(\"user/mofan\")  # 这里会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这怎么办呢？把文件一个个删了？太费事了吧，其实这种事情，需要用到另一个库，名字叫做 shutil，但是你要注意的是， 这个库太强大了，如果你不小心删掉了其他东西，那就真没了，一定要小心！它可以清空整个目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"user/mofan\")\n",
    "print(os.listdir(\"user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随着你的文件系统越来越厉害，你得应付不同用户的不同需求，比如改名字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"user/mofan\", exist_ok=True)\n",
    "os.rename(\"user/mofan\", \"user/mofanpy\")\n",
    "print(os.listdir(\"user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 文件目录多种检验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了用户目录，还有很多事情是需要判断的，比如有没有某个文件呀，文件路径的一些便捷操作呀。 下面我先建一个文件，然后再对其进行一些鉴别。Python里的 os.path 真的也是非常容易接触到的一个内容。 光是判断这是否是一个文件或者是否是一个文件夹，都有很多种不同的判断方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"user/mofan\", exist_ok=True)\n",
    "with open(\"user/mofan/a.txt\", \"w\") as f:\n",
    "    f.write(\"nothing\")\n",
    "print(os.path.isfile(\"user/mofan/a.txt\")) # True\n",
    "print(os.path.exists(\"user/mofan/a.txt\")) # True\n",
    "print(os.path.isdir(\"user/mofan/a.txt\")) # False\n",
    "print(os.path.isdir(\"user/mofan\"))  # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在很多时候，我们的文件是通过传参传进来的，比如我随便告诉你一个文件目录，我想为这个文件创建一个副本，我就得用到三个功能，\n",
    "\n",
    "1.先拿到文件名 os.path.basename<br>\n",
    "2.再拿文件夹名 os.path.dirname<br>\n",
    "3.为副本重命名<br>\n",
    "4.把目录重新组合 os.path.join<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy(path):\n",
    "    filename = os.path.basename(path)   # 文件名\n",
    "    dir_name = os.path.dirname(path)    # 文件夹名\n",
    "    new_filename = \"new_\" + filename    # 新文件名\n",
    "    new_path = os.path.join(dir_name, new_filename) # 目录重组\n",
    "    shutil.copy2(path, new_path)   # 复制文件\n",
    "    return os.path.isfile(new_path), new_path\n",
    "\n",
    "copied, new_path = copy(\"user/mofan/a.txt\")\n",
    "if copied:\n",
    "    print(\"copied to:\", new_path)\n",
    "else:\n",
    "    print(\"copy failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者，还有个更方便的功能代替拿文件名和文件夹名的工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy(path):\n",
    "    dir_name, filename = os.path.split(path)\n",
    "    new_filename = \"new2_\" + filename    # 新文件名\n",
    "    new_path = os.path.join(dir_name, new_filename) # 目录重组\n",
    "    shutil.copy2(path, new_path)   # 复制文件\n",
    "    return os.path.isfile(new_path), new_path\n",
    "copied, new_path = copy(\"user/mofan/a.txt\")\n",
    "if copied:\n",
    "    print(\"copied to:\", new_path)\n",
    "else:\n",
    "    print(\"copy failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然 os 和 os.path 都还有非常多有关于文件和文件夹的操作，我只提到了比较重要和常用的内容。 今后如果你发现你的文件操作要经历更复杂的手法，你再去搜一搜，就更容易理解啦。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.字符串的高级玩法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "处理字符串很有意思的，一般的情况下，我们只需要打印出一段特定的话就好了， 但是还有些时候，这些话会应为场景的不同，方式的不同，参数的不同，里面的具体内容就会随之发生改变。 不管你是打印给自己看的，还是输出给别人看的，你都会使用这些方法。\n",
    "\n",
    "而下面介绍的这些方法就是能让你释放劳动力的功能，让你更关注与编程本身，而不是处理那些繁杂的字符。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 %百分号模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个应该会算是你接触到最多的一种形式，因为它在很久以前的 Python 版本中就存在了。 下面还有 format，f 字符串都是类似的功能，只是 Python 给你提供了多样化的方式达成类似的目的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"莫烦Python\"\n",
    "print(\"我的名字是\" + name + \"！\")\n",
    "print(\"我的名字是%s!\" % name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，同样是输出一个可配置的字符串，我们就见到了两种不同的方式。而上面第二种，相对而言就算比较简单的，因为当字符串里面要传入的参数变多的时候， 第一种方式将会很混乱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"莫烦Python\"\n",
    "age = 18\n",
    "gender = \"男\"\n",
    "print(\"我的名字是\" + name + \"！我\" + str(age) + \"岁了，我是\" + gender + \"的~\")\n",
    "print(\"我的名字是 %s !我 %d 岁了，我是 %s 的~\" % (name, age, gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们后面再说 % 后面那些标识符的含义，你现在就光看我们的模式，你觉得哪一种看起来比较舒服，比较好写呢？我认为是第二种，你还认为是第一种吗？ 要不你自己手打一遍，体验一下~\n",
    "\n",
    "而且当你要在这句话中塞入更多参数时，即使是第二种也有可能不太适合了，因为我都不记得他们的顺序是怎样的，我很容易就填错了。 那么能不能用字典一样的模式来填入数据呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"莫烦Python\"\n",
    "age = 18\n",
    "gender = \"男\"\n",
    "print(\"我的名字是 %(nm)s !我 %(age)d 岁了，我是 %(gd)s 的~\" % {\"nm\": name, \"age\":age, \"gd\":gender})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为用字典我就不用关心后面参数的顺序了，而且有的时候，我还可以重复利用字典里面的 key 做索引。\n",
    "\n",
    "好了，上面我还卖了个关子，没告诉你们这个 % 后面跟着的字母是什么意思，我现在在下面列了一些比较常用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|方式|\t意思|\n",
    "|---|---|\n",
    "|%d|\t整数|\n",
    "|%i\t|整数|\n",
    "|%f\t|小数|\n",
    "|%s\t|字符|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照这些，我来举几个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"莫烦Python\"\n",
    "age = 18\n",
    "height = 1.8\n",
    "print(\"我的名字是 %s !我 %d 岁了，我 %f 米高~\" % (name, age, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于字符和数字类型，如果你在数字类型（%d,%f）里输入的是字符，它就报错了，不信你试试。 但是你在字符类型（%s）里输入的是数字，它却没有问题，你也可以试试。神不神奇！\n",
    "\n",
    "还有一个比较常用的方式，就是当你使用小数的时候，你会发现 %f 可以打印出很长一串数字。有时候很占格子，我不喜欢，我可以让它短一点，输出固定长度的小数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%f\" % (1/3))\n",
    "print(\"%.2f\" % (1/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比较上面两种写法，如果你不需要看太多精度的话，你就浓缩一下就好，我觉得简约就是美。同样，下面还有四种对比， 让你看看我不光可以限制小数点后面的长度，也可以对小数点前面的长度做点手脚。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%f\" % (1/3))     # 后面不限制\n",
    "print(\"%.2f\" % (1/3))   # 后面限制 2 个位置\n",
    "print(\"%4d\" % (1/3))    # 前面补全最大 4 个位置\n",
    "print(\"%5d\" % 12)       # 前面补全最大 5 个位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 format功能更多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "format 的方法是在 % 百分号之后发明的，我一般都比较喜欢用这种方法，因为我觉得它更加 Python。为什么这么说呢？ 因为在我眼里，我会认为 format 更像是一个编辑字符串的功能，而非像百分号那样的固定搭配。 我们来对比一下 format 和百分号吧，他们能实现的功能差不多的。只是你可以按你的需求挑选一种你喜欢的方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"莫烦Python\"\n",
    "age = 18\n",
    "height = 1.8\n",
    "print(\"我的名字是 %s !我 %d 岁了，我 %f 米高~\" % (name, age, height))\n",
    "print(\"我的名字是 {} !我 {} 岁了，我 {} 米高~\".format(name, age, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从这里看出，简单的使用方式，就是我只用{}来占位，后面在 format 里按顺序放入值就好了，不用管这个值到底是什么类型。 其实除了这样的方式，format 还支持很多其他方式。比如我给 {} 里放一个数字，表示后面 format 里面的 index，这样我就能复用传入的值了。 这一招就比 百分号 模式要好一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"莫烦Python\"\n",
    "age = 18\n",
    "height = 1.8\n",
    "print(\"我的名字是 {0} !我 {1} 岁了，我 {2} 米高~我是{0}\".format(name, age, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了按照 index 来传字符，我们也可以用字典模式。只要我在 {} 传入一个 key 的名字就好。这样子也是可以复用参数的，方便很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"莫烦Python\"\n",
    "age = 18\n",
    "height = 1.8\n",
    "print(\"我的名字是 {nm} !我 {age} 岁了，我 {ht} 米高~我是{nm}\".format(nm=name, age=age, ht=height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，我么也是可以在做一些手脚，让它在显示小数或数字时，有更丰富的控制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"我 {:.3f} 米高\".format(1.12345))\n",
    "print(\"我 {ht:.1f} 米高\".format(ht=1.12345))\n",
    "print(\"我 {:3d} 米高\".format(1))\n",
    "print(\"我 {:3d} 米高\".format(21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对了，你迟早会遇到要在 {} 放入百分号的问题的，至少我在实际中，也遇到了要输入百分号的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"You scored {:%}\"\n",
    "print(txt.format(2.1234))\n",
    "\n",
    "txt = \"You scored {:.2%}\"\n",
    "print(txt.format(2.1234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我在下面这个表里列一下我觉得你可能会用到的。除了表里这些常用的，还有更多方式，你可以去查一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|方式\t|意思|\n",
    "|---|---|\n",
    "|:,\t|每 3 个 0 就用逗号隔开，比如 1,000|\n",
    "|:b\t|该数字的二进制|\n",
    "|:d\t|整数型|\n",
    "|:f\t|小数模式|\n",
    "|:%\t|百分比模式|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 f格式化字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个是 Python 3.6 之后引入的一个功能，如果你是其他语言转过来学 Python 的，你可能在其他语言中有遇到过这种形式的字符串处理模式。 这就比百分号%和 format 更加方便易用了。因为你写的字更少了，用有限的生命写出更多的 code~\n",
    "\n",
    "注意，在使用 f 模式的情况下，我们要在字符串开头加上一个 f。然后用 {} 圈出你的变量名，直接在 {} 引用变量。例子如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"莫烦Python\"\n",
    "age = 18\n",
    "height = 1.8\n",
    "print(f\"我的名字是 {name} !我 {age} 岁了，我 {height} 米高~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至你还可以在 {} 里做运算，比如下面这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"我 {age} 岁了，明年我就{age + 1}岁了~\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不仅仅是节省了代码量，它同样还是保留了一些特殊写法，包括限制字符长度等。做法都和 % 还有 format 类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 2.1234\n",
    "print(f\"You scored {score:.2%}\")\n",
    "print(f\"You scored {score:.3f}\")\n",
    "print(f\"You scored {12:5d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 修改字符串"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了让你多样化拼接字符串，比如用 %，format 或者 f 方式，我们还可以用一些字符串功能来处理文字的更多需求。\n",
    "\n",
    "这些我就在下面列一个表告诉你一些常用的吧，还有些不常用的，你也很容易从网上搜到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|方式|\t意思|\n",
    "|---|---|\n",
    "|strip|\t去除两端的空白符|\n",
    "|replace|\t替换字符|\n",
    "|lower\t|全部做小写处理|\n",
    "|upper\t|全部做大写处理|\n",
    "|title\t|仅开头的字母大写|\n",
    "|split\t|按要求分割|\n",
    "|join\t|按要求合并|\n",
    "|startswith\t|判断是否为某字段开头|\n",
    "|endswith\t|判断是否为某字段结尾|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我来介绍几个我觉得有必要介绍的，因为它很有趣。而且很多还可以和正则表达式配合着用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剔除前后空白"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"  我不想要前后的空白，但是  中间\\n的可以有\\n  \".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "替换文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"帮我替换掉莫烦\".replace(\"莫烦\", \"沫凡\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文字的大小写处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"How ABOUT lower CaSe?\".lower())\n",
    "print(\"And upper CaSe?\".upper())\n",
    "print(\"do tiTle For me\".title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "拆散你，重组你"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"你|帮|我|拆分|一下|这句话\".split(\"|\"))\n",
    "print(\"|\".join([\"你\",\"帮\", \"我\", \"重组\", \"一下\", \"这句话\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "街头巷尾遇见你"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"我在街头看到你\".startswith(\"我在\"))\n",
    "print(\"我在街头看到你\".startswith(\"街头\"))\n",
    "print(\"我在巷尾看到你\".endswith(\"看到你\"))\n",
    "print(\"我在巷尾看到你\".endswith(\"巷尾\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：字符串绝对不是单一的文字，它是有生命的~ 有很多有趣的方法可以丰富你的字符串表达，这里介绍的技术 %、format、f 模式，你肯定在使用Python某个阶段中会要用到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.Python的偷懒用法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Python 中，其实是有很多可以偷懒的方法的。原生的 Python 语言就自带了非常多小技巧，小实用方法。 我经常在日常写代码的时候用到它们。这可以节约我很多写代码的时间。还是回到最开始那一个课程介绍页的内容。 人生苦短，我用 Python 这句话，那既然我们抱着这个目的在学 Python，你势必要学会更加有效的方法，让你在苦短人生中， 比一般 Pythoner 更加出众。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 Lambda: 更直接的 Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Python 中，我们肯定会定义功能 Function，或者 method，无论你管它叫什么，它都是一个会执行你任务的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "print(add(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，即使是一个简单的 add 功能，我都要写一长串的固定格式才能把它当功能使用。 有没有更简单的方法？答案是肯定的。如果你发现你的情况是：\n",
    "\n",
    "1.我的功能很简单<br>\n",
    "2.调用次数不多（没那么正式的功能）<br>\n",
    "你就可以用 lambda 来写功能啦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add = lambda a, b: a+b\n",
    "print(add(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，我一行就能解决的事，为什么要写那么多行呢？不过 lambda 也不能滥用，一定要记得有这么个约定的前提条件。 它不是正式功能，你要临时使用的时候可以用，正式的功能，特别是你要为别人写功能的时候，你写在 lambda 里，大家不会把它当回事的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 一行for能解决的事，干嘛写那么多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你是否有这么一个时候：\n",
    "\n",
    "1.我想要出一个列表，<br>\n",
    "2.然后用 for 循环不断添加列表里的元素。<br>\n",
    "\n",
    "正常来说，我们通常要这样写，列表才会添加完毕。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(10):\n",
    "    l.append(i*2)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是这样写，对于我来说太麻烦了。不就是要按规律得到一个列表吗？我一行就可以解决呀。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i*2 for i in range(10)]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至，你还能那这种方法来创造字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"index\"+str(i): i*2 for i in range(10)}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是这种方法也是有适用场景的，如果你的列表/字典生成逻辑非常复杂，这种一行的 for 就太劳民伤财了，你会为其中的格式纠结死的。 所以这种列表/字典的生成方式只适合 for 内部只有比较简单的运算逻辑的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 可以一行判断，何必多行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里要说的是判断逻辑，那些简单的 if-else 判断，如果写成多行，有时候还挺费力的。比如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "if done:\n",
    "    a = 1\n",
    "else:\n",
    "    a = 2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你对比下面这种写法，你的生命负担是不是又减轻了~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = False\n",
    "a = 1 if done else 2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不过上面这种简写模式，也有一些经验上的偏爱条件。如果你的 if else 逻辑很复杂，比如里面还有 elif 这种逻辑，就不要用一行写。 一行只是为了减少你处理简单情况的时间。如果你在一行里面写了太多逻辑，阅读起来就很困难了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 一行for+判断也行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们刚刚说了 for 的超简写模式，和 if else 的简写模式，如果上天再给我一个恩惠，我想，它一定会把这两种模式整合起来， 让我的生命得到升华~这不它来了。\n",
    "\n",
    "在这种情况下，我们通常是处理一种特殊的列表/字典生成方式。\n",
    "\n",
    "1.我要用一行 for 生成一个列表/字典<br>\n",
    "2.对原始数据进行判断，符合要求的生成，不符合的抛弃<br>\n",
    "\n",
    "如果我们用原始的 for 来写这样的逻辑，将会是下面这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in range(10):\n",
    "    if i % 2 == 0:\n",
    "        l.append(i*2)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当你看到下面的写法的时候，将会豁然开朗~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i*2 for i in range(10) if i%2==0]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么字典行吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"index\"+str(i): i*2 for i in range(10) if i % 2 == 0}\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我的生命从此得到了升华~ Yeah。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.5 enumerate 自动加 index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候你肯定会苦恼，我想为在 for 里面记个数，到某个数的时候做点特殊处理。我的生命没有得到升华的时候，我肯定会这样写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "l = [11,22,33,44]\n",
    "for data in l:\n",
    "    if count == 2:\n",
    "        data += 11\n",
    "    l[count] = data\n",
    "    count += 1\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个 count 的存在是不是很费事？还要我手动去累加。要不试试 enumerate？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [11,22,33,44]\n",
    "for count, data in enumerate(l):\n",
    "    if count == 2:\n",
    "        data += 11\n",
    "    l[count] = data\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有更炫酷的，如果我自定义 count 还好，我可以初始化 count 到不同的数值。不急，这点小 case，enumerate 也能应付。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [11,22,33,44]\n",
    "d = {}\n",
    "for count, data in enumerate(l, start=5):\n",
    "    d[count] = data\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.6 Zip让你同时迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我要同时处理两个列表，一个是姓名一个是分数，并把它们做成一个字典，你会怎么做？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"a\", \"b\", \"c\"]\n",
    "score = [1,2,3]\n",
    "d = {}\n",
    "for i in range(3):\n",
    "    d[name[i]] = score[i]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种写法对于我来说，还是比较累赘的。怎么搞？直接上 zip。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"a\", \"b\", \"c\"]\n",
    "score = [1,2,3]\n",
    "d = {}\n",
    "for n, s in zip(name, score):\n",
    "    d[n]=s\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实这也就是在 d[n]=s 这一步得到了简化，但是你有没有想过，如果需要同时循环的东西变多了以后，情况就变得复杂很多。我们 zip 还是能简化写法的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = [\"a\", \"b\", \"c\"]\n",
    "score = [1,2,3]\n",
    "bonus = [1,0,1]\n",
    "d = {}\n",
    "for n, s, b in zip(name, score, bonus):\n",
    "    d[n]=s+b\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我看见了光~ 生命之光。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.7 reverse & reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "翻转列表？你会遇到吗？有时候还真有这种需求，比如页面上用户想要按时间正序排列，有时候想要按时间倒叙，这不就是一个最常见的场景吗？ 你怎么办？如果我用一些列表技巧，可能这样比较合适"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]\n",
    "_l = []\n",
    "for i in range(len(l)):\n",
    "    _l.append(l[-i-1])\n",
    "print(_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你学了今天的内容，上面我们不是提到了一种 for 的续命短模式吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]\n",
    "_l = [l[-i-1] for i in range(len(l))]\n",
    "print(_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这还不是最简单的，最简单的当然是 Python 自带的翻转功能呀。比如下面这三种种都可以。 第一种是自己就地反转。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]\n",
    "l.reverse()\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种是可以用在 for 循环里的翻转迭代器，你也可以试试不用在 for 循环中，它会返回什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]\n",
    "for i in reversed(l):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一种是要 copy 出一个浅拷贝副本的反转"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]\n",
    "_l = l[::-1]\n",
    "print(l)\n",
    "print(_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个反转都有这么多种不同的方式，真不愧是 Python。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结:有了这些 handly 的方法，我的秃头病也要治好了，用 Python 无时无刻都体现出生命之光的本色。印证了\"生命苦短，我用 Python \"这句话。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分：numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.numpy简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 为什么用numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择 Python 这门语言的确可以让你相对快速地上车数据分析和人工智能，而但靠裸 Python，它并不能支撑起这么多拥护者， 之所以 Python 被称为万能编程语言，正式因为它有很多实用，扎实的第三方库。而 Numpy 正是把 Python 捧上神坛的第三方库之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 使用numpy的情景"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.需要批量处理数据的时候<br>\n",
    "2.机器学习，人工智能这些需要进行海量数据运算处理的地方<br>\n",
    "3.写游戏里面的物体运行逻辑时，经常涉及到矩阵、向量运算<br>\n",
    "4.机器人模拟环境，背后的环境反馈信息，全是靠批量数据算出来的<br>\n",
    "5.任何需要做统计的时候（爬虫爬完了信息后）<br>\n",
    "6.画图表之前，要对数据做一轮批量处理<br>\n",
    "7.Blah blah<br>\n",
    "……"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 安装numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在terminal（终端）输入：（确保已安装python环境前提下）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者，如果你是 conda 来管理 Python 环境，你可以先创建一个 Python 环境，然后再装 numpy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 Python 环境，如果你已经有一个环境，就不用创建了\n",
    "conda create -n my-env\n",
    "conda active my-env\n",
    "\n",
    "# 在这个 my-env 的Python环境中安装 numpy\n",
    "conda install numpy\n",
    "\n",
    "# 或者直接用 pip 安装也能用\n",
    "pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 Numpy 和 Python List 的差别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Numpy 中，我们会一直使用到它的一种 Array 数据。这个 Array 的格式和形态多种多样，我们会在后续的教程中更详细的介绍。 现在，你只需要懂得如何 import numpy，并像下面这样定义一个 array 就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "了解 Python 原生 List 的朋友一定都知道，当你想要存储一些数据的时候， 你很可能想要用一个 list 来存储，并且可以按顺序提取出来。比如下面这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [1,2,3]\n",
    "print(my_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "存储和提取就是 List 的最基本用法和功能。而 Numpy Array 也能做这件事。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_array = np.array([1,2,3])\n",
    "print(my_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至对内部的一个值进行修改也是同样的逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list[0] = -1\n",
    "my_array[0] = -1\n",
    "print(my_list)\n",
    "print(my_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以这咋一看起来，Numpy Array 好像也没什么特别的呀，为什么这么多人都爱 Numpy 呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy的核心优势：运算快。用专业的语言描述的话，Numpy 喜欢用电脑内存中连续的一块物理地址存储数据，因为都是连号的嘛，找到前后的号，不用跑很远， 非常迅速。而 Python 的 List 并不是连续存储的，它的数据是分散在不同的物理空间，在批量计算的时候，连号的肯定比不连号的算起来更快。因为找他们的时间更少了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而且 Numpy Array 存储的数据格式也有限制，尽量都是同一种数据格式，这样也有利于批量的数据计算。 所以只要是处理大规模数据的批量计算，Numpy 肯定会比 Python 的原生 List 要快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()\n",
    "# python list\n",
    "l = list(range(100))\n",
    "for _ in range(10000):\n",
    "    for i in range(len(l)):\n",
    "        l[i] += 1\n",
    "\n",
    "t1 = time.time()\n",
    "# numpy array\n",
    "a = np.array(l)\n",
    "for _ in range(10000):\n",
    "    a += 1\n",
    "\n",
    "print(\"Python list spend {:.3f}s\".format(t1-t0))\n",
    "print(\"Numpy array spend {:.3f}s\".format(time.time()-t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：Numpy Array 和 Python List 在很多使用场景上是可以互换的，不过在大数据处理的场景下，而且你的数据类型又高度统一， 那么 Numpy 绝对是你不二的人选，能提升的运算速度也是杠杠的~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. numpy的维度选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy 为什么在 Python 的科学计算上优势明显？其中最主要的一个原因是 Numpy 可以处理多维数据， 而且 Numpy 底层的 C 让它在多维数据上计算也非常快。\n",
    "\n",
    "特别是在做机器学习，人工智能的时候，十有八九，人工智能的算法里面，就会出现多维数据的计算问题。可见多维数据在科学计算中的普遍性， 也可见 Numpy 真的是非常有价值的一个 Python 库。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 创建多维数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想象我们要维护一个车辆数据信息，每一个数据，代表的是一辆车的百公里加速时间，首先就是要创建一个车辆百公里加速的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cars = np.array([5, 10, 12, 6])\n",
    "print(\"数据：\", cars, \"\\n维度：\", cars.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你会发现，cars.ndim 会返回给你一个维度的属性，现在这组数据是一个一维数据。你可以认为这是某一次测试 4 款车收集到的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|测试批|\tcar1|\tcar2\t|car3|\tcar4|\n",
    "|---|---|---|---|---|\n",
    "|1|\t5|\t10|\t12|\t6|\n",
    "|2|\t5.1|\t8.2|\t11|\t6.3|\n",
    "|3|\t4.4\t|9.1|\t10\t|6.6|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看看，我们为了让结果更加准确，想着要多测几组数据，这就变成了一个二维数据了。在代码中，你可以这样一次性创建二维数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = np.array([\n",
    "[5, 10, 12, 6],\n",
    "[5.1, 8.2, 11, 6.3],\n",
    "[4.4, 9.1, 10, 6.6]\n",
    "])\n",
    "\n",
    "print(\"数据：\\n\", cars, \"\\n维度：\", cars.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然能创建二维数据，当然更高维度也不在话下啦，比如三维，可以表示，我在不同场地，多次测试不同测量，比二维数据多出来的一个维度就是不同场地这个维度了。 比如下面这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = np.array([\n",
    "[\n",
    "    [5, 10, 12, 6],\n",
    "    [5.1, 8.2, 11, 6.3],\n",
    "    [4.4, 9.1, 10, 6.6]\n",
    "],\n",
    "[\n",
    "    [6, 11, 13, 7],\n",
    "    [6.1, 9.2, 12, 7.3],\n",
    "    [5.4, 10.1, 11, 7.6]\n",
    "],\n",
    "])\n",
    "\n",
    "print(\"总维度：\", cars.ndim)\n",
    "print(\"场地 1 数据：\\n\", cars[0], \"\\n场地 1 维度：\", cars[0].ndim)\n",
    "print(\"场地 2 数据：\\n\", cars[1], \"\\n场地 2 维度：\", cars[1].ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "四位或更多维我就不打出来了，太麻烦了。你懂这个意思就行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 添加数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面创建了一个多维数据，但是我还会有很多新增数据的需求，比如在原数据的基础上，要新增一条，我总不能每次新增的时候，都创建一整个大数据吧，这样多麻烦。 还好，Numpy 有很多添加数据的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|测试批|\tcar1|\tcar2\t|car3\t|car4\t|car5|\tcar6|\n",
    "|---|---|---|---|---|---|---|\n",
    "|cars\t|5|\t10|\t12|\t6|\t5.2|\t4.2|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars1 = np.array([5, 10, 12, 6])\n",
    "cars2 = np.array([5.2, 4.2])\n",
    "cars = np.concatenate([cars1, cars2])\n",
    "print(cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种一维的数据很简单，也很好理解，就和 Python 中的 List 添加很像。但是如果数据换成了二维呢？我要添加一组测试数据呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|测试批|\tcar1|\tcar2|\tcar3|\tcar4|\n",
    "|---|---|---|---|---|\n",
    "|cars1\t|5\t|10\t|12\t|6|\n",
    "|cars2|\t5.1|\t8.2|\t11|\t6.3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = np.array([5, 10, 12, 6])\n",
    "test2 = np.array([5.1, 8.2, 11, 6.3])\n",
    "\n",
    "# 首先需要把它们都变成二维，下面这两种方法都可以加维度\n",
    "test1 = np.expand_dims(test1, 0)\n",
    "test2 = test2[np.newaxis, :]\n",
    "\n",
    "print(\"test1加维度后 \", test1)\n",
    "print(\"test2加维度后 \", test2)\n",
    "\n",
    "# 然后再在第一个维度上叠加\n",
    "all_tests = np.concatenate([test1, test2])\n",
    "print(\"括展后\\n\", all_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 合并数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有同学肯定会问了，你既然能在第一个维度上叠加，那你能不能在第二个维度上叠加呢？当然可以，只需要巧妙给 np.concatenate 一个参数就好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"第一维度叠加：\\n\", np.concatenate([all_tests, all_tests], axis=0))\n",
    "print(\"第二维度叠加：\\n\", np.concatenate([all_tests, all_tests], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里其实是一个 Numpy Array 合并的概念。只要维度能够对齐，你可以在任意维度上进行合并操作。注意，有些数据维度是对不齐的，这样没办法合并。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "[1,2,3],\n",
    "[4,5,6]\n",
    "])\n",
    "b = np.array([\n",
    "[7,8],\n",
    "[9,10]\n",
    "])\n",
    "\n",
    "print(np.concatenate([a,b], axis=1))  # 这个没问题\n",
    "# print(np.concatenate([a,b], axis=0))  # 这个会报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了 np.concatenate()，还有两个比较好用的在二维数据上可以方便调用的功能，分别是 np.vstack(), np.hstack()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "[1,2],\n",
    "[3,4]\n",
    "])\n",
    "b = np.array([\n",
    "[5,6],\n",
    "[7,8]\n",
    "])\n",
    "print(\"竖直合并\\n\", np.vstack([a, b]))\n",
    "print(\"水平合并\\n\", np.hstack([a, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 观察形态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了 np.ndim 来查看数据的形态，其实我们有时候还想更加了解数据的细节问题，比如这个数据的大小，规格。方便我们管理这些数据。\n",
    "\n",
    "比如当我想知道到底有多少车辆测试数据时，你可能会通过遍历的方法来计数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = np.array([\n",
    "[5, 10, 12, 6],\n",
    "[5.1, 8.2, 11, 6.3],\n",
    "[4.4, 9.1, 10, 6.6]\n",
    "])\n",
    "\n",
    "count = 0\n",
    "for i in range(len(cars)):\n",
    "    for j in range(len(cars[i])):\n",
    "        count += 1\n",
    "print(\"总共多少测试数据：\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看上面写的多麻烦。其实 Numpy 还有更好用的方式获取总个数。看看使用 cars.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"总共多少测试数据：\", cars.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更进一步，我不光想知道总数据，我还想知道当前有多少次测试（第一个维度，行），和在多少辆车上测试了（第二个维度，列）。怎么办？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"第一个维度：\", cars.shape[0])\n",
    "print(\"第二个维度：\", cars.shape[1])\n",
    "print(\"所有维度：\", cars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结:数据是多样的，有时候会跨越很多个维度。所以理解维度，理解形态对于科学计算中，数据的理解，都是十分重要的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.numpy的数据选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在海量的数据中，你如何挑选出符合你要求的数据呢？用肉眼一个个挑选筛选，别说上百亿的数据了，就算是一个上百的数据， 你都可能要挑个很久。Numpy 这时候就来拯救你了。不管是批量划分，还是按条件筛选，都能做到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.1 单个选取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实这里的单个选择，我想表达的意思是，单个单个的选择。下面的假设有三个同学，我要选其中的某个同学，就可以像 Python 中的 List 选择方法来选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "print(\"a[0]:\", a[0])\n",
    "print(\"a[1]:\", a[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然还有种方法，可以一次性选择多个，但实际上选择的逻辑还是一个个拎出来的逻辑。就像一个个从抽屉里拿出来的意思。后面我们还会介绍一批拿出来的概念（切片划分）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"a[[0,1]]:\\n\", a[[0,1]])\n",
    "print(\"a[[1,1,0]]:\\n\", a[[1,1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二维或者多维数据也可以用上面的方法来选择数据，一个个拎出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([\n",
    "[1,2,3,4],\n",
    "[5,6,7,8],\n",
    "[9,10,11,12]\n",
    "])\n",
    "\n",
    "# 选第 2 行所有数\n",
    "print(\"b[1]:\\n\", b[1])   \n",
    "\n",
    "# 选第 2 行，第 1 列的数\n",
    "print(\"b[1,0]:\\n\", b[1,0])   \n",
    "\n",
    "# 这个看着有点纠结，如果对应到数据，\n",
    "# 第一个拿的是数据位是 [1,2]\n",
    "# 第二个拿的是 [0,3]\n",
    "print(\"b[[1,0],[2,3]]:\\n\", \n",
    "b[[1,0],\n",
    "[2,3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总之，在上面的选取方式中，不管是几维数据，我们都可以在其不同维度上挑选那个维度上对应序号上的数值。而且还能一次从原数据上选取多个数据点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.2 切片划分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面已经介绍到了一个个拎出来数据的方式，基本上可以总结成，索引到具体的数上，就能拎出这个数具体的值。而有时候你会不会觉得特别麻烦， 如果我要在 100 个数中，从第一个一直找到第 50 个。我要写成这样 a[1,2,3,4....50]，这样太累赘了。Numpy 也考虑得非常周全，它有一个更取巧的方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "print(\"a[0:2]：\\n\", a[0:2])\n",
    "print(\"a[1:]：\\n\", a[1:])\n",
    "print(\"a[-2:]：\\n\", a[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 : 就能让你跨着取数字，而且一次取一批。注意，在 Numpy 中：一次取一批和一个个拎起来，拎了一批，是不同的概念哦 一次取一批来的更快， 因为它不用去一个个查看，一个个数了。\n",
    "\n",
    "在多维上，也可以进行切片划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([\n",
    "[1,2,3,4],\n",
    "[5,6,7,8],\n",
    "[9,10,11,12]\n",
    "])\n",
    "\n",
    "print(\"b[:2]:\\n\", b[:2])\n",
    "print(\"b[:2, :3]:\\n\", b[:2, :3])\n",
    "print(\"b[1:3, -2:]:\\n\", b[1:3, -2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14.3 条件筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面选择一部分数据的方式比较没有选择性。什么叫有选择性呢？其实就是按照一定的筛选逻辑进行过滤，留下那些在数值上符合条件的数据。 而上面的方式，只能从位置上选择。举个例子你可能比较明白一些。\n",
    "\n",
    "按位置选：请这队同学中，第 2 号到第 6 号的同学出列\n",
    "\n",
    "按数条件：请这队同学中，身高高于 1.5 米的同学出列\n",
    "\n",
    "两种方法不分好坏，区别在于你当前的使用场景。用合适的方法筛选数据就行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "[1,2,3,4],\n",
    "[5,6,7,8],\n",
    "[9,10,11,12]\n",
    "])\n",
    "\n",
    "print(a[a>7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面选取的是 a 数据中，大于 7 的数据。我们再拆开来看，a[a>7] 这里面究竟发生了什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = a > 7\n",
    "print(condition)\n",
    "\n",
    "print(a[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然 condition 是一种 True/False, 那么只要我们得到一个 True/False 数据，我都能做筛选。这才是它筛选的底层逻辑了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (a > 7) & (a != 10)\n",
    "print(a[condition])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了这种直接用[]的形式，在 Numpy 中，还有一个专用的函数来做数据筛选。这种筛选更强大，它还能做筛选结果的替换工作。 它可已将满足条件的位置变成你设定的数字。下面满足条件的，都改成 -1，不满足的，都还是 a 里面的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = a > 7\n",
    "print(np.where(condition, -1, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "或者，不仅是满足条件的 condition，不满足条件的，也能变成你期望的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = a > 7\n",
    "print(np.where(condition, -1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不光是数字哦，我还能让它和另外一个数据做条件上的整合哦，比如下面这样。如果满足 condition 要求，那么就会在对应的 True 位置放上 a 里的值，如果不满足 condition 要求，也就是在 condition 为 False 的地方放上 b 里对应位置的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = a > 7\n",
    "b = -a - 1\n",
    "print(np.where(condition, a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以 np.where() 函数真的十分强大，每每当我想要按条件选择、替换数据的时候，我脑海中，都是 np.where() 的身影。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：数据虽然有格式，但是如果要把数据用起来，还是得学会挑选和筛选。而今天介绍的单个、分段、条件筛选，都是数据工程师必备的一项技能。也是后续数据分析和机器学习的基石。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15.numpy的基础运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然 Numpy 是一个科学计算的模块，那么必定最牛逼的就是它的计算能力和多样的计算功能。 对于一个 Python 中数学运算的怪兽，Numpy 合理运用了 C 语言的能力，将 Python 的易用性和 C 的高效完美结合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.1 加减乘除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Numpy 中进行加减乘除可比 List 有效率多了，为什么这么说？Numpy 可以让在 Array 中的每一个元素都快速计算，甚至有时候还可以帮你自动并行运算。 比如你要为一个列表中的每个元素都加上一个值，比如收集了一批学生的身高，一年后，大家都长高了 3cm。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [150, 166, 183, 170]\n",
    "for i in range(len(l)):\n",
    "    l[i] += 3\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用列表你需要使用到一个循环，或者是一个map函数来帮你实现这个功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(map(lambda x: x+3, [150, 166, 183, 170])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看似 map 也挺试用的，不过一般来说，这个写法还是比较复杂的。如果我们用 Numpy 的方式来实现，怎么搞？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([150, 166, 183, 170])\n",
    "print(a + 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy 是可以批量进行计算的，只需要简单的 +-*/，就能进行全元素的运算，也就是向量化运算。同理，我们也可以进行其他符号的批量运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"a + 3:\", a + 3)\n",
    "print(\"a - 3:\", a - 3)\n",
    "print(\"a * 3:\", a * 3)\n",
    "print(\"a / 3:\", a / 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在科学运算，机器学习中。矩阵运算毋庸置疑十分重要， 我们在之后的小练习中也会着重体验到重要性。 下面我来介绍在机器学习中最常用的矩阵点积运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面可以看出，你有两种写法。1）直接用一个矩阵 dot 另一个；2）用 np.dot(a, b) 把两个矩阵包起来。 因为 莫烦Python 有很多 AI 的内容，所以我分享的时候，就偏向于往 AI 方向带啦，见谅啦。\n",
    "\n",
    "当然，矩阵还有很多其他的计算，比如 np.outer() 矩阵外积，np.inner() 矩阵内积 （和 np.dot() 的用法稍稍有些不同，你可以理解成 np.dot(a, b）= np.inner(a, b.T), 把 b 做一次转置）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2 数据统计分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 Numpy 做数据分析理所应当，但是如果数据的种类多样的话，我还是比较推荐用 Pandas 来做分析的，后面我们也会进入 Pandas 教学. 不过，就我个人经验，在数据量比较大的时候，我更喜欢直接 Numpy 来搞，因为 Numpy 的速度还是要比 Pandas 快上不少。\n",
    "\n",
    "那么什么是数据分析呢？其实也就是在数据中找到你想要的一些变量，总结数据的规律。最简单的当属找到最大值最小值了。 比如上面的身高数据，你想找全班最高和最矮的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([150, 166, 183, 170])\n",
    "print(\"最大：\", np.max(a))\n",
    "print(\"最小：\", a.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里也有两种方法可以获取到最大最小，只是不同的写法罢了，你习惯用哪个就用哪个好了。\n",
    "\n",
    "1.np.max(a), np.min(a)<br>\n",
    "2.a.max(), a.min()<br>\n",
    "\n",
    "当有一天，你有个躺尸的活动，要计算每个人躺下来头尾相连，有多长，我们怎么算？当然就是累加啦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一个，累乘的计算，这个我不好做比喻，但是你肯定能在生活中找到一些需要累乘的例子的。 我还想一同介绍的是一个计数的函数，这个用来统计总共有多少人。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([150, 166, 183, 170])\n",
    "print(\"累乘：\", a.prod())\n",
    "print(\"总数：\", a.size)   \n",
    "                 \n",
    "a = np.array([0, 1, 2, 3])\n",
    "print(\"非零总数：\", np.count_nonzero(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在统计学中，我们常会有两个概念，均值，中位数。算算你公司的平均工资是多少？不算不知道，一算吓一跳， 我们公司，因为有一个工资很高的人，平均工资是 4.82w，哈哈哈，我也被平均了。 但是这时候，为了更准确看到普通民众的薪资水平，最好还是用中位数（1.2w）更可靠。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_salary = [1.2, 20, 0.5, 0.3, 2.1]\n",
    "print(\"平均工资：\", np.mean(month_salary))\n",
    "print(\"工资中位数：\", np.median(month_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在统计数据分布的时候，还有一个值也比较重要，standard deviation 标准差，用来描述正态分布。 这个在机器学习中，特别是深度神经网络中也非常重要，特别用于权重的生成原则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_salary = [1.2, 20, 0.5, 0.3, 2.1]\n",
    "print(\"标准差：\", np.std(month_salary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3 特殊运算符号"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一些有的没的，时不时会用上的功能，我在这里给大家介绍 4 个，但是除了这 4 个，当你需要更多能力的时候， 建议你直接搜索对应的功能。现在给你看太多，多一段时间，你也很难回忆的起来。\n",
    "\n",
    "有的时候，其实你不关心 np.max() 或者 np.min() 的数值是多少，而是关心这个数值的序号， 比如还是那个身高的例子，我找到了最高身高，其实我是想对应上人的。用 np.argmax() 和 np.argmin() 就能搞定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([150, 166, 183, 170])\n",
    "name = [\"小米\", \"OPPO\", \"Huawei\", \"诺基亚\"]\n",
    "high_idx = np.argmax(a)\n",
    "low_idx = np.argmin(a)\n",
    "print(\"{} 最高\".format(name[high_idx]))\n",
    "print(\"{} 最矮\".format(name[low_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外一个时不时会用到的功能是，取天花板的值还是地板的值，这个在 AI 算法中也比较常见， 比如我要对其做取整处理，抹除小数部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([150.1, 166.4, 183.7, 170.8])\n",
    "print(\"ceil:\", np.ceil(a))\n",
    "print(\"floor:\", np.floor(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那我如果还有更自由的取值截取空间时咋办？我可以用 np.clip() 来做上下界限的值截取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([150.1, 166.4, 183.7, 170.8])\n",
    "print(\"clip:\", a.clip(160, 180))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结:其实 Numpy 中做数据运算的功能，比我这里列举的要多很多，我只是列举了一些我在数据分析和人工智能算法中，经常会使用到的一些功能。 还有更多的功能，可以在他的官方网站查找哦。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16.numpy改变数据形态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在 Array维度 的教学中，已经得知 Numpy 最核心的一种能力就是处理多维数据。 但是在那一节内容中，我们还没提到多维数据的一些处理方式。因为在数据分析，特别是机器学习中，数据的形态转变十分频繁。 今天我们就来看看如何做数据的变换吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.1 改变形态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "改变形态，其实是针对与多维度空间上的数据，要改变它的维度信息，和每个维度中的数据格式。所以第一点你就要清楚，如何添加维度。 其实在 多维数据教程中 中我们就提到过添加维度的方法，我这里在总结括展一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1,2,3,4,5,6])\n",
    "a_2d = a[np.newaxis, :]\n",
    "print(a.shape, a_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我再来讲讲，除了这种方式的其它几种，能达到同样效果的方式。比如用 None 或者 np.expand_dims(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "a_none = a[:, None]\n",
    "a_expand = np.expand_dims(a, axis=1)\n",
    "print(a_none.shape, a_expand.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了添加维度，我们还能减少维度，但是下面介绍的减少维度，只能减少那些维度 shape 上为 1 的维度。因为减掉这个维度，数据结构上是没有变化的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_squeeze = np.squeeze(a_expand)\n",
    "a_squeeze_axis = a_expand.squeeze(axis=1)\n",
    "print(a_squeeze.shape)\n",
    "print(a_squeeze_axis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述方法都是添加维度的方式，但是，在机器学习中，我们还有一个更常见的操作，是要改变 shape。维度的添加减少，只能添加减少一个维度，数据结构是不变的。 但是 np.reshape() 可以改变数据结构。 举个例子，a[None, :] 之后，a.shape 会在第一个维度上多一个 1，而 a.reshape([2,3]) 则可以更加自定义的将维度内的个数进行修改。 从而达到改变维度及尺寸。\n",
    "\n",
    "举个例子，学生军训的时候，我想让他们战队，可以站成一排，可以分几排站。其实学生都没有变化，只是战队的方式变了，这时候，reshape 就能帮我们干这件事。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5,6])\n",
    "a1 = a.reshape([2, 3])\n",
    "a2 = a.reshape([3,1,2])\n",
    "print(\"a1 shape:\", a1.shape)\n",
    "print(a1)\n",
    "print(\"a2 shape:\", a2.shape)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实还有更过的改变形态的方法，比如让数据变直、展平 的 np.ravel(), np.flatten()，这两个比较特殊， 我会在 对速度有洁癖 这节的时候详细说明。\n",
    "\n",
    "而在矩阵运算的时候，也有一种形态的转化，叫做矩阵转置，np.transpose(), 在机器学习中也用得很多。这里提一下， 给一个小案例，你们玩玩试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5,6]).reshape([2, 3])\n",
    "aT1 = a.T\n",
    "aT2 = np.transpose(a)\n",
    "\n",
    "print(aT1)\n",
    "print(aT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.2 合并"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在介绍多维数组的时候， 我们也稍微介绍了一下如何添加和并数组。现在我们再详细把数组的合并拆解都细说一下。\n",
    "\n",
    "一般来说，在数据分析统计，机器学习中的数据，都是以二维来存储的。行是数据样本（第一维度），列是特征（第二维度）。 所以我们可以组合特征和组合样本。 比如将列column合并，特征 a 的数据和特征 b 的数据合并。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_a = np.array([1,2,3,4,5,6])\n",
    "feature_b = np.array([11,22,33,44,55,66])\n",
    "c_stack = np.column_stack([feature_a, feature_b])\n",
    "print(c_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "条条的数据 sample 合并。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_a = np.array([0, 1.1])\n",
    "sample_b = np.array([1, 2.2])\n",
    "c_stack = np.row_stack([sample_a, sample_b])\n",
    "print(c_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的两种方法 np.column_stack() 和 np.row_stack() 和后面的 np.vstack()、np.hstack() 相比， 有些特殊之处，我们先看看使用 vstack 和 hstack 的案例，再说说不同处吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_a = np.array([1,2,3,4,5,6])[:, None]\n",
    "feature_b = np.array([11,22,33,44,55,66])[:, None]\n",
    "c_stack = np.hstack([feature_a, feature_b])\n",
    "print(c_stack)\n",
    "\n",
    "sample_a = np.array([0, 1.1])[None, :]\n",
    "sample_b = np.array([1, 2.2])[None, :]\n",
    "c_stack = np.vstack([sample_a, sample_b])\n",
    "print(c_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到了吗？用 column_stack 和 row_stack() 的时候，Numpy 自动帮你处理的维度信息，而用 vstack 和 hstack 的时候，你需要先确保维度信息是正确的，然后再合并。\n",
    "\n",
    "有时候，你想要用统一的方法来处理各种不同情况的合并，np.concatenate() 是我最喜欢的方法，管它什么 vstack hstack 甚至是在更高维度上要合并， 我们都可以用 concatenate() 一个功能实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "[1,2],\n",
    "[3,4]\n",
    "])\n",
    "b = np.array([\n",
    "[5,6],\n",
    "[7,8]\n",
    "])\n",
    "\n",
    "print(np.concatenate([a, b], axis=0))\n",
    "print(np.concatenate([a, b], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16.3 拆解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，能横着，竖着合并，那也能横着竖着拆解。np.vsplit() 和 np.hsplit() 就是干这事的。 如果直接在 indices_or_sections 后填入数字，就是要整分的段数， 而如果接着的是一个列表，那就按照列表中的 index 来取区间。可以看看下面代码注解中的意思。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(\n",
    "[[ 1, 11, 2, 22],\n",
    " [ 3, 33, 4, 44],\n",
    " [ 5, 55, 6, 66],\n",
    " [ 7, 77, 8, 88]]\n",
    ")\n",
    "print(np.vsplit(a, indices_or_sections=2))  # 分成两段\n",
    "print(np.vsplit(a, indices_or_sections=[2,3]))  # 分片成 [:2]，[2:3], [3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.vsplit 是拿着刀沿着横向切分，那么 np.hsplit 就是沿纵向切分，我就不再举例了。那么有没有既能横切也能纵切的函数呢？ 当然有呀，和 stack 一样，如果直接用 np.split() 你就能选择要切分的维度来自定义切分了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(\n",
    "[[ 1, 11, 2, 22],\n",
    " [ 3, 33, 4, 44],\n",
    " [ 5, 55, 6, 66],\n",
    " [ 7, 77, 8, 88]]\n",
    ")\n",
    "print(np.split(a, indices_or_sections=2, axis=0))  # 分成两段\n",
    "print(np.split(a, indices_or_sections=[2,3], axis=1))  # 在第二维度，分片成 [:2]，[2:3]，[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：形态变化和合并拆解都是十分有用的功能，我们介绍了很多种实用的方法来完成这些事， 而懂了这些之后，你的数据分析和机器学习才算是真正迈入入圈的第一步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.关于numpy的其他介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节的内容初学不用记忆，只是要明白numpy有这些功能，需要用的时候查询资料即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1 读取和保存数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 Numpy 来直接读取数据（通常是纯数值形式的数据），并加以运算，有以下几个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载常用数据格式\n",
    "np.loadtxt(), np.fromstring()\n",
    "# 保存数据\n",
    "np.savetxt()\n",
    "np.save(), np.savez(), np.savez_compressed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.1.1 加载常用数据格式（txt,csv）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们就模拟你经常要加载的情况，从文件中加载出来。这是你可以选择用纯 Python 的方式一行一行读出来，然后保存到 List 当中。 但也可以直接用 numpy 的方式读取出来。使用 np.loadtxt() 功能，我们就能自定义地读取出来数据啦。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.loadtxt(\"read-save-data/data.csv\", delimiter=\",\", skiprows=1, dtype=np.int64)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如在 loadtxt 的参数中，我们传入 , 让 numpy 在做数据分隔的时候，以逗号作为分隔符。同时 skiprow skip 掉第一行描述文字 （其实不设置这个的话，它好像也会自动帮你 skip），还有读取出来的数据要放到 dtype=np.int64 类型的 array 中。 你看一行功能，就能轻松读取出来这 csv 的数据了。\n",
    "\n",
    "注意，np.loadtxt() 为什么不叫 np.loadcsv() 呢？因为 csv 数据也是纯文本数据，我还存了一个 read-save-data/data.txt 文件，你在上面再试试， 看能不能用 np.loadtxt() 加载 read-save-data/data.txt?\n",
    "\n",
    "上面就是最普通的一种加载数据方式。下面我们来看一种更有趣的加载过程。我能不能直接从字符中加载数据呢？\n",
    "\n",
    "有时候，我需要对字符串加工处理后，然后直接读这个加工后的字符串。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_string = \"20131, 10, 67, 20132, 11, 88, 20133, 12, 98, 20134, 8, 100, 20135, 9, 75, 20136, 12, 78\"\n",
    "data = np.fromstring(row_string, dtype=np.int64, sep=\",\")\n",
    "data = data.reshape(6, 3)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，这种方法目前应该是只能读取一个数值序列，读完这个序列后，你可以再用 Numpy 的方法给他 reshape 成你想要的样子。另外要注意的，对比 np.loadtxt(delimiter=\",\") 和 np.fromstring(sep=\",\") 这两个用来判断分隔符的参数，它们的参数命名是不一样的。\n",
    "\n",
    "有同学会问了，上面只讲了 csv 和 txt 格式的数据，那 Numpy 能读 Excel 中的 xlsx 数据格式吗？答案是不能！ 但是未来我们会讲 Pandas 库的教学，这个库就能读 xlsx 数据格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.1.2 保存数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看了几种日常生活中经常会碰到的数据格式，都能用 Numpy 读，那么读完之后，或者处理完数据之后，我想保存起来，怎么办呢？ 还在 Numpy 还是挺人性化的，也有丰富的方法来处理保存数据这件事。\n",
    "\n",
    "Numpy 存数据，存哪种数据格式，取决于你想不想这份数据被人查看，或者被其他语言编辑，如果想的话，你就会保存成一些通用的数据格式，比如 csv 或 txt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numpy data:\\n\", data)\n",
    "np.savetxt(\"read-save-data/save_data.csv\", data, delimiter=\",\", fmt='%s')\n",
    "\n",
    "print(\"data file in directory:\", os.listdir(\"read-save-data\"))\n",
    "with open(\"read-save-data/save_data.csv\", \"r\") as f:\n",
    "    print(\"\\n\", f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一些 Numpy 独有的模式，那就是用二进制的格式保存。如果你没有想让别人看你的数据，你只想自己使用 Numpy 时加载的话，那你完全就可以用这种方式存储下来。 注意，使用 np.save() 来保存，保存的是一个以 .npy 结尾的二进制文件。加载的时候，我们能用 np.load() 直接加载这个二进制数据文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"read-save-data/save_data.npy\", data)\n",
    "\n",
    "print(\"data file in directory:\", os.listdir(\"read-save-data\"))\n",
    "npy_data = np.load(\"read-save-data/save_data.npy\")\n",
    "print(npy_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一个更神奇的保存方式，我们可以在一个 numpy 文件中保存多个 numpy array。有时候，你是分开多个 array 来存放不同类型的数据，比如机器学习中的 traindata 和 testdata。这时我们能用 np.savez() 保存一个 .npz 文件将这两个 array 同时存储好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array([1,2,3])\n",
    "test_data = np.array([11,22,33])\n",
    "\n",
    "np.savez(\"read-save-data/save_data.npz\", train=train_data, test=test_data)\n",
    "print(\"data file in directory:\", os.listdir(\"read-save-data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.savez() 第二、三个参数名 train=xx, test=xx 其实是可以自定义的，这些参数名会作为之后我们加载回来的索引标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_data = np.load(\"read-save-data/save_data.npz\")\n",
    "print(\"train:\", npz_data[\"train\"])\n",
    "print(\"test:\", npz_data[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 np.savez() 的时候，还有一个方法可以让你更节省空间，那就是用 np.savez_compressed() 来做一次数据压缩。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(\"read-save-data/save_data_compressed.npz\", train=train_data, test=test_data)\n",
    "print(\"data file in directory:\", os.listdir(\"read-save-data\"))\n",
    "\n",
    "npz_data_compressed = np.load(\"read-save-data/save_data_compressed.npz\")\n",
    "print(\"train:\", npz_data_compressed[\"train\"])\n",
    "print(\"test:\", npz_data_compressed[\"test\"])\n",
    "\n",
    "import os\n",
    "print(\"compressed file size:\", os.path.getsize(\"read-save-data/save_data_compressed.npz\"))\n",
    "print(\"original file size:\", os.path.getsize(\"read-save-data/save_data.npz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.2 标准数据生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据是多变的，不光是数据的形态多变，里面的数值也是多变的。通常，我们在创建一个 Numpy Array 的时候， 是想带着一些数值来初始化的，比如我想先要一个全零的 Array。\n",
    "\n",
    "所以这节内容，主要是完成带着数值初始化，带着怎样的数值初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建统一数据\n",
    "np.zeros(), np.ones(), np.full()\n",
    "np.zeros_like(), np.ones_like(), np.full_like()\n",
    "# 创建规则数据\n",
    "np.arange(), np.linspace()\n",
    "# 快速创建再添加值\n",
    "np.empty(), np.empty_like()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.2.1 创建统一数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先来点简单的，初始化 Array 的时候，让他们全部都为某数。最简单的就是全 0 或者全 1 的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "zeros = np.zeros([2, 3])\n",
    "print(\"zeros:\\n\", zeros)\n",
    "\n",
    "ones = np.ones([3, 2])\n",
    "print(\"\\nones:\\n\", ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你会发现，创建这些数据时，我们不光光可以给定要创建的具体数值是 0 还是 1，而且还能指定这个数据的 shape 是什么。 创建出来后，你就可以把它当成普通的 Array 数据使用就好了，要 reshape, transpose, 还是 sum 等操作，都是可以进行的。不信你就在上面的代码框试试。\n",
    "\n",
    "我们可以创建 0 或 1 的数据，那我们能不能创建其它数值的数据的？答案是肯定的，用 np.full() 功能就好了。 同样，我们先输入这份数据的 shape，然后指定这份数据要全是什么数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nines = np.full([2,3], 9)\n",
    "print(nines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在处理 shape 的时候，有件有趣的事。如果我们手头已经有一份数据，我们想创建一个和它类型一样，大小一样的另一份数据， 我们可以调用 np.xxx_like 这种形式的功能。看看下面这个例子，你就明白我的意思了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "[1,2,3],\n",
    "[4,5,6]\n",
    "], dtype=np.int64)\n",
    "\n",
    "ones = np.ones(data.shape, dtype=data.dtype)\n",
    "ones_like = np.ones_like(data)\n",
    "\n",
    "print(\"ones:\", ones.shape, ones.dtype)\n",
    "print(\"ones_like:\", ones_like.shape, ones_like.dtype)\n",
    "print(\"ones_like value:\\n\", ones_like)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为 dtype 和 shape 都和源数据一样，那么它们俩之间做加减乘除运算就很契合了。 从上面的案例看出，其实 ones_like 其实算是一种偷懒功能，少写一些字而已。\n",
    "\n",
    "同理，我们还有 np.zeros_like() 和 np.full_like() 这两种。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.zeros_like(data))\n",
    "print(np.full_like(data, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.2.2 创建规则数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而创建有些规律的数据也是 Numpy 的拿手好戏。首先我要说一个最常见的，arange 功能，这就有点像 Python 里的 range 功能，用来得到一个序列，我举个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"python range:\", list(range(5)))\n",
    "print(\"numpy arange:\", np.arange(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样，np.arange() 也可以像 range() 一样，对范围做自定义更变或跳跃取值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (start, end, step) \n",
    "print(\"python range:\", list(range(3, 10, 2)))\n",
    "print(\"numpy arange:\", np.arange(3, 10, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一个也是用来取一段数字中的值，这个我也比较常用，特别是在画折线图的时候，我想要连续在一个区间内取间隔一致的数据点。 里面的参数分别代表从 start 的值到 end 的值，一共返回这中间 num 个数据点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (start, end, num)\n",
    "print(\"linspace:\", np.linspace(-1, 1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更厉害的是，有时候我们会很纠结，上面是在-1 至 1 之间分了 4 个区域。 而我们想在-1 至 1 之间分 5 个区域，怎么搞？加一个 endpoint=False 就可以返回这 5 个区域的结节点了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"5 segments:\", np.linspace(-1, 1, 5, endpoint=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有很多做特殊规则的数据的方式，比如 np.identity(), np.eye(), np.logspace() 等等， 这个教学我先介绍一些常用的，当你有需要的时候，你再单个搜索就行了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.2.3 快速创建再添加值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和 np.ones() 这种很相似的，有一个叫 np.empty() 功能，我想单独拎出来介绍一下。 如果你对运算速度有要求，你就得仔细听一下。\n",
    "\n",
    "np.empty() 功能，不会初始化新建 array 里面的数值，所以你会看到这里面的数值都是乱乱的。 注意，虽然乱乱的，但是它不是随机数哦，你不能把它当随机数使用。 想用随机数的话，我后面有单独一个教学讲随机数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.empty([4,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那又不能当随机数，又没有具体数值，这个 empty 到底为什么存在呢？\n",
    "\n",
    "1.首先，可以当成一个 placeholder，一个容器先放着，之后慢慢放数据<br>\n",
    "2.创建起来比 ones, zeros, full 都快一点点\n",
    "\n",
    "所以在这种情况下，我们才想使用 np.empty()。我们来对比一下创建速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "for _ in range(1000):\n",
    "    _ = np.ones([100, 100])\n",
    "\n",
    "t1 = time.time()\n",
    "for _ in range(1000):\n",
    "    _ = np.empty([100, 100])\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"ones time:\", t1 - t0)\n",
    "print(\"empty time:\", t2 - t1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我这里的结果是：还是可以快了几倍的速度。看完速度，我给你看看我一般是怎么使用的吧："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "empty = np.empty([2,3])\n",
    "print(\"empty before:\\n\", empty)\n",
    "data = np.arange(6).reshape([2, 3])\n",
    "for i in range(data.shape[0]):\n",
    "    for j in range(data.shape[1]):\n",
    "        empty[i, j] = data[i, j] * random.random()\n",
    "print(\"empty after:\\n\", empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以一般当我有一个数据要根据另一份数据生成的时候，无论我初始化是什么值，到最终都要全部被替换的时候，我就喜欢用 np.empty()。 ok，最后说一句，有 np.empty()，我们也有 np.empty_like() 用法和 np.zeros_like() 这种类似，很方便用的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.3 随机数和随机操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你不光可以利用 Numpy 来创建很多种不同的随机数，还能对数据做随机化处理，甚至还能当上帝，控制计算机的随机过程（seed）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多种随机数生成\n",
    "np.random.rand(), np.random.random()\n",
    "np.random.randn(), np.random.randint()\n",
    "# 给你施加随机\n",
    "np.random.choice()\n",
    "np.random.shuffle(), np.random.permutation()\n",
    "# 随机分布\n",
    "np.random.normal(), np.random.uniform()\n",
    "# 随机种子的重要性\n",
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.3.1 多种随机数生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提到随机，首先我们想到的当然是生成一批随机数，对这批随机数做计算啦。在深度学习中，这是一件非常重要的事，比如你常会随机生成神经网络的权重，生成遗传算法中的基因序列等等。\n",
    "\n",
    "假设现在没有 Numpy，我们当然也能用 Python 自带的 random 来解决，但是效率会低不少。 用 Python 自带的 random，大概是怎么用的呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "print(random.random())\n",
    "print(random.randint(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 的 random 没有考虑数组类型的高效数据结构，所以我们在 array 类型的数据结构时，更喜欢直接用 Numpy 来生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成 [0, 1) 之间的数\n",
    "dim1, dim2 = 3, 2\n",
    "print(np.random.rand(dim1, dim2)) # 你还能继续添加 dim3 或更多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.rand() 是一种最方便去生成带 shape 的 [0, 1) 之间取值的 Array。实现同一个目的的还有这样一种写法，功能上没差别，但是就是看你个人习惯了， np.random.random() 用它就是直接传一个 shape 进去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.random([dim1, dim2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那除了生成 [0, 1) 之间的随机数，Numpy 还可以生成其他数值，或使用其他生成规则。比如按照标准正态分布去生成。（啥，不想标准正态分布，想要搞点特殊的？后面我接着介绍，客官不急）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.randn(dim1, dim2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面都是一些小数的生成，我想生成随机整数呢？那就要用到 np.random.randint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.random.randint(low=-3, high=6, size=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.3.2 给你施加随机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经可以自动生成一批随机数啦，但是 Numpy 的好用功能可不止有这么一些简单的生成功能哦。它还可以对已有的数据做随机化处理。 比如我想随机从一组数据中选择，我就可以用 np.random.choice()。我之前在做遗传算法的时候, 做基因重组配对，就需要经常使用到这个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([2,1,3,4,6])\n",
    "print(\"选一个：\", np.random.choice(data))\n",
    "print(\"选多个：\", np.random.choice(data, size=3))\n",
    "print(\"不重复地选多个(不放回)：\", np.random.choice(data, size=3, replace=False))\n",
    "print(\"带权重地选择：\", np.random.choice(data, size=10, p=[0,0,0,0.2,0.8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "没骗你吧，这个功能好用吧。我真的是很常会用到 choice 这个功能。而在机器学习中，你也许会经常在 epoch 迭代训练数据的时候，碰到 shuffle 的概念。 如果你在机器学习中没弄懂没关系，这里给你补充一下。Numpy 里也有 np.random.shuffle() 的功能，就是用来洗牌的。 注意，它会将源数据洗牌重新排列，如果你想保留源数据的话，记得 np.copy(data) 备份一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = np.copy(data)\n",
    "np.random.shuffle(data)\n",
    "print(\"源数据：\", data_copy)\n",
    "print(\"shuffled:\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一个功能，np.random.permutation(), 它实现的是 np.random.shuffle() 的一种特殊形式。可以说是一种简单处理特殊情况的功能。 它有两个方便之处，1. 直接生成乱序的序列号，2. 对数据乱序。\n",
    "\n",
    "而且相比 np.random.shuffle()，permutation 有一个好处，就是可以返回一个新数据，对原本的数据没有影响。而且还可以处理多维数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"直接出乱序序列：\", np.random.permutation(10))\n",
    "data = np.arange(12).reshape([6,2])\n",
    "print(\"多维数据在第一维度上乱序：\", np.random.permutation(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.3.3 随机分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于统计学或者机器学习，我们在生成数据的时候，有时需要按照特定的统计学分布来生成，比如需要一个正态分布的抽样数据，或者均匀分布的数据抽样结果。 又或者是其他更高级的，比如泊松分布等等，都可以用 Numpy 来实现。这里我们只介绍一下在机器学习中比较常用的 正态分布 和 均匀分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (均值，方差，size)\n",
    "print(\"正态分布：\", np.random.normal(1, 0.2, 10))\n",
    "\n",
    "# (最低，最高，size)\n",
    "print(\"均匀分布：\", np.random.uniform(-1, 1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.3.4 随机种子的重要性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习中，我们要对比两种随机初始化模型的优劣，或者在强化学习中要固定随机环境的随机序列，用于复现当前配置的情况，我们通常要做的事情就是伪随机。 简单说，就是每次都是一组随机，但是我可以后续再完整运行一遍一模一样的随机效果。比如生成两遍一模一样的随机序列。\n",
    "\n",
    "为了达到这个目的，我们要了解 Numpy 中的 random seed 概念，随机种子。当我们把种子固定的时候（用一个数字），同一个种子（数字）产生的随机序列就会一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed(1) 代表的就是 1 号随机序列\n",
    "np.random.seed(1)\n",
    "print(np.random.randint(2, 10, size=3))\n",
    "print(np.random.randint(2, 10, size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "无论你运行多少次上门的代码，你看到的随机结果，都是同一种结果。当你想改变随机种子的时候，可以在 seed() 中传入不同的数字。\n",
    "\n",
    "有时候我还会这么用，在同一次执行代码时，重新设定种子，让随机在同一次执行中复现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "print(np.random.randint(2, 10, size=3))\n",
    "np.random.seed(2)\n",
    "print(np.random.randint(2, 10, size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以同一份代码，这两次运行，都会是一样的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.4 numpy的view与copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy 之所以运算快，是有道理的，我们就在这节内容中尝试去理解 Numpy 底层的运行逻辑。其中，有一个非常重要的概念， 那就是 View 和 Copy，你会发现，有可能前几天要花 10 天处理完的数据，学完这个之后，一优化，只需要 1 小时就搞定了。\n",
    "\n",
    "如果你对 Numpy 运算速度有追求，我十分建议你了解这方面的内容。如果你是萌新，目前阶段不用 Numpy 处理大数据（上百MB的文件），那这一节的内容你可以以后再作了解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.4.1 view与copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用 Numpy 创建 Array 的时候，它使用到的是内存上的一段连续空间，而 Python List 是物理内存上的不同区域，只是它用索引将这些区域联系起来了。 正是这样的架构，使得 Numpy Array 在物理空间上可以高效排列。这就为后面理解 View 和 Copy 奠定了基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy 顾名思义, 会将 Array 中的数据 copy 出来存放在内存中另一个地方, 而 View 不 copy 数据, 而是给源数据加一个窗，从外面看窗户里的数据。 具体来说，view 不会新建数据，而只是在源数据上建立索引部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(1, 7).reshape((3,2))\n",
    "a_view = a[:2]\n",
    "a_copy = a[:2].copy()\n",
    "\n",
    "a_copy[1,1] = 0\n",
    "print(\"在 copy 上修改数据，不会影响源数据：\\n\", a)\n",
    "\n",
    "a_view[1,1] = 0\n",
    "print(\"在 view 上修改数据，会影响'窗里'的源数据：\\n\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单说, a_view 的东西全部都是 a 的东西, 动 a_view 的任何地方, a 都会受到牵扯, 因为他们在内存中的位置是一模一样的, 本质上就是自己。 而 a_copy 则是将 a copy 了一份, 然后把 a_copy 放在内存中的另外的地方, 这样改变 a_copy, a 是不会被改变的.\n",
    "\n",
    "那为什么要提这点呢? 因为 View 只是加了窗，不会复制东西, 速度快! 我们来测试一下速度。 我会用下面这个功能来测试一下每个功能的运行时间，数字越小的，运行时间越快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from functools import partial\n",
    "        \n",
    "def get_run_time(func, *args):\n",
    "    repeat = 3\n",
    "    number = 200\n",
    "    return min(timeit.Timer(partial(func, *args)).repeat(repeat=repeat, number=number)) / number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面的例子中 a*=2 就是将这个 view 给赋值了, 和 a[:] *= 2 一个意思, 从头到尾没有创建新的东西。而 b = 2*b 中, 我们将 b 赋值给另外一个新建的 b。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(1000, 1000)\n",
    "b = np.random.rand(1000, 1000)\n",
    "\n",
    "def f1():\n",
    "    global b\n",
    "    # 这会产生新的 b\n",
    "    b = 2*b\n",
    "\n",
    "def f2():\n",
    "    global a\n",
    "    # 这不会产生新的 a\n",
    "    a *= 2    # 和 a[:] *= 2 一样\n",
    "\n",
    "print('%.6f - b = 2*b' % get_run_time(f1))     \n",
    "print('%.6f - a *= 2' % get_run_time(f2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从运行结果来看，运行结果还是快了 10%~20% 的。\n",
    "\n",
    "对于 view 还有一点要提, 你是不是偶尔有时候要把一个矩阵展平, 用到 np.flatten() 或者 np.ravel()。 我们在改变数据结构 中也提到了这两个功能。 他俩虽然结果上相同，但是含义是完全不同的! 官方说如果用 ravel(), 需要 copy 的时候才会被 copy , 我想这个时候可能是把 ravel 里面 order 转换的时候, 如 'C-type' -> 'Fortran', 而 flatten() 返回的总是一个 copy。现在你知道谁在拖你的后腿了吧!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1():\n",
    "    a.flatten()\n",
    "\n",
    "def f2():\n",
    "    b.ravel()\n",
    "\n",
    "print('%.6f - flatten' % get_run_time(f1))     \n",
    "print('%.6f - ravel' % get_run_time(f2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行了上面的测试后, 相比于 flatten(), ravel() 简直是神速，提高了近 700 倍。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.4.2 在数据选择上加速"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择数据的时候, 我们常会用到 view 或者 copy 的形式。现在你应该知道了, 如果能用到 view 的, 我们就尽量用 view, 避免 copy 数据。那在选择数据的时候，那些是选择了一个 view 呢? 下面举例的都是 view 的方式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([100, 100])\n",
    "a_view1 = a[1:2, 3:6]    # 切片 slice\n",
    "a_view2 = a[:100]        # 同上\n",
    "a_view3 = a[::2]         # 跳步\n",
    "a_view4 = a.ravel()      # 上面提到了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那哪些操作我们又会变成 copy 呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([2, 2])\n",
    "a_copy2 = a[[True, True], [False, True]]  # 用 mask\n",
    "\n",
    "a = np.zeros([100, 100])\n",
    "a_copy1 = a[[1,4,6], [2,4,6]]   # 用 index 选\n",
    "a_copy3 = a[[1,2], :]        # 虽然 1,2 的确连在一起了, 但是他们确实是 copy\n",
    "a_copy4 = a[a[1,:] != 0, :]  # fancy indexing\n",
    "a_copy5 = a[np.isnan(a[:,0]), :]  # fancy indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy 给了我们很多很自由的方式选择数据, 这些虽然都很方便, 但是在你没必要 copy 的时候， 如果你可以避免引起 Copy 的这些操作, 你的速度可以飞起来.\n",
    "\n",
    "在上面提到的 blog 里面, 他提到了, 如果你还是喜欢这种 fancy indexing 的形式, 我们也是可以对它加点速的。那个 blog 中指出了两种方法。\n",
    "\n",
    "1. 使用 np.take(), 替代用 index 选数据的方法。\n",
    "\n",
    "上面提到了如果用 index 来选数据, 像 a_copy1 = a[[1,4,6], [2,4,6]], 用 take 在大部分情况中会比这样的 a_copy1 要快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(1000000, 10)\n",
    "indices = np.random.randint(0, len(a), size=10000)\n",
    "\n",
    "def f1():\n",
    "    # fancy indexing\n",
    "    _ = a[indices]\n",
    "\n",
    "def f2():\n",
    "    # take\n",
    "    _ = np.take(a, indices, axis=0)\n",
    "\n",
    "print('%.6f - [indices]' % get_run_time(f1))     \n",
    "print('%.6f - take' % get_run_time(f2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的数据，用 take() 有个十几倍的加速还是挺不错的。\n",
    "\n",
    "2. 使用 np.compress(), 替代用 mask 选数据的方法。\n",
    "\n",
    "上面的 a_copy2 = a[[True, True], [False, True]] 这种就是用 True, False 来选择数据的。我们对比一下它和 compress() 的效率， 测试如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10000, 10)\n",
    "mask = a[:, 0] < 0.5\n",
    "\n",
    "def f1():\n",
    "    _ = a[mask]\n",
    "\n",
    "def f2():\n",
    "    _ = np.compress(mask, a, axis=0)\n",
    "        \n",
    "\n",
    "print('%.6f - [mask]' % get_run_time(f1))     \n",
    "print('%.6f - compress' % get_run_time(f2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compress 方法在这种情况下，也有一个 9 倍左右的提升。已经相当不错了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17.4.3 非常有用的out参数总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不深入了解 numpy 的朋友, 应该会直接忽略很多功能中的这个 out 参数 (之前我从来没用过)。 不过当我深入了解了以后, 发现他非常有用! 比如下面两个其实在功能上是没差的, 不过运算时间上有差, 我觉得可能是 a=a+1 要先转换成 np.add() 这种形式再运算, 所以前者要用更久一点的时间."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([10000, 10])\n",
    "\n",
    "def f1(a):\n",
    "    a = a + 1 \n",
    "\n",
    "def f2(a):\n",
    "    a = np.add(a, 1)\n",
    "        \n",
    "\n",
    "print('%.6f - a + 1' % get_run_time(f1, a))     \n",
    "print('%.6f - np.add(a, 1)' % get_run_time(f2, a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果是上面那样, 我们就会触发之前提到的 copy 原则, 这两个被赋值的 a, 都是原来 a 的一个 copy, 并不是 a 的 view。但是在功能里面有一个 out 参数, 让我们不必要重新创建一个 a。\n",
    "\n",
    "我们看看使用 out 之前，它们的处理方式算不算 copy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([2,])\n",
    "a_copy = np.add(a, 1)  # copy 发生在这里\n",
    "print(a, a_copy)\n",
    "\n",
    "b = np.zeros([2,])\n",
    "c = np.zeros_like(b)  # copy 发生在这里\n",
    "np.add(b, 1, out=c)\n",
    "print(b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我上面的例子，你应该可以很明显的看出来，如果我们新建了一个 c，用 out=c 来指定将加法结果输出到 c， 那么我们就可以利用这种特性来减少 copy 的产生。比如下面这个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros([1000, 1000])\n",
    "b = np.zeros_like(a)\n",
    "c = np.zeros_like(a)\n",
    "\n",
    "def f1():\n",
    "    a[:] = np.add(a, 1)  # 把计算结果赋值回原数据\n",
    "\n",
    "def f2():\n",
    "    np.add(b, 1, out=b)  # 把计算结果赋值回原数据\n",
    "\n",
    "def f3():\n",
    "    _c = np.add(c, 1)   # 把计算结果赋值到新数据\n",
    "\n",
    "\n",
    "print('%.6f - without out' % get_run_time(f1))     \n",
    "print('%.6f - out' % get_run_time(f2))\n",
    "print('%.6f - new data' % get_run_time(f3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的例子可以看出来，如果要完完全全对比将计算结果赋值回源数据的案例，我们明显发现，使用 out 要比不使用 out 快一倍。 但是有意思的是，如果我不赋值回源数据，而是创建一个新数据 _c，这种方法也只是比使用 out 的方法慢了一点点，但是比 a[:] 这种方法快上不少。 我想可能是 numpy 对于创造新数据的做法做了深度优化吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.5 用numpy搞机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前的机器学习算法中，深度学习无疑是最厉害之一，而深度学习的核心基础是矩阵运算。恰好 Numpy 就最擅长做这件事。 那为什么 Numpy 能做深度学习中最核心的事，但还有这么多其他机器学习的库，比如 Tensorflow, Pytorch 等，它们和 Numpy 相比，有什么不同呢？\n",
    "\n",
    "其实，Numpy 是上个时代的产物，它基本上所有的优化都是基于 CPU 的优化，而现在的深度学习，大多都要利用到 GPU 甚至是 TPU 的计算单元。 所以有很多操作，Numpy 是不擅长的。但是像 Tensorflow，Pytorch 这种深度学习库，在很大程度上都是借鉴了 Numpy 而开发的。所以说， Numpy 的贡献还是不可忽视。\n",
    "\n",
    "好了，说了这么多背景，我有两条建议。\n",
    "\n",
    "1.自己开发不依赖于 Tensorflow 和 Pytorch 的深度学习的项目，建议从 Numpy 入手。（比如遗传算法）<br>\n",
    "2.Tensorflow 和 Pytorch 能实现的项目，就尽量用它们开发，Numpy 在深度学习上的功能，和 GPU 的加速上，都不占优势。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三部分：pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18.pandas简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.1 为什么用pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进入大数据时代，感觉我们如果不会一些分析数据的能力，就将要被时代淘汰。不过好在现在的技越来越先进，越来越易用，而且网络上也有越来越多的教学内容。 只要你有一些耐心，入门其实并不难。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大数据虽然描述的是海量的数据，但是大数据离你却并不远，特别是大数据所涵盖的技术，在你生活当中，是时刻都能使用这些大数据涉及到的技术， 来解决你生活中的具体问题。当你也有想解决的数据问题，不管是一份考题，还是工作总结，拥有了这种处理数据的能力后，不光是你自己，就可能连身边的人都会受益于你的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今天要讲的是 Pandas，是什么时候才会让我想要使用 Pandas 来处理问题呢？我下面列一条，说不定就有你正面临的问题：\n",
    "\n",
    "1.办公自动化<br>\n",
    "上学上班，有 Excel 或者格式化的文本文件，需要进行数据加工处理<br>\n",
    "对大量的这些文本文件作图，想要自动化处理<br>\n",
    "2.人工智能<br>\n",
    "数据分析，可视化数据规律<br>\n",
    "数据前处理，为 AI 模型展平道路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.2 pandas是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单来说，Pandas 是 Python 中一个比较常用的第三方库，里面集成了很多和数据相关的功能组件。上面提到的那些场景中， 无非就是要：\n",
    "\n",
    "1.处理数据<br>\n",
    "2.分析数据<br>\n",
    "3.画图\n",
    "\n",
    "所以 Pandas 就围绕着这些环节施展能力。而且它承接了 Numpy 的能力，使用的底层也是 Numpy。按理来说，我们也能用 Numpy 来实现上述功能， 但为什么 Pandas 还是这么广为流传呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18.3 Pandas 和 Numpy 的差别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用过 Python，你肯定熟悉里面的 List 和 Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list = [1,2,3]\n",
    "a_dict = {\"a\": 1, \"b\": 2, \"c\": 3}\n",
    "print(\"list:\", a_list)\n",
    "print(\"dict:\", a_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面就是一种最常见的 Python 列表和字典表达方式。而下面，我们展示的就是 Numpy 和 Pandas 的一种构建方式。 试着执行一下代码结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "a_array = np.array([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "a_df = pd.DataFrame(\n",
    "    {\"a\": [1,3], \n",
    "     \"b\": [2,4]}\n",
    ")\n",
    "\n",
    "print(\"numpy array:\\n\", a_array)\n",
    "print(\"\\npandas df:\\n\", a_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你会发现，我们看到的结果中，Numpy 的是没有任何数据标签信息的，你可以认为它是纯数据。而 Pandas 就像字典一样，还记录着数据的外围信息， 比如标签（Column 名）和索引（Row index）。 这也是我为什么总说 Numpy 是 Python 里的列表，而 Pandas 是 Python 里的字典。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是回到之前提的问题，对于数据运算，既然我们有了 Numpy，为什么还要用 Pandas？对比列表和字典，我们很容易感受到其中的一种原因。 就是 Pandas 帮我们记录的信息量变多了。\n",
    "\n",
    "在 Numpy 中， 如果你不特别在其他地方标注，你是不清楚记录的这里边记录的是什么信息的。而 Pandas 记录的信息可以特别丰富， 你给别人使用传播数据的时，这些信息也会一起传递过去。或者你自己处理数据时对照着信息来加工数据，也会更加友善。\n",
    "\n",
    "这就是在我看来 Pandas 对比 Numpy 的一个最直观的好处。\n",
    "\n",
    "另外 Pandas 用于处理数据的功能也比较多，信息种类也更丰富，特别是你有一些包含字符的表格，Pandas 可以帮你处理分析这些字符型的数据表。 当然还有很多其它功能，比如处理丢失信息，多种合并数据方式，读取和保存为更可读的形式等等。\n",
    "\n",
    "这些都让 Pandas 绽放光彩。但是，Pandas 也有不足的地方：运算速度稍微比 Numpy 慢。\n",
    "\n",
    "你想想，因为 Pandas 是在 Numpy 之上的一层封装，所以肯定在处理数据的时候要多几层处理，小数据量的处理不要紧，慢一点就慢一点， 你也感受不到处理速度的变化。但当数据量变大，用 Numpy 要处理 1 小时的数据，你可能用 Pandas 要花两小时。 所以你得依据自己的实际需求来选择到底是用 Numpy 还是 Pandas。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19.pandas从文件读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有很多 Pandas 的教学，一开始一般都是开始教 Pandas 的数据结构或者运算方法。 但是我觉得，当你想要使用 Pandas 的时候，更多是因为你手头有 Excel 数据或者比较格式化的数据， 需要处理分析和表达这些数据。为了解决你这种当务之急，我觉得先解决读取数据这回事。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.1 Excel文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一步假设的就是我们电脑里有一份 xlsx 的 Excel 文件，现在我们要来用 Pandas 打开它。 你只需要使用使用 pd.read_excel() 就能读出来了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"data/体检数据.xlsx\", index_col=0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，当你在自己电脑，本地运行 Python 时，pd.read_excel() 功能有可能会报错，说你可能缺失这几个库 openpyxl, xlrd, lzma 当中的某些库。 解决的办法很简单，就是用 pip 来安装它们就好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，我在 pd.read_excel() 当中使用了 index_col=0 这个参数，你先看看如果不使用这个，会显示什么。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel(\"data/体检数据.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，前面还多了一列 Unnammed：0，使用 index_col=0 就是告诉 Pandas，让它使用第一个 column（学号）的数据当做 row 索引。 后面还有很多读取的功能里也有一样的参数。\n",
    "\n",
    "好，我们既然可以读取 Excel 文件，那么稍稍修改，再保存起来应该也不成问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[2, \"体重\"] = 1\n",
    "print(df)\n",
    "df.to_excel(\"data/体检数据_修改.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行完上面这句保存的指令，我们下面再打开这份修改版 Excel 吧。看看这份文件到底有没有被修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_excel(\"data/体检数据_修改.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实在读取和保存 Excel 文件的时候，还有很多额外的参数可供选择，因为太多了，我们这里就先讲最常用的，如果你要深入研究， 可以到他们的官网来看官方文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19.2 csv或txt等纯文本文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提到纯文本文件，你会想到哪些？txt，csv，log 等这些都可以是纯文本文件，不过值得注意的是，对于 Pandas，它只对结构化的纯文本文件感兴趣。如果在你的纯文本文件中， 不是用一些标准的分隔符来分割数据，那么 Pandas 也拿它无能为力，是解析不出来的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习或者很多场景下的数据分析中，数据也都是这样保存的。 因为这样保存出来的数据，所占空间比 xlsx 这种 Excel 文件要小很多。而且也不失可读性。用 Pandas 打开也很简单，直接调用 pd.read_csv() 就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(\"data/体检数据.csv\", index_col=0)\n",
    "print(df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有的时候，你不能保证别人给你的数据，是不是一份标准格式的数据，比如别人不喜欢用 , 来分隔数据点， 而是喜欢用什么乱七八糟的 = 来分隔。这时，Pandas 帮你考虑到了这种问题， 你可以挑选要用哪个字符来识别这些分隔。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/体检数据_sep.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(f.read())\n",
    "df_csv = pd.read_csv(\"data/体检数据_sep.csv\", index_col=0, sep=\"=\")\n",
    "print(df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提到 csv，你可能还会想用 Excel 打开看看，但是提到 txt，一般你也不会想用 Excel 打开了吧。用 Pandas 打开一个 txt 文件和打开一个 csv 文件，、 其实本质上是一样的，都是打开一个纯文本文件。所以下面我再打开一下 txt。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/体检数据_sep.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    print(f.read())\n",
    "df_txt = pd.read_csv(\"data/体检数据_sep.txt\", index_col=0, sep=\"=\")\n",
    "print(df_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能打开，我们就能保存，保存方法同样很简单，只需要 df.to_csv() 就好了，甚至，你还能保存到 Excel 文件，在 Pandas 中它们是可以互相转换的。 同理用 read_excel() 打开的，也能存成 to_csv()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt.to_csv(\"data/体检数据_sep_修改.csv\")\n",
    "df_txt.to_excel(\"data/体检数据_sep_修改.xlsx\")\n",
    "\n",
    "print(\"读保存后的 csv\")\n",
    "print(pd.read_csv(\"data/体检数据_sep_修改.csv\"))\n",
    "\n",
    "print(\"读保存后的 xlsx\")\n",
    "print(pd.read_excel(\"data/体检数据_sep_修改.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，做数据分析和机器学习，会用上面的方法来读 Excel 或者是纯文本，我们就已经解决了大部分的需求了。下面我来介绍几个我觉得 Pandas 的额外几个有趣的读取方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一些功能，比如让 Pandas 读剪切板，读数据库，读 Json 等，你都可能在后期自己开发的时候偶尔用到。只要用到的时候，查查 Pandas 官方文档 还是很有帮助的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：大千世界，数据也是多样的，Pandas 量身为你定制了很多读取数据的方法。从做数据分析和机器学习最常用的 Excel、csv、txt 数据等，到 html，剪切板等有趣的数据类型， 一个 Pandas 都可以帮你搞定。了解完读存数据，下一节，我们就来认真了解，数据在 Pandas 中到底是一个什么样的东西。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.pandas中的数据是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上次我们已经提到了在你分析数据时最基础的工作 用 Pandas 打开数据文件， 不过我们并没有详细说这份打开的数据，它的格式是什么样。但了解我们要如何更改加工数据，我们必然还是要清楚这个在 Pandas 中的数据格式是什么。\n",
    "\n",
    "简单来说，Pandas 支持最好的是一维和二维数据，一维数据就是一个序列，一条数据，而二维数据是我们生活中更常见的种类，基本上所有 Excel 数据， 都是二维数据，有横纵交替，用两个维度来定位这个数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1 数据序列Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一串 Python List 的形式你肯定不陌生，Pandas 中的 Series 的核心其实就是一串类似于 Python List 的序列。只是它要比 Python List 丰富很多， 有更多的功能属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "l = [11,22,33]\n",
    "s = pd.Series(l)\n",
    "print(\"list:\", l)\n",
    "print(\"series:\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印出来，对比很明显，Pandas Series 还帮我们额外维护了一份索引。有这个索引有啥意义呢？Python List 不也有一个隐藏的序号索引吗？ 其实啊，Pandas 之所以做这一种索引，目的并不是仅让你用 0123 这样的序号来检索数据，它还想让你可以用自己喜欢的索引来检索。看看下面的代码吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "是不是打开了新世界！原来还能自定义索引。现在想想，你有没有发现，是不是只要是有索引形式的结构，都可以搞成 Series？比如下面这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series({\"a\": 11, \"b\": 22, \"c\": 33})\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "太神奇了吧，原来字典也可以变成一个序列！更神奇的还在后面的 DataFrame 呢，也可以用字典来创建 DataFrame。\n",
    "\n",
    "既然 Python 的 List 可以用来创建 Series，那我想 Numpy 应该也可以吧，要不来试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "s = pd.Series(np.random.rand(3), index=[\"a\", \"b\", \"c\"])\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然 Numpy 和 List 可以用来创建 Series，那 Series 能回退到 Numpy array 或者 List 吗? 我们试一试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"array:\", s.to_numpy())\n",
    "print(\"list:\", s.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还真是，他们真的能自由穿梭，这可大大减轻了我们在不同的数据形式中切换的成本。一维的 Series 都这么神奇，那二维的 DataFrame 岂不是要玩出花来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2 数据表DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas 首先支持的是序列数据和表格数据，因为这两种是如常生活中最常用的数据保存和编辑格式了，你见过有人去编辑一个 3 维数据吗？ 话说回来，如果你硬扯上 Excel 里面的不同 sheet，把 sheet 当成第三个维度，那也是成立的。sheet 这个我就先不说了，我们先看看用 Pandas 的 DataFrame 怎么维护一张数据表吧。\n",
    "\n",
    "在上一节数据文件读取的教学中，你 load 到的数据，实际上就是一个 DataFrame， 举个最简单的例子。将一个二维数组变成 Pandas 的 DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "  [1,2],\n",
    "  [3,4]\n",
    "])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看看，它创建出来的 df，在真实数据外圈，还包上了一层其他的数据，比如 0 1， 这是什么呢？其实这是 DataFrame 中，用来索引行列的序号， 外圈的横竖都是 0 1 代表着每个维度上，都有第 0 位和第 1 位。如果我要按位置来选取一下其中的值，我可以这么干。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第 0 行，第 1 列\n",
    "# 或 第一个维度中的第 0 号，第二个维度中的第 1 号\n",
    "print(df.at[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas 中还有很多方式来选取和改变数据值，请按捺一下激动的小心情， 我们将在下节内容中具体介绍。\n",
    "\n",
    "上面我们见识到了直接用一个二维列表来创建 DataFrame，但是自动创建的索引序号并不是很可读。我们还能将这些序号换成人类更好理解的文字标签信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"col1\": [1,3], \"col2\": [2, 4]})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以从结果看出，其实字典中的 key 会被当成是数据中的 column，而 value 会被当做是 row，这个非常符合你在 Excel 中的使用习惯。 因为往往随着数据量变大，你用鼠标滚轮滚动查看不同数据的时候，天然的比较喜欢上下查看不同的数据样本，而不是左右查看，所以一般都是左右记的是数据标签（特征）， 上下排列的是不同数据样本。\n",
    "\n",
    "见识了字典变 DataFrame，其实 Series 也是可以组合变成 DataFrame 的，而且这也非常符合常理， 如果我从 DataFrame 中取出一个 Column， 这不就变成了一条 Series 了吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"col1\"], \"\\n\")\n",
    "print(\"取出来之后的 type：\", type(df[\"col1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么将两个 Series 拼接起来呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"col1\": pd.Series([1,3]), \"col2\": pd.Series([2, 4])})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面 Series 说过，我们是可以为它构建特殊索引的，现在来看看 Series 和 DataFrame 构建索引的方式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1.0, 2.0, 3.0], index=[\"a\", \"b\", \"c\"])\n",
    "df = pd.DataFrame({\"col1\": [1,3], \"col2\": [2, 4]}, index=[\"a\", \"b\"])\n",
    "print(s, \"\\n\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然 DataFrame 的 Column 和 Index 这么有意思，十有八九，你会想取出来用一用这些 Column 和 Index，比如你数据比较大的时候，想初步看看这份数据涉及了多少特征， 数据的 index 有多少种的时候，你可以直接获取到这些信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index, \"\\n\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有更有意思的，如果写前端的朋友，你们时常会遇到 json 形式的数据，比如可以像下面这样处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_json_data = [\n",
    "  {\"age\": 12, \"height\": 111},\n",
    "  {\"age\": 13, \"height\": 123}\n",
    "]\n",
    "pd.DataFrame(my_json_data, index=[\"jack\", \"rose\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在有了 Pandas 中的 DataFrame，我们在想转化成 Numpy，怎么搞？ 如果你刚刚认真跑 Series 的案例，你就会知道可以用下面的方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"col1\": [1,3], \"col2\": [2, 4]}, index=[\"a\", \"b\"])\n",
    "df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas 真的用心良苦，为我们广大数据同胞提供了这么多这么丰富的接口。学会这样观看数据，我们在分析和处理数据的时候就更有把握了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：Pandas 中，为了我们提供了日常最常用的数据存储方式，分别是 Series 的一维数据，和 DataFrame 的二维数据，在机器学习中，我们常会接触到 3 维甚至是更高维度， 但是在分析数据的时候，特别是，要结合 Excel 来分析数据的时候，二维数据才是最常用的。\n",
    "\n",
    "了解 Pandas 的 Series，DataFrame 如何构建，和这两种数据类型的差别，我们再来探索更有趣的数据选取教学。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21.pandas选取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas 的数据结构和你管理 Excel 很像，特别是 DataFrame 就约等于 Excel 当中的 sheet。 我们非常适应用 Excel 来选择和修改数据，但是如果把它程序化，用代码来修改和选取的时候，我们该如何操作呢？\n",
    "\n",
    "Pandas 的数据选取，和 List，Numpy Array 还是有挺大差别的，因为它想要维护了很多的人类可读的索引信息， 所以它在索引的时候，也有不一样的处理方式，今天我们就来看看 Pandas 是如何处理数据选取和修改的吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.1 多种选取方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Pandas 中，有丰富的选取数据方式，这可比 List，Dictionary，甚至是 Numpy 还要多样化。我们既能通过文字标签来定位数据，也能通过数值序号来定位。 所以为了实现这种多样性，Pandas 对于数据的选取采用了不同类型的处理方法，比如 .loc, .iloc 等，我们下面一一来介绍一下吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "面对应用比较多的工作学习场景，我先以 Excel 型的表格数据举例，请你帮我构建一下下面这份 DataFrame："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = np.arange(-12, 12).reshape((6, 4))\n",
    "df = pd.DataFrame(\n",
    "  data, \n",
    "  index=list(\"abcdef\"), \n",
    "  columns=list(\"ABCD\"))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.2 选Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到了上面这份数据后，我们发现，DataFrame 会分 Column 和 Row（index）。如果你搞机器学习，通常我们的 Column 是特征，Row 是数据样本， 在要对某个特征进行分析的时候，比如要做特征数值分布的分析，我们得把特征取出来吧。 那么你可以这么搞。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选一个就这么简单，但是偶尔你还想多选几个特征，怎么搞呢？想一想以前 Numpy 教学里面的 Array 是怎么选的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numpy:\\n\", data[:, [2,1]])\n",
    "print(\"\\ndf:\\n\", df[[\"C\", \"B\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "已经能选 column 了，那意味着肯定能将 Index（Row）的信息也一起考虑到数据筛选的工作当中了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.3 loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你是刚从 面向 Excel 编程，或者也没怎么用过 Excel 中的函数的朋友，也可以轻松从 loc 函数中找到一丝丝熟悉的感觉。 因为这个 .loc 方法是更贴近我们人类直觉的，按照字面来选取数据块的方式。\n",
    "\n",
    "我举个例子你就明白了，如果你对我的 Numpy教程 熟悉，你会知道，在 Numpy 中选取数据一般都是按照在维度上的排序来定位的。 比如对于你刚刚创建的 Numpy 数据 data："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2:3, 1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而在 DataFrame 中，同样是上述功能，你可以这么干："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"c\":\"d\", \"B\":\"D\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "咦，不知道你有没有发现，这个 \"c\":\"d\" 和 \"B\":\"D\" 明明对应的是上面 data 的 [2:3] 和 [1:3]，但为什么它还包含了最后一位的 \"d\" 和 \"D\" 呢？这的确是 Pandas 的一个用心良苦，我猜他是为了更贴切 Excel 中的使用原则吧，想一想，如果你在选择 Excel 要被筛选的数据时，从 b 选到 d，其实你是有包含 d 的。所以我说，Pandas 这么设计，原因之一也应该是为了照顾我们吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了筛选一个片段，还可以像 Numpy 那样单个单个的选取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numpy:\\n\", data[[3,1], :])\n",
    "print(\"\\ndf:\\n\", df.loc[[\"d\", \"b\"], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这两个例子，不难看出，Pandas 选取数据的底层逻辑，和 Python Numpy 的类似，都是按维度的先后（先选第一维，再第二，以此类推）， 开始选取。按数据的索引找到维度上的对应索引区域。\n",
    "\n",
    "下面我再来整个有趣的，如果我不按字母顺序去组织 index，比如从原本的 index=abcdef 换成 index=beacdf， 猜猜下面的这份数据索引会找到哪一份子数据？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "  data, \n",
    "  index=list(\"beacdf\"), \n",
    "  columns=list(\"ABCD\"))\n",
    "print(df2)\n",
    "print(df2.loc[\"e\":\"c\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.4 iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看完面向 Excel 编程，我们再来回到编程本身，用程序的思维去选取数据。这意味着什么？用最朴素的方法，也是意味着能更快找到数据位置，比如直接用位置信息来筛选。 Numpy 不就是这么干的吗？这时 .iloc 功能就派上用场了。\n",
    "\n",
    "同样还是上面那份数据，我们走一遍 .iloc 的流程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numpy:\\n\", data[2:3, 1:3])\n",
    "print(\"\\ndf:\\n\", df.iloc[2:3, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简直和 Numpy 的模式一模一样，就是结果中多了一个 DataFrame 的标签信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"numpy:\\n\", data[[3,1], :])\n",
    "print(\"\\ndf:\\n\", df.iloc[[3, 1], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.5 loc和iloc混搭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "难免有时候，我们需要混搭 loc 和 iloc 的方式，比如我想要选取第 2 到第 4 位数据的 A C 两个特征，这时咋办？ 想想 Pandas 这么牛逼，肯定有办法解决。的确，它解决的方法是采用索引转换的方式，比如我在 .loc 模式下，将序号索引转换成 .loc 的标签索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_labels = df.index[2:4]\n",
    "print(\"row_labels:\\n\", row_labels)\n",
    "print(\"\\ndf:\\n\", df.loc[row_labels, [\"A\", \"C\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再看看 Column 的 labels 怎么取？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_labels = df.columns[[0, 3]]\n",
    "print(\"col_labels:\\n\", col_labels)\n",
    "print(\"\\ndf:\\n\", df.loc[row_labels, col_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清楚了吧，用 df.index 和 df.columns 来调取到全部的标签，然后在用像 Numpy index 索引的方式把这些标签给筛选出来，放到 .loc 里面用。 那反过来，我想要找 A B 两个特征的 前两个数据，这时咋办？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_index = df.columns.get_indexer([\"A\", \"B\"])\n",
    "print(\"col_index:\\n\", col_index)\n",
    "print(\"\\ndf:\\n\", df.iloc[:2, col_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，df.index.get_indexer([\"a\", \"b\"]) 也可以这样获取到 label 对应的 index 信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.6 条件过滤筛选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按条件过滤其实是一件很有趣的事，因为很多情况我们事先也不知道具体的 index 是什么，我们更想要从某些条件中筛选数据。 下面我举几个例子，大家应该很容易 get 到其中的奥秘。\n",
    "\n",
    "选在 A Column 中小于 0 的那些数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"A\"] < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选在第一行数据不小于 -10 的数据，这里注意了你可以用两种方式，一种是 ~ 来表示 非 什么什么，第二种是直接用 >=-10 来筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"~:\\n\", df.loc[:, ~(df.iloc[0] < -10)])\n",
    "print(\"\\n>=:\\n\", df.loc[:, df.iloc[0] >= -10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同上面类似的，我还能用或 | 来表示 or 的意思, & 表述 and。比如选在第一行数据不小于 -10 或小于 -11 的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i0 = df.iloc[0]\n",
    "df.loc[:, ~(i0 < -10) | (i0 < -11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以你看，你可以用 .loc 或者 .iloc 来做过滤处理。然后用 .loc 来做筛选。为什么用 .iloc 来筛选呢，比如下面这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, ~(df.iloc[0] < -10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样写居然会导致报错，为什么呢？你分析分析，把 ~(df.iloc[0] < -10) 这个筛选条件打印出来看看它是什么值。然后想一想 .iloc 能够接受的值是啥？ 想清楚了，这个问题就迎刃而解了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21.7 Series和DataFrame类似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我的讲解顺序可能有点反常规，一般人可能会先从 Series 的数据筛选操作讲到 DataFrame，而我想要从你日常最常用的东西，讲到不太常用的。 从数据处理的角度，比如处理常用的 Excel，在这里的顺序， 就应该是从 DataFrame 讲到 Series。\n",
    "\n",
    "既然二维的 DataFrame 你都已经玩过了，Series 的操作就不在话下了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = list(range(-4, 4))\n",
    "s = pd.Series(\n",
    "  list_data, \n",
    "  index=list(\"abcdefgh\"))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21.7.1 按标签筛选数据 .loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.loc[[\"a\", \"g\", \"c\"]], \"\\n\")\n",
    "print(s.loc[\"c\": \"f\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21.7.2 按 index 筛选数据 .iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.iloc[[3, 1, 5]], \"\\n\")\n",
    "print(s.iloc[2: 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21.7.3 iloc 和 loc 互相混用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.iloc[s.index.get_indexer([\"c\", \"d\"])], \"\\n\")\n",
    "print(s.loc[s.index[[3,2]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21.7.4 按条件过滤筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.loc[s < 3], \"\\n\")\n",
    "print(s.loc[(s < 0) & (s > -2)], \"\\n\")\n",
    "print(s.loc[(s < 0) | (s > 2)], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：Pandas 的数据筛选方法比 Numpy 丰富多了，介绍的篇幅也有点多，我日常用的最多的还是用条件来筛选，比如在处理机器学习的脏数据的时候，要用很多筛选逻辑。 有时甚至我会觉得 Numpy 的筛选方式不够多，专门把 Numpy 数据转换成 Pandas 数据，然后再用 Pandas 提供的丰富工具处理数据，再转回 Numpy。 相信你用熟了之后，数据处理将要简单很多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22.pandas统计展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.1 基础统计方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Pandas 上做数据统计，要比在 Numpy 上做舒服很多，因为在数据展示上，有很多额外的信息辅助你来消化这些信息。 而且你还能比较方便地绘制成图。\n",
    "\n",
    "我们在这一节内容中，会对比 Numpy 中的方法和 Pandas 的不同，来解释为什么人们在做数据分析的时候喜欢用 Pandas。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.1.1 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在分析数据或者统计数据的时候，首先得有数据，我简单创建了一份数据，后续的工作将会依赖于这份数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([\n",
    "    [1.39, 1.77, None],\n",
    "    [0.34, 1.91, -0.05],\n",
    "    [0.34, 1.47, 1.22],\n",
    "    [None, 0.27, -0.61]\n",
    "])\n",
    "df = pd.DataFrame(data, index=[\"r0\", \"r1\", \"r2\", \"r3\"], columns=[\"c0\", \"c1\", \"c2\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你在日常生活中，也经常是以这种 2 维表格型数据为主，而且因为各种不可知原因，你的数据可能存在缺失状况。比如有人没交作业，有数据还没被采集到等等。 如果你使用 Excel 收集的数据（用 Pandas 读 Excel），那这种情况可能更加多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.1.2 快速总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常，如果我们不知道这份数据包含了什么，想快速了解一下这份数据的基础信息，我们可以直接先上一个 describe()，让 Pandas 自动帮我们描述一下这份数据的基础信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，会显示出来 count 计数（剔除掉 None 或者 NAN 这种无效数据），所以你在结果中能看到 c0，c2 两个的有效数是 3 个，而 c1 有效数有 4 个。\n",
    "\n",
    "unique 表示的是每个 column 中有多少独特的数据。这个在初步感知数据丰富度上会有一定的作用。\n",
    "\n",
    "top 表示出现最多的数据是哪一个，这组数据在 c0 column 处，我们能观察到 0.34 出现了两次，所以它选的 top 是 0.34。\n",
    "\n",
    "freq 是继续了 top，表述的是这个出现频率最多的数据，出现的次数有多少次。\n",
    "\n",
    "上面这份数据还不是纯数据，如果是存数值型的数据，我们跑 describe() 还能看到统计学的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.random((4,3)), columns=[\"c0\", \"c1\", \"c2\"])\n",
    "print(df1)\n",
    "print(\"\\ndescribe:\\n\", df1.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "平均数（mean），均方差（std），最小值（min），统计学的 25 分位，50 分位，75 分位各是多少，最大值（max）是多少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.1.3 均值中位数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "像上面，我们已经可以从 describe() 功能中略知一二了，但是你肯定也不满足于这些简单的描述信息。那么我们看看还有哪些简单实用的统计学功能。 比较常用的，我们通常会想知道一组数据的均值，用 mean() 就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样可以直接输出每一个 columns 的均值，因为这是在对 df 的第0个维度在做求均值。也可以这么写。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，如果你不想对第 0 个维度，而是想对第 1 个维度求均值呢（后面的功能中 axis 的用法都基本相似）。我们只需要把 axis=0 换成 axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一个比较有用的参数 skipna，这个是用来处理数据中有 None 或者是 NaN 时用的。我们需不需要排除掉有 None 或者 NaN 的数据。 如果需要 skip 掉这些，我们就还是会计算所有行列的数值，只是在计数的时候，扣掉这些 None 和 NaN。而当 skipna=False 的时候， Pandas 只要遇到了 None 或者 NaN，就不计算这列、行的数据了。所以下面你会看到，它只返回了一个 column 的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=0, skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，对比 Numpy 的用法，你会发现， Pandas 在展示信息上还是挺对用户考虑的，它把行名等都展示出来，让人不犯迷糊。\n",
    "\n",
    "有了上面的 mean() 的用法做铺垫，理解后面的用法也方便很多。比如在计算人民收入的时候， 我们常用中值来代替均值，原因很简单，极高收入群体总是拉高了我们的平均收入， 用中位数反倒能反映出群众的真实收入。 查中值的方式也很简单，就是 median()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后一个为高收入人\n",
    "s = pd.Series([1000, 2000, 4000, 100000])\n",
    "print(\"mean():\", s.mean())   # 拉高平均收入，拉高仇恨\n",
    "print(\"median():\", s.median())  # 比较合理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.1.4 累加累乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了上面的 mean() 和 median() 的用法做铺垫，理解后面的用法也方便很多。 比如要对数据做累加和累乘的运算，我们使用方式和 mean() 就没啥差别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(12).reshape((4,3)), columns=[\"c0\", \"c1\", \"c2\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sum():\\n\", df.sum())\n",
    "print(\"\\nsum(axis=0):\\n\", df.sum(axis=0))\n",
    "print(\"\\nsum(axis=1):\\n\", df.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"prod():\\n\", df.prod())\n",
    "print(\"\\nprod(axis=0):\\n\", df.prod(axis=0))\n",
    "print(\"\\nprod(axis=1):\\n\", df.prod(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.1.5 最大最小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，理解了上面的用法，查找最大最小也不是问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max():\\n\", df.max())\n",
    "print(\"\\nmin():\\n\", df.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不过你注意到没，这种 max() 和 min() 都是对某一维度进行操作的，肯定有时候，你想要找到那个全局最大最小的数，这怎么找？ 哈哈，那你就做两次操作吧。或者你可以先把它转成 numpy，然后展平了求全局最大最小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.max().max())\n",
    "print(df.values.ravel().max())  # 用 Numpy 的方式运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想计算 mean 或者 median 这种，你想想然后再试试，用哪种方式比较合适呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.1.6 处理空值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总有 None 或者 NaN 值有时候挺烦人的，因为在做机器学习或者是统计数据的时候，你也不能放它在那不管。比如在机器学习中，如果有空值，你要么就选择放弃这条数据， 要么就要对它进行科学的填充，有人用均值有人用中值等。所以上面学到的技巧都能在这里用上。\n",
    "\n",
    "第一，你可能想要先看看你的数据中有没有空值。用下面的 isnull() 或者 notnull() 就能找到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 2, 3, 0],\n",
    "                   [3, 4, None, 1],\n",
    "                   [None, None, None, None],\n",
    "                   [None, 3, None, 4]],\n",
    "                  columns=list(\"ABCD\"))\n",
    "print(df)\n",
    "print(\"\\nisnull():\\n\", df.isnull())  # True 就是空\n",
    "print(\"\\nnotnull()\\n\", df.notnull())  # False 为空"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现这里有空值，下面你就可以对这些 None, Null, NaN 做处理了。要么你就放弃这些有空值的数据，用 dropna()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"默认：\\n\", df.dropna())  # 默认按 axis=0\n",
    "print(\"\\naxis=1:\\n\", df.dropna(axis=1))  # 可以换一个 axis drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，你觉得数据只要有值你就想留下来，只去除掉那些全为空的数据，那么你还能在筛选的时候加一个 how=\"all\" 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame([[None, None, None], [1,None,3]])\n",
    "print(df1.dropna(how=\"all\"))  # how 默认为 \"any\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "刚也说了，除了 drop 掉有 None 的，还可以对这些空值进行填充，填充的值也可以自行选定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(111)  # 填充 111"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对不同特征列做差异化的填充数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3}\n",
    "df.fillna(value=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至，如果你有一个每一位上的默认值，你都可以用一个全新的 df 来做空位的填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(np.arange(16).reshape((4,4)), columns=list(\"ABCD\"))\n",
    "print(\"df2:\\n\", df2)\n",
    "print(\"\\nfillna(df2):\\n\", df.fillna(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.1.7 获取索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，当你想用 np.argmax() 或者 np.argmin() 的时候，你可以在 pandas 用 idxmax() 和 idxmin() 来替换。原理都一样， 就是找到那个最大最小值的索引。这个的好处是，你只关注索引而不用关注值，你可以对这个索引的值做你想要的后续处理。\n",
    "\n",
    "同上面一样，你还能用上面学到的 skipna 来对空值做控制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 2, 3, 0],\n",
    "                   [3, 4, None, 1],\n",
    "                   [3, 5, 2, 1],\n",
    "                   [3, 2, 2, 3]],\n",
    "                  columns=list(\"ABCD\"))\n",
    "print(df)\n",
    "print(\"\\nidxmax():\\n\", df.idxmax())\n",
    "print(\"\\nidxmax(skipna=False):\\n\", df.idxmax(skipna=False))\n",
    "print(\"\\nidxmin():\\n\", df.idxmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：在机器学习或者统计学中，只要你是和数据打交道，就少不了先观察和了解数据。用 Pandas 的这些功能，可以帮你快速了解数据的全貌， 也可以对其中的数据缺失做一些处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22.2 pandas绘制图表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据是服务于人的决策的，我们有一大堆数据，如果人没有真正意义上理解这些数据背后的含义， 那即便数据量再大，它也是无意义的。所以我们今天来探讨一种让人与数据之间构建信息传递桥梁的方法 - 数据可视化技术。 Pandas 中， 就已经可以实现多种多样的数据可视化方案了。\n",
    "\n",
    "我们来看看你拥有的数据可以被 Pandas 表达成什么样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "散点图实际在很多生活场景上都有运用的。比如你要描绘数据 sample 之间与拟合曲线之间呈现的关系，又或者在演示算法是如何进化 ，如何运动的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.2.1 散点图 scatter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Pandas 中，我们有非常方便的办法来直接对 DataFrame 做散点图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n = 1024    # data size\n",
    "df = pd.DataFrame({\n",
    "    \"x\": np.random.normal(0, 1, n),\n",
    "    \"y\": np.random.normal(0, 1, n), \n",
    "})\n",
    "color = np.arctan2(df[\"y\"], df[\"x\"])\n",
    "df.plot.scatter(x=\"x\", y=\"y\", c=color, s=60, alpha=.5, cmap=\"rainbow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "点击运行之后，你会发现可以做出来一幅非常好看的图。当然这里的参数你可以随意搭配，比如试试不写 c=color 或者去掉 cmap=\"rainbow\"， 看看会有何影响。\n",
    "\n",
    "我稍微解释一下几个你可能在乎的参数：\n",
    "\n",
    "c: 对于这组数据中每个（x,y）数据点的颜色值<br>\n",
    "s: 画点的大小（size）<br>\n",
    "alpha：不透明度<br>\n",
    "cmap：colormap，你可以在这里找到非常丰富的案例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.2.2 折线图Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Pandas 中，折线图的绘制方法很简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20    # data size\n",
    "x = np.linspace(-1, 1, n)\n",
    "y = x * 2 + 0.4 + np.random.normal(0, 0.3, n)\n",
    "df = pd.DataFrame({\n",
    "    \"x\": x,\n",
    "    \"y\": y, \n",
    "})\n",
    "df.plot(x=\"x\", y=\"y\", alpha=.5, c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我用最朴素的方法，绘制了一条歪歪扭扭的折线图，来体现它真的很折。你可能很感兴趣，为什么这里的 c 参数传入的数值和上面散点图的不一样？ 原来在折线图中，线的颜色最好是一样的，不然当线多了以后，你会发现不同颜色就看不出到底是那条线了。\n",
    "\n",
    "你肯定会碰到多条线的时候，怎么处理？强大的 Pandas 给你答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20    # data size\n",
    "x = np.linspace(-1, 1, n)\n",
    "y1 = x * -1 - 0.1 + np.random.normal(0, 0.3, n)\n",
    "y2 = x * 2 + 0.4 + np.random.normal(0, 0.3, n)\n",
    "df = pd.DataFrame({\n",
    "    \"x\": x,\n",
    "    \"y1\": y1,\n",
    "    \"y2\": y2, \n",
    "})\n",
    "df.plot(x=\"x\", y=[\"y1\", \"y2\"], alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只要我给多个 y，它就能给出多条线的位置，当然还帮你注明哪个颜色是哪条线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.2.3 条形图Bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做两家公司收入对比，或者是年度值变化的时候，我们也很喜欢用条形图。我们看看 Pandas 的条形图怎么画。 假设有 abc 三家公司，这 5 年的营收对比可以这么画。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.rand(5, 3), columns=[\"a\", \"b\", \"c\"])\n",
    "df.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果把他们放在一起来看占比多少时，我们还能这么干："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "横着不好看，想画一个竖着的图，Pandas 也能轻松做到。你只需要把 bar() 换成 barh() 就好。多出来的这个 h 就是 horizontal 的意思。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.2.4 分布图Hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分布图在机器学习和统计学中非常重要，我经常画分布图，比如要画 神经网络的参数分布可视化。 又或者是 GAN 生成对抗网络当中的数据分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用 plot.hist() 就能画出来了，这里的 hist 是 histogram，也就是分布的意思。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"a\": np.random.randn(1000)})\n",
    "df.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然还会有多个分布重合在一起，你想对比这看看这些分布有无差别的时候，重合度怎么样的时候。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"a\": np.random.randn(1000) + 1,\n",
    "        \"b\": np.random.randn(1000),\n",
    "        \"c\": np.random.randn(1000) - 4,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.plot.hist(alpha=0.5, bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了使你能轻松辨析出 abc 这几个分布的不同，我把 alpha 不透明度调整了一下，让你能看清楚重叠部分。而且 bins 柱状体的数量也调多了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.2.5 饼图Pie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当你想给 Excel 批量话饼图的时候， 你就能结合读取 Excel 的教学，和这一节一起用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\"boss\": np.random.rand(4)},\n",
    "    index=[\"meeting\", \"supervise\", \"teaching\", \"team building\"], \n",
    ")\n",
    "df.plot.pie(y=\"boss\", figsize=(7,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你有多张大饼，想要对比？当然也没问题。可以多加一个 subpots 来分开画饼。legend 是用来确定要不要输出图例的，我这里嫌弃图例占地方， 就设置 legend=False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"bigBoss\": np.random.rand(4),\n",
    "        \"smallBoss\": np.random.rand(4),\n",
    "    },\n",
    "    index=[\"meeting\", \"supervise\", \"teaching\", \"team building\"], \n",
    ")\n",
    "df.plot.pie(subplots=True, figsize=(9,9), legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22.2.6 面积图Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "面积图偶尔你还是会看见的，比如在进化算法中， 就需要使用面积图来观看各个种群的占比随时间的变化情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    np.random.rand(10, 4), \n",
    "    columns=[\"a\", \"b\", \"c\", \"d\"]\n",
    ")\n",
    "df.plot.area()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你不想上下堆砌在一起观看，而是有统一的一个起点，那可以用这个参数 stacked=False。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.area(stacked=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：好了，这节内容也还挺多的，我就先讲到这里。用 Pandas 画图还可以有很多其他花样， 你可以在这里看到更加细节的官方文档。 每种画图功能里面，也还有更多参数可以调整。记得不懂就要多在网上搜搜，多看官方文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23.pandas运算方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们已经提过如何用 Pandas 有效地筛选数据，也知道一些基本的统计学运算方法，而在这一节中， 我们想要关注的是在 Pandas 中如何运算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.1 筛选赋值运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在之前筛选数据的教学中，我们能成功找出数据中的某个部分， 那么针对这个找出的部分，我们对它进行操作也是没问题的。比如下面我们先生成一组数据，然后在对这组数据进行筛选运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = np.arange(-12, 12).reshape((6, 4))\n",
    "df = pd.DataFrame(\n",
    "  data, \n",
    "  index=list(\"abcdef\"), \n",
    "  columns=list(\"ABCD\"))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们在筛选出 A column 出来，对 A column 进行乘以 0 的运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"] *= 0\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看看，新的 df 里面 A column 是不是都变成 0 了！\n",
    "\n",
    "同样，筛选数据教学中，提到的 iloc loc 功能也是可以用来对某数据进行运算的。 以免你忘记，我简单回顾一下，iloc 找的是 index，loc 找的是标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"a\", \"A\"] = 100\n",
    "df.iloc[1, 0] = 200\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看看现在 a row A column 的值是不是被改成了 100， 而第 [1, 0] 位是不是被改成了 200？这只是赋值，现在你拿这些赋值的方法进行运算试试？ 比如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"a\", :] = df.loc[\"a\", :] * 2\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们再来试试按条件运算？下面做的是对于 df[\"A\"], 我要找出 df[\"A\"] 中等于 0 的数，把这些数赋值成 -1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"][df[\"A\"] == 0] = -1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本上，pandas 中可以用于筛选数据的方法都可以用来进一步把筛选出来的数据赋予新的值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.2 Apply方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一种比较方便的批处理数据的方法，我比较喜欢用的是 apply。这是一种可以针对数据做自定义功能的运算。意味着可以简化数据做复杂的功能运算。 上面我们提到的筛选运算，其实是一种简单的运算方式，如果当运算变得复杂，甚至还需要很多局部变量来缓存运算结果，我们就可以尝试把运算过程放置在一个 func 中， 模块化。\n",
    "\n",
    "举个例子，我有下面这批数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我要对这个 df 做全量的平方根计算。 用一般能想到的方式，就会是下面这样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果用 apply，就会变成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们把 np.sqrt 这个函数当成一个参数传入了 apply，看起来好像并没啥用，还不如直接写 np.sqrt(df) 来的方便。的确这个 case 写 np.sqrt(df) 是要简单点。 但是下面这种 case 呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[0] * 2, x[1] * -1\n",
    "\n",
    "df.apply(func, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种极度自定义的功能，对 df 中的每一行，每行第 0 位乘以 2，第 1 位乘以 -1，我们原本的 col0，就都乘了 2，而 col1 就都乘了-1。 提示一下，apply 里面还有不同的参数项可以选，我使用了一个 result_type=\"expand\" 的配置，让输出的结果可以生成多 column，要不然， 会只生成一个 column，所有的结果都写在这一个 column 里。要不你试试取消 result_type，观察一下生成结果的变化。\n",
    "\n",
    "顺带提一下，如果 reult_type=\"broadcast\"，那么原 column 和 index 名会继承到新生成的数据中。仔细对比上下两次的运行，你就能发现不同的表现了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[0] * 2, x[1] * -1\n",
    "\n",
    "df.apply(func, axis=1, result_type='broadcast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么，你只想改一个 column，怎么写？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[\"A\"] * 4\n",
    "\n",
    "df.apply(func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你想还是返回原 df，但只有一个 column 被修改了？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[\"A\"] * 4\n",
    "\n",
    "df[\"A\"] = df.apply(func, axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么，你还想只对 row 进行操作？调一下 axis=0 和 func 里的运算规则。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(r):\n",
    "    return r[2] * 4\n",
    "\n",
    "last_row = df.apply(func, axis=0)\n",
    "print(\"last_row:\\n\", last_row)\n",
    "\n",
    "df.iloc[2, :] = last_row\n",
    "print(\"\\ndf:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：想对数据做特殊的运算，甚至想自定义功能，对数据做批量处理，我们今天就介绍了两大类方法，一种是直接索引-运算，一种是利用 pandas 的 apply 来做更为丰富的运算模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.pandas文字处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相比 Python 的科学运算神器 Numpy，Pandas 还有一个特别优势的地方，那就是处理数据库当中的文字信息。 对比 Numpy，Numpy 是一个纯数据处理的库，在数据处理的速度上， 是要优于 Pandas 的。但是在处理数据的丰富度上，比如要处理文字，日期型数据的时候，Pandas 还是有很大优势的。 今天我们就来看看处理文本数据时，Pandas 可以怎么用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.1 格式化字符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我觉得我需要对标一下 Python 中自带的文字处理功能。 我在 Python 基础内容中也提到，Python 本身就有很多自带的文字函数。 比如 strip() , upper() 等，我们就来对应着学习吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "py_s = \"A,B,C,Aaba,Baca,CABA,dog,cat\"\n",
    "pd_s = pd.Series(\n",
    "    [\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", \"CABA\", \"dog\", \"cat\"],\n",
    "    dtype=\"string\")\n",
    "\n",
    "print(\"python:\\n\", py_s.upper())\n",
    "print(\"\\npandas:\\n\", pd_s.str.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意如果要用到 Pandas 丰富的文字处理功能，你要确保 Series 或者 DataFrame 的 dtype=\"string\"，如果不是 string， 比如我们刚从一个 excel 中读取出来 一个数据，自动读的，没有解析到 string 格式， 我们怎么调整呢？ 其实也简单。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_not_s = pd.Series(\n",
    "    [\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", \"CABA\", \"dog\", \"cat\"],\n",
    ")\n",
    "print(\"pd_not_s type:\", pd_not_s.dtype)\n",
    "pd_s = pd_not_s.astype(\"string\")\n",
    "print(\"pd_s type:\", pd_s.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好，牢记这点，我们接着来对比原生 Python 的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"python lower:\\n\", py_s.lower())\n",
    "print(\"\\npandas lower:\\n\", pd_s.str.lower())\n",
    "print(\"python len:\\n\", [len(s) for s in py_s.split(\",\")])\n",
    "print(\"\\npandas len:\\n\", pd_s.str.len())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再来对比一下对文字的裁剪："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_s = [\"   jack\", \"jill \", \"    jesse    \", \"frank\"]\n",
    "pd_s = pd.Series(py_s, dtype=\"string\")\n",
    "print(\"python strip:\\n\", [s.strip() for s in py_s])\n",
    "print(\"\\npandas strip:\\n\", pd_s.str.strip())\n",
    "\n",
    "print(\"\\n\\npython lstrip:\\n\", [s.lstrip() for s in py_s])\n",
    "print(\"\\npandas lstrip:\\n\", pd_s.str.lstrip())\n",
    "\n",
    "print(\"\\n\\npython rstrip:\\n\", [s.rstrip() for s in py_s])\n",
    "print(\"\\npandas rstrip:\\n\", pd_s.str.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果可能看不清空白符有多少，但是实际上是把空白符都移除掉了。 下面再对比一下 split 拆分方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_s = [\"a_b_c\", \"jill_jesse\", \"frank\"]\n",
    "pd_s = pd.Series(py_s, dtype=\"string\")\n",
    "print(\"python split:\\n\", [s.split(\"_\") for s in py_s])\n",
    "print(\"\\npandas split:\\n\", pd_s.str.split(\"_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "咦，pandas 这样拆分起来怪怪的，把结果都放到了一个 column 里面，我还记得上一节用 apply() 的时候，我可以加一个 result_type=\"expand\"，同样，在 split 中也有类似的功能，可以将拆分出来的结果放到不同的 column 中去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_s.str.split(\"_\", expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，一共拆出了三个 column，但是有些 column 因为没有 split 出那么多值，所以显示的也是 pd.nan\n",
    "\n",
    "这里还有一点我想说，我们上面都是在 Series 里面做实验，其实 DataFrame 也是一样的。 你要做的，只是先选一个 column 或者 row，拿到一个 Series 再开始做 str 的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df = pd.DataFrame([[\"a\", \"b\"], [\"C\", \"D\"]])\n",
    "pd_df.iloc[0, :].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.2 正则方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有如下几个常用功能，需要用到时可查阅具体使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str.contains(); str.match(); str.startswith(); str.endswith()\n",
    "str.replace()\n",
    "str.extract(); str.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24.3 拼接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将两个文本 Series 拼接到一起的方法多种多样。大多情况我们是想结合两个 Series 而形成一个新的 Series。比如下面这样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([\"A\", \"B\", \"C\", \"D\"], dtype=\"string\")\n",
    "s2 = pd.Series([\"1\", \"2\", \"3\", \"4\"], dtype=\"string\")\n",
    "s1.str.cat(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这是将两个文字拼接成新的文字，如果你想了解如何在 pandas 中做 df 的数据上的拼接，比如 2 columns 和 3 columns 的 df 做横向拼接等， 我们会在后面 Pandas 的拼接中专门讲到，因为里面涉及的拼接方法实在是太多了， 在这里讲不完。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：可以看到，文字处理包罗万象，有很多方法。我们挑重点的，调有用的。如果觉得这些对于你还不够， 你可以参考到官方文档，获取到更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25.pandas异常数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "异常数据，我常代指的是机器学习或者是统计分析中的脏数据。为什么他们异常或者脏呢？ 是因为这些数据不符合你期望当中的规律，给你或你的模型带来困扰。而且很可能是收集数据时，\n",
    "\n",
    "因为人工差错、机器传感器差错而导致的数据异常。再或者某一个 sample 的数据没有被采集，这也会引发数据批量处理中的异常。\n",
    "\n",
    "既然数据异常经常发生，又无可避免，我们就来看看如何能找到合适的解决方案。\n",
    "\n",
    "囊括的功能："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找到NaN数据\n",
    "pd.isna(), pd.notna()\n",
    "# NaN的影响\n",
    "# 移除NaN\n",
    "df.dropna()\n",
    "# 填充NaN\n",
    "df.fillna()\n",
    "# 不符合范围的值\n",
    "df.clip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：对于做数据分析，机器学习的你来说，脏数据，异常数据就是一种生活常态，上面是很多有用的工具。需要用到时可对应查阅。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26.pandas处理时间数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么时间序列在有些数据中十分重要呢？ 想想如果你有一批按时间生产的产品，他们的销售业绩和产品质量肯定都绑定在了时间上， 如果哪几天销售好，你也可以回归过来看到底是什么原因导致的，比如节假日，购物节等等。\n",
    "\n",
    "又或者我有一批数据出现了记录异常，比如我的网站在昨天受黑客攻击了， 我要去定位攻击的时间和影响范围，我肯定要在以时间序列记录的 log 中寻找线索。\n",
    "\n",
    "所以时间序列不仅仅是数据的一个维度，而且也是协助数据分析的一个重要标尺。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26.1 读时间序列数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们这里通常说的时间序列是时间点的序列，比如 2022-03-13 12:22:32。看看这些数据是不是常出现在你的报表，或者 log 中？ 我们可以用 Pandas 读取文件的方式把这些带着时间序列的数据读出来， 在让 Pandas 识别这些时间序列，你就能对这些时间序列做很多事情。\n",
    "\n",
    "比如我读出来是这样一份数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"time\": [\"2022/03/12\", \"2022/03/13\", \"2022/03/14\"],\n",
    "    \"value\": [1,2,3]\n",
    "})\n",
    "print(df)\n",
    "print(\"\\n\\ntime:\\n\",df[\"time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，Pandas 是不知道 time 这个 column 是时间序列的（现在认为它是 object）， 我们需要告诉 Pandas 把这个 time 套上时间序列的标识。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df[\"time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，现在它就能把这串 object 数据转换成 datetime[64] 了。这就是 Pandas 当中的 Timestamp 数据类型。 就算我的数据不是按标准格式储存的，它也能尝试帮我识别出来标准的日期格式。可见 Pandas 的强悍之处了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(\n",
    "    [\"2022/03/12\", \"2022.03.13\", \"14/03/2022\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然它这么强悍，而且也能识别出非标准准的日期形式，但是输出的结果真的是你期望的吗？万一有个记录员比较有个性， 它喜欢用 月@日@年%%秒|时|分 这种形式记录日期，这么不规范，咋整？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(\n",
    "    [\n",
    "        \"1@21@2022%%11|11|32\", \n",
    "        \"12@01@2022%%44|02|2\", \n",
    "        \"4@01@2022%%14|22|2\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你试试直接解析看看，会出现什么情况？完蛋了，是不是我们就无法接下这个人留下的烂盘了？Pandas 又来拯救你了。 我们如果同时传入一个时间规则 format，有没有可能让 Pandas 按照我们的特殊规则解析？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(\n",
    "    [\n",
    "        \"1@21@2022%%11|11|32\", \n",
    "        \"12@01@2022%%44|02|2\", \n",
    "        \"4@01@2022%%14|22|2\"\n",
    "    ],\n",
    "    format=\"%m@%d@%Y%%%%%S|%H|%M\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然看起来这串 format 很复杂，但是是可以拆解来看的，他们分别表示的是<br>\n",
    "%m 月<br>\n",
    "%d 日<br>\n",
    "%Y 年的全称<br>\n",
    "%% 比配一个 %<br>\n",
    "%S 秒<br>\n",
    "%H 时<br>\n",
    "%M 分<br>\n",
    "规则太多，记不住？没事， Python 有官方文档 可以参考嘛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26.2 自建时间序列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面我们已经解决了读取到时间序列后，怎么让 Pandas 知道这是时间序列的问题。下面我们如果是要用程序采集数据，比如自己打 log， 或者自己爬虫写日期等等。你要往自己数据库中写日期。介绍一种方式批量生成时间戳。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2022, 3, 12)\n",
    "end = datetime.datetime(2022, 3, 18)\n",
    "\n",
    "index = pd.date_range(start, end)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种写法就有点像 Python 中的 range() 函数，我们可以规定一个起始日期和终止日期，让 pd.date_range() 自动生成。 那你可能会要问了，range() 里面还有一个 step 参数可以用来控制生成的步长的。 pd.date_range() 也可以吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"range(1, 10, 2)\\n\", \n",
    "    list(range(1, 10, 2))\n",
    ")\n",
    "print(\n",
    "    \"\\n\\npd.date_range()\\n\",\n",
    "    pd.date_range(start, end, freq=\"48h\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我也可以做一个打卡表，来看看那些时间点需要去做核酸。只要你想，用 pandas 做一个打卡器也是没问题。 现在你可以在换一下 freq 里面的时间描述，你还可以具体到 1h20min，1D 或者是这里 列举的很多 freq 识别的缩写形式。\n",
    "\n",
    "还有一种在 Numpy 里用的方式 np.linespace()， 这是一种在区间内均匀分割的方法，你也可以用 pd.date_range() 来模拟对日期的分割生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"np.linspace(-1, 1, 5)\\n\",\n",
    "    np.linspace(-1, 1, 5)\n",
    ")\n",
    "print(\n",
    "    \"\\n\\npd.date_range(start, end, periods=5)\\n\",\n",
    "    pd.date_range(start, end, periods=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.date_range() 对于时间个规则性生成还是很友善的。如果你处理工作日比较多，可以参考看看这个 pd.bdate_range() 函数， 它会打开你的眼界。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26.3 选取时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取完数据，生成完数据，也只是对数据的识别而已， 而现在我们要进入对时间数据的选取阶段，来看怎么选数据的问题。 因为有了这个阶段，我们才能真正开始对时间进行运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2022, 3, 1)\n",
    "end = datetime.datetime(2022, 5, 3)\n",
    "\n",
    "rng = pd.date_range(start, end)\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "\n",
    "ts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，我在生成 Series 的时候，把时间序列挂到了 Series 的 index 上，到时候也可以用这个来作为画图的坐标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画图出来，就能发现，横坐标已经打上了时间标签。 如果我们不想要一次性展示这么多数据怎么办？如果我们只想要显示某一周时间的数据怎么办？那直接上分片原则吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[1:8].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接用 index 看起来不好弄？不知道到底 index 对应的是哪个日期区间？没关系，我们试试用时间本身分片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "t1 = datetime.datetime(2022, 3, 12)\n",
    "t2 = datetime.datetime(2022, 3, 18)\n",
    "ts[t1: t2].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还想继续偷懒，我们直接上日期字符串做索引吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[\"2022-03-12\": \"2022-03-18\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至，我们还可以按月按年来，真实懒人的福利啊！比如下面我只想看 3 月的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts[\"2022-03\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas 的用法可为是真的强大，提供的方式真的很多样！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26.4 时间运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选择时间数据也会了，那我们就来看看如何对时间进行运算吧。这通常发生在需要改变日期数值的时候，比如我想复制一份这周的表格，给下周用， 我就直接将这个月 copy 过来，然后日期上加一周时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(\"2022-01-01\", \"2022-01-07\")\n",
    "rng + pd.Timedelta(weeks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timedelta 是一种用于时间加减的时间单位，我们可以个任何一个 Timestamp 加减一个时间。而且 Timedelta 还可以乘除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng + 2*pd.Timedelta(days=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timedelta 除了上面的 weeks, days 参数，还可以用 hours, minutes, seconds, milliseconds, microseconds, nanoseconds 这些。 这样你就能方便的运算时间了。\n",
    "\n",
    "有时候我都觉得用 Pandas 算日期，比用 Python 原生的 datetime 还要方便。比如下面这些："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(\"2022-01-08\", \"2022-01-11\")\n",
    "rng.dayofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上面的方法，再试试这几个：rng.dayofweek; rng.weekofyear; rng.weekday。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.strftime(\"%m/%d/%Y\")  # 按规则输出日期形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用上面的模式，再试试这几个：dt.day_name(); dt.month_name()。\n",
    "\n",
    "当然除了上面的这些方便的转换方法，官方还为我们提供了丰富的转换方式，只要你需要， 你能在这里又发现 Timestamp 转换的一片天地。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26.5 时区"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的操作系统没配置好，有或者你在其他时区，但有想处理另外的时区。那么学会配置 Pandas 的时区就是一件很重要的事。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(\"2022-01-08\", \"2022-01-11\")\n",
    "\n",
    "rng.tz is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认生成的时候，是不带时区的。所以当你要跨半球工作，你在处理 excel 读取出来的时间，或者你自己要控制时间的时候， 你就要特别标注好时区 tz_localize()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.to_datetime(\n",
    "    [\"2022/03/12 22:11\", \"2022/03/12 12:11\", \"2022/03/12 2:11\"]\n",
    ")\n",
    "s_us = s.tz_localize(\"America/New_York\")\n",
    "print(s_us)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我读取到了数据之后，因为老板告诉我这是 New York 时区， 区分于中国时区，我必须先标注是 America/New_York，以防我到时候时间记录错误。 如果要转换到中国时区，我们就可以用下面 tz_convert() 这种方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_cn = s_us.tz_convert(\"Asia/Shanghai\")\n",
    "print(s_cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你问我为什么用 Shanghai 不用 Beijing？因为下面用于时区标记中，没有北京。哈哈。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "pytz.country_timezones('CN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理，你要获取对应的时区名称，你可以用 pytz 这个库来看。 请参考这里的文档。\n",
    "\n",
    "当你自己要生成一批时间的时候，带上时区的方法就比较简单。直接在 pd.date_range() 里带上 tz 的描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = pd.date_range(\n",
    "    \"2022-01-08\", \"2022-01-11\", \n",
    "    tz=\"America/New_York\")\n",
    "print(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：不可不说，时间真是一件大工程，围绕时间的处理工作，我也只介绍了冰山一角。还有很多可以在官方文档中查看到， 比如工作日的计算，很多很丰富，但是我觉得你可能很少用，所以就先不介绍了， 有兴趣的朋友可以看看这里的官方文档， 去探索更加全面的时间处理方式吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27.融合数据 Concat 和 Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据表合并的情况也不罕见，在工作学习中，肯定有需要把表合并处理的时候，比如每个班级收上来一份班级表， 年级主任需要把所有班级表合并，在统一看全年级的情况。我们今天就来见识 Pandas 里面用于合并的多样化处理方式。\n",
    "\n",
    "日常要处理的合并情况还是相对比较简单的，但是 Pandas 提供了非常丰富的合并方案，我觉得也没必要介绍那些偏门的， 先提前知晓，下面的内容是针对我们生活中比较常见的情况，如果下面的方法不能满足你的需求， 可以来看看官方文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍：最简单的拼接无非就是上下左右的拼接，但是你有没有想过，在 Pandas 的 DataFrame 中，我们还有 index 和 column 这东西的存在， 它们的存在是为了我们更好的对应上数据的 index，可以用这些 index 索引和选取数据。那么在拼接的时候，你无时无刻也要关注对齐的影响。我们需不需要让 index 和 column 对齐，如果对不齐，有能怎么办？ 还好 Pandas 早为你想到了这些问题，也提供了很多合适的处理方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27.1 拼接Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\n",
    "    \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "    \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "    \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "    \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "}, index=[0, 1, 2, 3],)\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
    "    \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
    "    \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
    "    \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n",
    "}, index=[4, 5, 6, 7],)\n",
    "\n",
    "\n",
    "df3 = pd.DataFrame({\n",
    "    \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n",
    "    \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n",
    "    \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n",
    "    \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n",
    "}, index=[8, 9, 10, 11],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，我都规定了这三组 df 拥有不相冲突的 index，但是相同的 column 名，我们把它们进行上下拼接看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2, df3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设上面是三个不同班级的学生信息，如果你还是想带上班级的索引栏，你可以给他们加上一个主 key。比如 xyz 三个不同班。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes = pd.concat(\n",
    "    [df1, df2, df3], \n",
    "    keys=[\"x\", \"y\", \"z\"])\n",
    "print(all_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样你索引的时候，还是可以按班级来索引。这样可以既不破坏原本的 df 结构，又不丢失不同 df 的组织状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes.loc[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.concat 的默认是上下拼接的，我们也可以指定进行左右拼接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({\n",
    "    \"B\": [\"B2\", \"B3\", \"B6\", \"B7\"],\n",
    "    \"D\": [\"D2\", \"D3\", \"D6\", \"D7\"],\n",
    "    \"F\": [\"F2\", \"F3\", \"F6\", \"F7\"],\n",
    "}, index=[2, 3, 6, 7],)\n",
    "\n",
    "pd.concat([df1, df4], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，我这里故意没有对齐他们的 index。 你仔细观察的话，df1 和 df4 不是完全标齐的 index 和 column， 但是他们还是可以拼接的，只是拼接的时候 pandas 会自动将缺失的部分填充成 NaN。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实这种模式叫做 join=\"outer\" 的方式（默认方式）， 中文的话，就叫它外拼接吧。与其对应的，只留下对齐后的 index 和 column 模式， 我们可以用内拼接 join=\"inner\"。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df4], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有内外拼接，说明你十分关注重组后的数据 index，但是有的时候，我们的确不会关注新数据的 index 对齐。 与其保留老数据的索引，我还不如搞一个全新索引，直接覆盖了，不管以前了。用 ignore_index 就可以。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [df1, df4], \n",
    "    ignore_index=True, \n",
    "    sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前讲 pandas DataFrame 结构和基础操作的时候. 同学们可能会有这样一个疑问，我们怎么像 Numpy 或者 Python List 那样，append 数据进来呢？那这节数据拼接内容就来告诉你，可以用 concat。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col = pd.Series(\n",
    "    [\"X0\", \"X1\", \"X2\", \"X3\"], name=\"X\")\n",
    "pd.concat([df1, new_col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我把一条新的 col X 数据拼接到了 df1 的最右边。同样，如果你要向下 append 的话，首先你要有一条对应的 Series 数据。 然后 pd.concat 时选用 axis=0 进行上下拼接。但是 Pandas 不会帮你自动判断 添加 Series 的维度信息。这里还需要你手动将 Series 转化 .to_frame() 成 df，并调整 df 的维度信息，才能正常拼接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = pd.Series(\n",
    "    [\"X0\", \"X1\", \"X2\", \"X3\"],\n",
    "    index=[\"A\", \"B\", \"C\", \"D\"])\n",
    "pd.concat(\n",
    "    [df1, new_row.to_frame().T], \n",
    "    ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做一个类似 Python list append 的操作这么麻烦的吗！！ 当然不是，你也可以用一个简单的 append 搞定。两者出来是一样的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.concat() 我觉得已经能满足我们日常生活中的大部分拼接任务了。不过 Pandas 知道你肯定还有特殊需求， 比如在拼接的时候，到底要基于哪边 df 的 index？要不要添加特殊的新 col 名等等。所以它还给了一个更加细节的 pd.merge() 函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27.2 融合Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，如果你十分熟悉 SQL 语言那一套，merge 就非常适合你，其他的小伙伴，我觉得只有你发现 concat 不能解决你的问题的时候， 在过来看看 merge 能不能。因为 merge 还是比 concat 稍微复杂一点的。比如光是 join 的方式，就比 concat 多出了 3 种。\n",
    "\n",
    "注意，concat 可以一次性合并多个 df，可以【左右】，也可以【上下】拼接， 但是 merge 是用来针对两张 df 做【左右】拼接的。 但是如果你真的懂 merge 的功能，也许你会更喜欢用 merge。\n",
    "\n",
    "重要的事说三遍，merge 只做左右拼接。左右拼接。左右拼接。需要用到时可参考官方文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27.3 接入Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "join 其实是 df.join()。 但是它其实更像是 merge 和 concat 的某种结合体，merge() 是基于给定的某个 on=\"key\" 来拼接， 而 df.join() 使用的 key 可以和 concat() 一样，都是 index，也可以像 merge() 带一个 on=\"key\" 去使用一个 column 作为索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\n",
    "    \"A\": [\"A0\", \"A1\", \"A2\"], \n",
    "    \"B\": [\"B0\", \"B1\", \"B2\"]\n",
    "}, index=[\"K0\", \"K1\", \"K2\"])\n",
    "\n",
    "\n",
    "right = pd.DataFrame({\n",
    "    \"C\": [\"C0\", \"C2\", \"C3\"], \n",
    "    \"D\": [\"D0\", \"D2\", \"D3\"]\n",
    "}, index=[\"K0\", \"K2\", \"K3\"])\n",
    "\n",
    "left.join(right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.join() 的时候默认是使用 how=\"left\" 的。你可以在上面尝试将 how 这个参数明确出来，写不同的 join 方式， 比如 ‘left’, ‘right’, ‘outer’, ‘inner’。\n",
    "\n",
    "使用 key 作为 join 依据的时候，你可以这样使用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\n",
    "    \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "    \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "    \"key\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n",
    "})\n",
    "\n",
    "\n",
    "right = pd.DataFrame({\n",
    "    \"C\": [\"C0\", \"C1\"],\n",
    "    \"D\": [\"D0\", \"D1\"]\n",
    "}, index=[\"K0\", \"K1\"])\n",
    "\n",
    "left.join(right, on=\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：以上介绍了三种 pandas 中常用来合并数据的方式，concat，merge，join 他们的规则还是挺多的， 我也挑了一些重要的来讲解，如果你发现上面的合并方式还不能解决你的问题，你可以查看一下官方的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28.数据分组 Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据有关键词、每个数据带有特定类别？我们怎样可以快速找到对应的类别，聚类分析？\n",
    "\n",
    "Pandas 中就有提供这样便捷的功能，groupby()。简单来说，groupby 就是提前帮你准备好快筛功能， 在你想要筛选特定数据的时候，快速帮你找到对应的数据块。 而且还可以针对不同 group 做不同的数据处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.1 分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 groupby() 最核心的功能，自然就是将可以被归纳的数据进行归纳汇总。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        (\"小红\", \"哈利波特\", 80),\n",
    "        (\"小明\", \"蜘蛛侠\", 72),\n",
    "        (\"小红\", \"雷神\", 83),\n",
    "        (\"小红\", \"蜘蛛侠\", 45),\n",
    "        (\"小明\", \"超人\", 57),\n",
    "    ],\n",
    "    columns=(\"人\", \"人物\", \"评价\"),\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如我有上面这组数据，描述了每个人对人物的评价。这组数据的形成可能就是一段时间内，收集了不同人对各种人物的评价，所以它的组织顺序会比较乱。 好在我们还可以用 groupby 来重组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(\"人\")\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面我们就获取了 Pandas 当中的 group 类，再看看这个 grouped 当中究竟是怎么组织我们的数据的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你会发现，它保存的其实是不同 人 的 row index, 这样后面重新在找 group 组的时候，可以快速用 index 找到对应行。 要直接获取不同的 人 组，我们看看怎么搞？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[grouped.groups[\"小红\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对，上面的确是一种我们用以前学的知识就能找到的办法，不过 懒人工具 pandas 怎么能让我们这么费力呢？ 所以它直接能在 grouped 的基础上，get_group()。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.get_group(\"小红\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你看，这上下两种方法其实可以达到一样的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.2 调用分好的组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了 grouped.get_group()，其实还有更多方式来获取到分好的组，应对你不同的应用需求。 而这些不同的筛选方法，其实本质还是在对 grouped.groups 中的 index 进行操作的一个过程。 比如如果我要选第一个数据，pandas 就会调用 groups 里面的第一个 index。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，它会返回给你每一个组的第一个数据，而如果我要找最后一个，也是同样的逻辑。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "甚至你还可以做一些聚合操作，比如对每一个组里面的数据进行 sum, mean 等操作。你可以在下面的执行区都试试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.3 循环处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候你想要对组进行循环处理，通过一个循环最所有组统一操作一下。那你需要注意一下这个 grouped 的循环，会带着两个字段做循环。 一个是组名，一个是组数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in grouped:\n",
    "    print(\"name:\", name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.4 多重分组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据真的很多，在不同分组后，我们还想对另一 column 的值也进行分组？ 比如小红今天再看了一遍雷神，觉得雷神今年的表现不错，对雷神做了一次新的高分评价。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "        (\"小红\", \"哈利波特\", 80),\n",
    "        (\"小明\", \"蜘蛛侠\", 72),\n",
    "        (\"小红\", \"雷神\", 83),\n",
    "        (\"小红\", \"雷神\", 90),\n",
    "        (\"小红\", \"蜘蛛侠\", 45),\n",
    "        (\"小明\", \"超人\", 57),\n",
    "    ],\n",
    "    columns=(\"人\", \"人物\", \"评价\"),\n",
    ")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这时，小红数据中就会有两次雷神的评价了。如果这类的事情发生很多，我们也可以深入划分一下细分领域的组信息。 比如我按照 人 和 人物 进行分组，而且选择 小红 的 雷神 评分进行查看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"人\", \"人物\"]).get_group((\"小红\", \"雷神\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28.5 聚合计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对选出来的数据，有时候你并不仅仅只是为了用眼直接看，你还想要对筛选出来的数据进行统计学上的运算。比如上面我举的 grouped.sum() 这个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "grouped = df.groupby(\"人\")\n",
    "grouped.aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想要对数据一次性做更多的计算，你可以多加几个要计算的操作在后面，比如 [sum, mean, std]，注意下面的 .agg() 其实是 .aggregate() 的缩写， 它俩是一样的。下面我们就对每组的 评价 指标进行一次性的多种运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[\"评价\"].agg([np.sum, np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有一个小技巧，如果你不喜欢用英文表达，或者你想要用另外一个名字来描述 column，你可以用 rename 来重新命名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped[\"评价\"].agg(\n",
    "    [np.sum, np.mean, np.std]\n",
    ").rename(columns={\n",
    "    \"sum\": \"合\", \n",
    "    \"mean\": \"均值\", \n",
    "    \"std\": \"标准差\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：我以前在用 Excel 的时候（查 log），经常会用分组来筛选观看数据，现在如果我有了固定的需求， 我完全可以将这些手动 Excel 查 log 的行为自动化到 Python 让它自动帮我完成。你在有同样需求的情况下，也要记得考虑能否用 Pandas 来帮你减负哦。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29.多索引数据 Multi-Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据记录在数据表时，特别是数据归类比较复杂的情况， 比如年级-班级-学生信息这种层级的记录，我们很可能要使用到合并单元格。 我们把这种模式叫做 Multi-Indexing 多索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多索引在表格展示的时候，对数据规范化非常有利，所以如果你需要用表格来观察数据，是可以用这种形式来组织数据的。 但是如果你要做机器学习或频繁的数据加工时，我肯定不喜欢这样的数据组成方式，因为会让加工难度变高，成本变高。 所以你也可以想想，自己什么时候需要 Multi-Indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29.1 构建Row多索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假如我们有这样一组学生的名字数据，想要对它进行多索引分配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(\n",
    "  [\"小米\", \"小明\",      # 一年一班\n",
    "   \"小命\", \"小勉\",      # 一年二班\n",
    "   \"小牛\", \"小鸟\",      # 二年一班\n",
    "   \"小南\", \"小妮\"       # 二年二班\n",
    "   ], name=\"name\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些是 一年级 的，有些是 二年级 的。而且还分到的不同年级的不同班。 所以我们要给他们分配两个索引，年级，班级，班级在年级下面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [\n",
    "  # 年级，班级\n",
    "  (\"one\", \"1\"),\n",
    "  (\"one\", \"1\"),\n",
    "  (\"one\", \"2\"),  (\"one\", \"2\"),\n",
    "  (\"two\", \"1\"),\n",
    "  (\"two\", \"1\"),\n",
    "  (\"two\", \"2\"),\n",
    "  (\"two\", \"2\"),\n",
    "]\n",
    "index = pd.MultiIndex.from_tuples(\n",
    "  tuples, names=[\"grade\", \"class\"])\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了这些索引，我们就能在刚刚构建 Series 的基础上，把 Multi-Index 给加上去了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(\n",
    "    [\"小米\", \"小明\",      # 一年一班\n",
    "     \"小命\", \"小勉\",      # 一年二班\n",
    "     \"小牛\", \"小鸟\",      # 二年一班\n",
    "     \"小南\", \"小妮\"       # 二年二班\n",
    "     ], \n",
    "    name=\"name\",\n",
    "    index=index)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想获取刚刚构建的 Series 索引，可以直接调用 s.index 来看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其实上面构建索引的方式还略微有点复杂，在年级班级的情况下，我们可以分级来构建索引，第一层级是年级，下面层级是每个学生所在的班级。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterables = [\n",
    "  [\"one\", \"two\"],  # 年级\n",
    "  [\"1\", \"1\", \"2\", \"2\"]  # 每个学生所在班级\n",
    "]\n",
    "\n",
    "index2 = pd.MultiIndex.from_product(\n",
    "  iterables, names=[\"grade\", \"class\"])\n",
    "print(index2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样构建的 index2 和上面刚刚构建的 index 数值上是一模一样的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = pd.Series(\n",
    "    [\"小米\", \"小明\",      # 一年一班\n",
    "     \"小命\", \"小勉\",      # 一年二班\n",
    "     \"小牛\", \"小鸟\",      # 二年一班\n",
    "     \"小南\", \"小妮\"       # 二年二班\n",
    "     ], \n",
    "    name=\"name\",\n",
    "    index=index2)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候你都不是用 Python 列表或者是元组来保存这些索引数据，你的索引数据也维护在一张 DataFrame 中。还别说，考虑一些业务逻辑的话， 还真有分开用不用表来维护的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    [\n",
    "    # 年级，班级\n",
    "    (\"one\", \"1\"),\n",
    "    (\"one\", \"1\"),\n",
    "    (\"one\", \"2\"),\n",
    "    (\"one\", \"2\"),\n",
    "    (\"two\", \"1\"),\n",
    "    (\"two\", \"1\"),\n",
    "    (\"two\", \"2\"),\n",
    "    (\"two\", \"2\"),\n",
    "    ],\n",
    "    columns=[\"grade\", \"class\"]\n",
    ")\n",
    "\n",
    "index3 = pd.MultiIndex.from_frame(df)\n",
    "print(index3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再来看看拼接起来是不是一样的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = pd.Series(\n",
    "    [\"小米\", \"小明\",      # 一年一班\n",
    "     \"小命\", \"小勉\",      # 一年二班\n",
    "     \"小牛\", \"小鸟\",      # 二年一班\n",
    "     \"小南\", \"小妮\"       # 二年二班\n",
    "     ], \n",
    "    name=\"name\",\n",
    "    index=index3)\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29.2 构建DataFrame多索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "刚刚做的都是 Series 的 Multi-Index 构建，我们再来举一个 DataFrame 的例子。这个表记录了学生的学号和姓名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    {\"id\": [11,12,13,14,15,16,17,18],\n",
    "    \"name\": \n",
    "     [\"小米\", \"小明\",      # 一年一班\n",
    "     \"小命\", \"小勉\",      # 一年二班\n",
    "     \"小牛\", \"小鸟\",      # 二年一班\n",
    "     \"小南\", \"小妮\"       # 二年二班\n",
    "    ]},\n",
    "    index=index)\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29.3 构建Column多索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果能构建 Row 的多索引，当然可以对 Column 做多索引配置。 假设我还是用上一个例子，只是把他们的行列对调一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    [[11,12,13,14,15,16,17,18],\n",
    "     [\"小米\", \"小明\",      # 一年一班\n",
    "     \"小命\", \"小勉\",      # 一年二班\n",
    "     \"小牛\", \"小鸟\",      # 二年一班\n",
    "     \"小南\", \"小妮\"       # 二年二班\n",
    "    ]],\n",
    "    index=[\"id\", \"name\"])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给它加上 Row 的 index，就相当于把原本的 Multi index 加到 columns 参数里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(\n",
    "    [[11,12,13,14,15,16,17,18],\n",
    "     [\"小米\", \"小明\",      # 一年一班\n",
    "     \"小命\", \"小勉\",      # 一年二班\n",
    "     \"小牛\", \"小鸟\",      # 二年一班\n",
    "     \"小南\", \"小妮\"       # 二年二班\n",
    "    ]],\n",
    "    index=[\"id\", \"name\"],\n",
    "    columns=index,  # 多索引加这\n",
    ")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29.4 选择数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "说了这么多构建多索引的方法，想必如果要你生成一张表保存下来，你已经没问题了。 但如果是要拿到一张多索引的表，要把里面的数据拿出来再加工呢？\n",
    "\n",
    "这就需要我们会使用 pandas 的方法读多索引表了。 其实也不难，和正常读取选择数据非常像。\n",
    "\n",
    "假设我们用的是下面这组数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(\n",
    "    [[11,12,13,14,15,16,17,18],\n",
    "     [\"小米\", \"小明\",      # 一年一班\n",
    "     \"小命\", \"小勉\",      # 一年二班\n",
    "     \"小牛\", \"小鸟\",      # 二年一班\n",
    "     \"小南\", \"小妮\"       # 二年二班\n",
    "    ]],\n",
    "    index=[\"id\", \"name\"],\n",
    "    columns=index,  # 多索引加这\n",
    ")\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取一年级的所有学生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"one\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再往下一级，选取一年级 1 班的所有学生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"one\"][\"1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那如果是在 Row 上多索引呢？我们还是可以像以前选取数据那样， 使用 .loc[] 来所筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame(\n",
    "    {\"id\": [11,12,13,14,15,16,17,18],\n",
    "    \"name\": \n",
    "     [\"小米\", \"小明\",      # 一年一班\n",
    "     \"小命\", \"小勉\",      # 一年二班\n",
    "     \"小牛\", \"小鸟\",      # 二年一班\n",
    "     \"小南\", \"小妮\"       # 二年二班\n",
    "    ]},\n",
    "    index=index)\n",
    "print(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就是用 .loc[] 来所筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.loc[\"one\"].loc[\"2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：到此，我们发现，数据表除了单 Column 和 单 Row 的索引方式，还可以在 Column 和 Row 上组建多层级的索引模式。 而且也不会影响我们日常从这种多索引的表格中获取数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四部分：matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30.matplotlib简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.1 为什么用matplotlib？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果某天你发现自己要学习 Matplotlib, 很可能是因为:\n",
    "\n",
    "Matplotlib 是一个非常强大的 Python 画图工具;<br>\n",
    "手中有很多数据, 可是不知道该怎么呈现这些数据。<br>\n",
    "所以就找到了 Matplotlib. 它能帮你画出美丽的:\n",
    "\n",
    "1.线图;<br>\n",
    "2.散点图;<br>\n",
    "3.等高线图;<br>\n",
    "4.条形图;<br>\n",
    "5.柱状图;<br>\n",
    "6.3D 图形;<br>\n",
    "7.甚至是图形动画等等."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 30.2 安装matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminal（终端）运行：pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 31.基本使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.1 基础应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用import导入模块matplotlib.pyplot，并简写成plt 使用import导入模块numpy，并简写成np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用np.linspace定义x：范围是(-1,1);个数是50. 仿真一维数据组(x ,y)表示曲线1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 50)\n",
    "y = 2*x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.figure定义一个图像窗口. 使用plt.plot画(x ,y)曲线. 使用plt.show显示图像."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.2 figure 图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib 的 figure 就是一个 单独的 figure 小窗口, 小窗口里面还可以有更多的小图片.\n",
    "\n",
    "使用import导入模块matplotlib.pyplot，并简写成plt 使用import导入模块numpy，并简写成np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用np.linspace定义x：范围是(-3,3);个数是50. 仿真一维数据组(x ,y1)表示曲线1. 仿真一维数据组(x ,y2)表示曲线2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 50)\n",
    "y1 = 2*x + 1\n",
    "y2 = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.figure定义一个图像窗口. 使用plt.plot画(x ,y1)曲线."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, y1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.figure定义一个图像窗口：编号为3；大小为(8, 5). 使用plt.plot画(x ,y2)曲线. 使用plt.plot画(x ,y1)曲线，曲线的颜色属性(color)为红色;曲线的宽度(linewidth)为1.0；曲线的类型(linestyle)为虚线. 使用plt.show显示图像."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num=3, figsize=(8, 5),)\n",
    "plt.plot(x, y2)\n",
    "plt.plot(x, y1, color='red', linewidth=1.0, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.3 设置坐标轴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 matplotlib 中如何设置坐标轴的范围, 单位长度, 替代文字，移动matplotlib 中 axis 坐标轴的位置.等等."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.3.1 调整名字和间隔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用import导入模块matplotlib.pyplot，并简写成plt 使用import导入模块numpy，并简写成np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用np.linspace定义x：范围是(-3,3);个数是50. 仿真一维数据组(x ,y1)表示曲线1. 仿真一维数据组(x ,y2)表示曲线2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 50)\n",
    "y1 = 2*x + 1\n",
    "y2 = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.figure定义一个图像窗口. 使用plt.plot画(x ,y2)曲线. 使用plt.plot画(x ,y1)曲线，曲线的颜色属性(color)为红色;曲线的宽度(linewidth)为1.0；曲线的类型(linestyle)为虚线."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, y2)\n",
    "plt.plot(x, y1, color='red', linewidth=1.0, linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.xlim设置x坐标轴范围：(-1, 2)； 使用plt.ylim设置y坐标轴范围：(-2, 3)； 使用plt.xlabel设置x坐标轴名称：'I am x'； 使用plt.ylabel设置y坐标轴名称：'I am y'；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim((-1, 2))\n",
    "plt.ylim((-2, 3))\n",
    "plt.xlabel('I am x')\n",
    "plt.ylabel('I am y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用np.linspace定义范围以及个数：范围是(-1,2);个数是5. 使用print打印出新定义的范围. 使用plt.xticks设置x轴刻度：范围是(-1,2);个数是5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ticks = np.linspace(-1, 2, 5)\n",
    "print(new_ticks)\n",
    "plt.xticks(new_ticks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.yticks设置y轴刻度以及名称：刻度为[-2, -1.8, -1, 1.22, 3]；对应刻度的名称为['really bad','bad','normal','good', 'really good']. 使用plt.show显示图像."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yticks([-2, -1.8, -1, 1.22, 3],[r'$really\\ bad$', r'$bad$', r'$normal$', r'$good$', r'$really\\ good$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.3.2 设置不同名字和位置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用import导入模块matplotlib.pyplot，并简写成plt 使用import导入模块numpy，并简写成np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用np.linspace定义x：范围是(-3,3);个数是50. 仿真一维数据组(x ,y1)表示曲线1. 仿真一维数据组(x ,y2)表示曲线2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 50)\n",
    "y1 = 2*x + 1\n",
    "y2 = x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.figure定义一个图像窗口. 使用plt.plot画(x ,y2)曲线. 使用plt.plot画(x ,y1)曲线，曲线的颜色属性(color)为红色;曲线的宽度(linewidth)为1.0；曲线的类型(linestyle)为虚线. 使用plt.xlim设置x坐标轴范围：(-1, 2)； 使用plt.ylim设置y坐标轴范围：(-2, 3)；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, y2)\n",
    "plt.plot(x, y1, color='red', linewidth=1.0, linestyle='--')\n",
    "plt.xlim((-1, 2))\n",
    "plt.ylim((-2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用np.linspace定义范围以及个数：范围是(-1,2);个数是5. 使用plt.xticks设置x轴刻度：范围是(-1,2);个数是5. 使用plt.yticks设置y轴刻度以及名称：刻度为[-2, -1.8, -1, 1.22, 3]；对应刻度的名称为['really bad','bad','normal','good', 'really good']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ticks = np.linspace(-1, 2, 5)\n",
    "plt.xticks(new_ticks)\n",
    "plt.yticks([-2, -1.8, -1, 1.22, 3],['$really\\ bad$', '$bad$', '$normal$', '$good$', '$really\\ good$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.gca获取当前坐标轴信息. 使用.spines设置边框：右侧边框；使用.set_color设置边框颜色：默认白色； 使用.spines设置边框：上边框；使用.set_color设置边框颜色：默认白色；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.3.3 调整坐标轴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用.xaxis.set_ticks_position设置x坐标刻度数字或名称的位置：bottom.（所有位置：top，bottom，both，default，none）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.xaxis.set_ticks_position('bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用.spines设置边框：x轴；使用.set_position设置边框位置：y=0的位置；（位置所有属性：outward，axes，data）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用.yaxis.set_ticks_position设置y坐标刻度数字或名称的位置：left.（所有位置：left，right，both，default，none）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.yaxis.set_ticks_position('left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用.spines设置边框：y轴；使用.set_position设置边框位置：x=0的位置；（位置所有属性：outward，axes，data） 使用plt.show显示图像."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.spines['left'].set_position(('data',0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y1 = 2*x + 1\n",
    "y2 = x**2\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y2)\n",
    "# plot the second curve in this figure with certain parameters\n",
    "plt.plot(x, y1, color='red', linewidth=1.0, linestyle='--')\n",
    "# set x limits\n",
    "plt.xlim((-1, 2))\n",
    "plt.ylim((-2, 3))\n",
    "\n",
    "# set new ticks\n",
    "new_ticks = np.linspace(-1, 2, 5)\n",
    "plt.xticks(new_ticks)\n",
    "# set tick labels\n",
    "plt.yticks([-2, -1.8, -1, 1.22, 3],\n",
    "           ['$really\\ bad$', '$bad$', '$normal$', '$good$', '$really\\ good$'])\n",
    "# to use '$ $' for math text and nice looking, e.g. '$\\pi$'\n",
    "\n",
    "# gca = 'get current axis'\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "# ACCEPTS: [ 'top' | 'bottom' | 'both' | 'default' | 'none' ]\n",
    "\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "# the 1st is in 'outward' | 'axes' | 'data'\n",
    "# axes: percentage of y axis\n",
    "# data: depend on y data\n",
    "\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "# ACCEPTS: [ 'left' | 'right' | 'both' | 'default' | 'none' ]\n",
    "\n",
    "ax.spines['left'].set_position(('data',0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.4 Legend 图例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.4.1 添加图例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib 中的 legend 图例就是为了帮我们展示出每个数据对应的图像名称. 更好的让读者认识到你的数据结构.\n",
    "\n",
    "上节内容我们了解到关于坐标轴设置方面的一些内容，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y1 = 2*x + 1\n",
    "y2 = x**2\n",
    "\n",
    "plt.figure()\n",
    "#set x limits\n",
    "plt.xlim((-1, 2))\n",
    "plt.ylim((-2, 3))\n",
    "\n",
    "# set new sticks\n",
    "new_sticks = np.linspace(-1, 2, 5)\n",
    "plt.xticks(new_sticks)\n",
    "# set tick labels\n",
    "plt.yticks([-2, -1.8, -1, 1.22, 3],\n",
    "           [r'$really\\ bad$', r'$bad$', r'$normal$', r'$good$', r'$really\\ good$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节中我们将对图中的两条线绘制图例，首先我们设置两条线的类型等信息（蓝色实线与红色虚线)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set line syles\n",
    "l1, = plt.plot(x, y1, label='linear line')\n",
    "l2, = plt.plot(x, y2, color='red', linewidth=1.0, linestyle='--', label='square line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "legend将要显示的信息来自于上面代码中的 label. 所以我们只需要简单写下一下代码, plt 就能自动的为我们添加图例."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参数 loc='upper right' 表示图例将添加在图中的右上角."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.4.2 调整位置和名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们想单独修改之前的 label 信息, 给不同类型的线条设置图例信息. 我们可以在 plt.legend 输入更多参数. 如果以下面这种形式添加 legend, 我们需要确保, 在上面的代码 plt.plot(x, y2, label='linear line') 和 plt.plot(x, y1, label='square line') 中有用变量 l1 和 l2 分别存储起来. 而且需要注意的是 l1, l2,要以逗号结尾, 因为plt.plot() 返回的是一个列表."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.legend(handles=[l1, l2], labels=['up', 'down'],  loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样我们就能分别重新设置线条对应的 label 了.最后我们得到带有图例信息的图片."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中'loc'参数有多种，'best'表示自动分配最佳位置，其余的如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 'best' : 0,          \n",
    " 'upper right'  : 1,\n",
    " 'upper left'   : 2,\n",
    " 'lower left'   : 3,\n",
    " 'lower right'  : 4,\n",
    " 'right'        : 5,\n",
    " 'center left'  : 6,\n",
    " 'center right' : 7,\n",
    " 'lower center' : 8,\n",
    " 'upper center' : 9,\n",
    " 'center'       : 10,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y1 = 2*x + 1\n",
    "y2 = x**2\n",
    "\n",
    "plt.figure()\n",
    "# set x limits\n",
    "plt.xlim((-1, 2))\n",
    "plt.ylim((-2, 3))\n",
    "\n",
    "# set new sticks\n",
    "new_sticks = np.linspace(-1, 2, 5)\n",
    "plt.xticks(new_sticks)\n",
    "# set tick labels\n",
    "plt.yticks([-2, -1.8, -1, 1.22, 3],\n",
    "           [r'$really\\ bad$', r'$bad$', r'$normal$', r'$good$', r'$really\\ good$'])\n",
    "\n",
    "l1, = plt.plot(x, y1, label='linear line')\n",
    "l2, = plt.plot(x, y2, color='red', linewidth=1.0, linestyle='--', label='square line')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "# plt.legend(handles=[l1, l2], labels=['up', 'down'],  loc='best')\n",
    "# the \",\" is very important in here l1, = plt... and l2, = plt... for this step\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.5 Annotation 标注"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.5.1 画出基本图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当图线中某些特殊地方需要标注时，我们可以使用 annotation. matplotlib 中的 annotation 有两种方法， 一种是用 plt 里面的 annotate，一种是直接用 plt 里面的 text 来写标注.\n",
    "\n",
    "首先，我们在坐标轴中绘制一条直线."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y = 2*x + 1\n",
    "\n",
    "plt.figure(num=1, figsize=(8, 5),)\n",
    "plt.plot(x, y,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.5.2 移动坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们挪动坐标轴的位置."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['left'].set_position(('data', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后标注出点(x0, y0)的位置信息. 用plt.plot([x0, x0,], [0, y0,], 'k--', linewidth=2.5) 画出一条垂直于x轴的虚线."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1\n",
    "y0 = 2*x0 + 1\n",
    "plt.plot([x0, x0,], [0, y0,], 'k--', linewidth=2.5)\n",
    "# set dot styles\n",
    "plt.scatter([x0, ], [y0, ], s=50, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.5.3 添加注释 annotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们就对(x0, y0)这个点进行标注."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.annotate(r'$2x+1=%s$' % y0, xy=(x0, y0), xycoords='data', xytext=(+30, -30),\n",
    "             textcoords='offset points', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中参数xycoords='data' 是说基于数据的值来选位置, xytext=(+30, -30) 和 textcoords='offset points' 对于标注位置的描述 和 xy 偏差值, arrowprops是对图中箭头类型的一些设置."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.5.4 添加注释 text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.text(-3.7, 3, r'$This\\ is\\ the\\ some\\ text. \\mu\\ \\sigma_i\\ \\alpha_t$',\n",
    "         fontdict={'size': 16, 'color': 'r'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中-3.7, 3,是选取text的位置, 空格需要用到转字符\\,fontdict设置文本字体."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y = 2*x + 1\n",
    "\n",
    "plt.figure(num=1, figsize=(8, 5),)\n",
    "plt.plot(x, y,)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "\n",
    "x0 = 1\n",
    "y0 = 2*x0 + 1\n",
    "plt.plot([x0, x0,], [0, y0,], 'k--', linewidth=2.5)\n",
    "plt.scatter([x0, ], [y0, ], s=50, color='b')\n",
    "\n",
    "# method 1:\n",
    "#####################\n",
    "plt.annotate(r'$2x+1=%s$' % y0, xy=(x0, y0), xycoords='data', xytext=(+30, -30),\n",
    "             textcoords='offset points', fontsize=16,\n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle=\"arc3,rad=.2\"))\n",
    "\n",
    "# method 2:\n",
    "########################\n",
    "plt.text(-3.7, 3, r'$This\\ is\\ the\\ some\\ text. \\mu\\ \\sigma_i\\ \\alpha_t$',\n",
    "         fontdict={'size': 16, 'color': 'r'})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 31.6 tick 能见度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.6.1 生成图形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当图片中的内容较多，相互遮盖时，我们可以通过设置相关内容的透明度来使图片更易于观察，也即是通过本节中的bbox参数设置来调节图像信息.\n",
    "\n",
    "首先参考之前的例子, 我们先绘制图像基本信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y = 0.1*x\n",
    "\n",
    "plt.figure()\n",
    "# 在 plt 2.0.2 或更高的版本中, 设置 zorder 给 plot 在 z 轴方向排序\n",
    "plt.plot(x, y, linewidth=10, zorder=1)\n",
    "plt.ylim(-2, 2)\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['left'].set_position(('data', 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 31.6.2 调整坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后对被遮挡的图像调节相关透明度，本例中设置 x轴 和 y轴 的刻度数字进行透明度设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "    label.set_fontsize(12)\n",
    "    # 在 plt 2.0.2 或更高的版本中, 设置 zorder 给 plot 在 z 轴方向排序\n",
    "    label.set_bbox(dict(facecolor='white', edgecolor='None', alpha=0.7, zorder=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中label.set_fontsize(12)重新调节字体大小，bbox设置目的内容的透明度相关参，facecolor调节 box 前景色，edgecolor 设置边框， 本处设置边框为无，alpha设置透明度."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(-3, 3, 50)\n",
    "y = 0.1*x\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y, linewidth=10, zorder=1)      # set zorder for ordering the plot in plt 2.0.2 or higher\n",
    "plt.ylim(-2, 2)\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "ax.spines['bottom'].set_position(('data', 0))\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.spines['left'].set_position(('data', 0))\n",
    "\n",
    "\n",
    "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "    label.set_fontsize(12)\n",
    "    # set zorder for ordering the plot in plt 2.0.2 or higher\n",
    "    label.set_bbox(dict(facecolor='white', edgecolor='none', alpha=0.8, zorder=2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32.画图种类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32.1 散点图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，先引入matplotlib.pyplot简写作plt,再引入模块numpy用来产生一些随机数据。生成1024个呈标准正态分布的二维数据组 (平均数是0，方差为1) 作为一个数据集，并图像化这个数据集。每一个点的颜色值用T来表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n = 1024    # data size\n",
    "X = np.random.normal(0, 1, n) # 每一个点的X值\n",
    "Y = np.random.normal(0, 1, n) # 每一个点的Y值\n",
    "T = np.arctan2(Y,X) # for color value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集生成完毕，现在来用scatterplot这个点集，鼠标点上去，可以看到这个函数的各个parameter的描述。\n",
    "\n",
    "输入X和Y作为location，size=75，颜色为T，color map用默认值，透明度alpha 为 50%。 x轴显示范围定位(-1.5，1.5)，并用xtick()函数来隐藏x坐标轴，y轴同理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, Y, s=75, c=T, alpha=.5)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.xticks(())  # ignore xticks\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.yticks(())  # ignore yticks\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n = 1024    # data size\n",
    "X = np.random.normal(0, 1, n)\n",
    "Y = np.random.normal(0, 1, n)\n",
    "T = np.arctan2(Y, X)    # for color later on\n",
    "\n",
    "plt.scatter(X, Y, s=75, c=T, alpha=.5)\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.xticks(())  # ignore xticks\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.yticks(())  # ignore yticks\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32.2 Bar 柱状图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.2.1 生成基本图形"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向上向下分别生成12个数据，X为 0 到 11 的整数 ，Y是相应的均匀分布的随机数据。 使用的函数是plt.bar，参数为X和Y："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n = 12\n",
    "X = np.arange(n)\n",
    "Y1 = (1 - X / float(n)) * np.random.uniform(0.5, 1.0, n)\n",
    "Y2 = (1 - X / float(n)) * np.random.uniform(0.5, 1.0, n)\n",
    "\n",
    "plt.bar(X, +Y1)\n",
    "plt.bar(X, -Y2)\n",
    "\n",
    "plt.xlim(-.5, n)\n",
    "plt.xticks(())\n",
    "plt.ylim(-1.25, 1.25)\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.2.2 加颜色和数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们就颜色和数值进行优化。 用facecolor设置主体颜色，edgecolor设置边框颜色为白色，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(X, +Y1, facecolor='#9999ff', edgecolor='white')\n",
    "plt.bar(X, -Y2, facecolor='#ff9999', edgecolor='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们用函数plt.text分别在柱体上方（下方）加上数值，用%.2f保留两位小数，横向居中对齐ha='center'，纵向底部（顶部）对齐va='bottom'："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in zip(X, Y1):\n",
    "    # ha: horizontal alignment\n",
    "    # va: vertical alignment\n",
    "    plt.text(x + 0.4, y + 0.05, '%.2f' % y, ha='center', va='bottom')\n",
    "\n",
    "for x, y in zip(X, Y2):\n",
    "    # ha: horizontal alignment\n",
    "    # va: vertical alignment\n",
    "    plt.text(x + 0.4, -y - 0.05, '%.2f' % y, ha='center', va='top')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n = 12\n",
    "X = np.arange(n)\n",
    "Y1 = (1 - X / float(n)) * np.random.uniform(0.5, 1.0, n)\n",
    "Y2 = (1 - X / float(n)) * np.random.uniform(0.5, 1.0, n)\n",
    "\n",
    "plt.bar(X, +Y1, facecolor='#9999ff', edgecolor='white')\n",
    "plt.bar(X, -Y2, facecolor='#ff9999', edgecolor='white')\n",
    "\n",
    "for x, y in zip(X, Y1):\n",
    "    # ha: horizontal alignment\n",
    "    # va: vertical alignment\n",
    "    plt.text(x + 0.4, y + 0.05, '%.2f' % y, ha='center', va='bottom')\n",
    "\n",
    "for x, y in zip(X, Y2):\n",
    "    # ha: horizontal alignment\n",
    "    # va: vertical alignment\n",
    "    plt.text(x + 0.4, -y - 0.05, '%.2f' % y, ha='center', va='top')\n",
    "\n",
    "plt.xlim(-.5, n)\n",
    "plt.xticks(())\n",
    "plt.ylim(-1.25, 1.25)\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32.3 Contours 等高线图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.3.1 画等高线"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集即三维点 (x,y) 和对应的高度值，共有256个点。高度值使用一个 height function f(x,y) 生成。 x, y 分别是在区间 [-3,3] 中均匀分布的256个值，并用meshgrid在二维平面中将每一个x和每一个y分别对应起来，编织成栅格:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f(x,y):\n",
    "    # the height function\n",
    "    return (1 - x / 2 + x**5 + y**3) * np.exp(-x**2 -y**2)\n",
    "\n",
    "n = 256\n",
    "x = np.linspace(-3, 3, n)\n",
    "y = np.linspace(-3, 3, n)\n",
    "X,Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来进行颜色填充。使用函数plt.contourf把颜色加进去，位置参数分别为：X, Y, f(X,Y)。透明度0.75，并将 f(X,Y) 的值对应到color map的暖色组中寻找对应颜色。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plt.contourf to filling contours\n",
    "# X, Y and value for (X,Y) point\n",
    "plt.contourf(X, Y, f(X, Y), 8, alpha=.75, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来进行等高线绘制。使用plt.contour函数划线。位置参数为：X, Y, f(X,Y)。颜色选黑色，线条宽度选0.5。现在的结果如下图所示，只有颜色和线条，还没有数值Label："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use plt.contour to add contour lines\n",
    "C = plt.contour(X, Y, f(X, Y), 8, colors='black', linewidth=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.3.2 添加高度数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，8代表等高线的密集程度，这里被分为10个部分。如果是0，则图像被一分为二。\n",
    "\n",
    "最后加入Label，inline控制是否将Label画在线里面，字体大小为10。并将坐标轴隐藏："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clabel(C, inline=True, fontsize=10)\n",
    "plt.xticks(())\n",
    "plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f(x,y):\n",
    "    # the height function\n",
    "    return (1 - x / 2 + x**5 + y**3) * np.exp(-x**2 -y**2)\n",
    "\n",
    "n = 256\n",
    "x = np.linspace(-3, 3, n)\n",
    "y = np.linspace(-3, 3, n)\n",
    "X,Y = np.meshgrid(x, y)\n",
    "\n",
    "# use plt.contourf to filling contours\n",
    "# X, Y and value for (X,Y) point\n",
    "plt.contourf(X, Y, f(X, Y), 8, alpha=.75, cmap=plt.cm.hot)\n",
    "\n",
    "# use plt.contour to add contour lines\n",
    "C = plt.contour(X, Y, f(X, Y), 8, colors='black', linewidth=.5)\n",
    "# adding label\n",
    "plt.clabel(C, inline=True, fontsize=10)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32.4 Image 图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.4.1 随机矩阵画图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一节我们讲解怎样在matplotlib中打印出图像。这里我们打印出的是纯粹的数字，而非自然图像。 我们今天用这样 3x3 的 2D-array 来表示点的颜色，每一个点就是一个pixel。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "a = np.array([0.313660827978, 0.365348418405, 0.423733120134,\n",
    "              0.365348418405, 0.439599930621, 0.525083754405,\n",
    "              0.423733120134, 0.525083754405, 0.651536351379]).reshape(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三行三列的格子，a代表每一个值，图像右边有一个注释，白色代表值最大的地方，颜色越深值越小。\n",
    "\n",
    "下面我们来看代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a, interpolation='nearest', cmap='bone', origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们之前选cmap的参数时用的是：cmap=plt.cmap.bone，而现在，我们可以直接用单引号传入参数。 origin='lower'代表的就是选择的原点的位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.4.2 出图方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们使用的是内插法中的 Nearest-neighbor 的方法，其他的方式参照官方文档也都可以随意取选。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.4.3 colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们添加一个colorbar ，其中我们添加一个shrink参数，使colorbar的长度变短为原来的92%："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.colorbar(shrink=.92)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# image data\n",
    "a = np.array([0.313660827978, 0.365348418405, 0.423733120134,\n",
    "              0.365348418405, 0.439599930621, 0.525083754405,\n",
    "              0.423733120134, 0.525083754405, 0.651536351379]).reshape(3,3)\n",
    "\n",
    "plt.imshow(a, interpolation='nearest', cmap='bone', origin='lower')\n",
    "plt.colorbar(shrink=.92)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 32.5 3D 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.5.1 3D 图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先在进行 3D Plot 时除了导入 matplotlib ，还要额外添加一个模块，即 Axes 3D 3D 坐标轴显示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之后要先定义一个图像窗口，在窗口上添加3D坐标轴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来给进 X 和 Y 值，并将 X 和 Y 编织成栅格。每一个（X, Y）点对应的高度值我们用下面这个函数来计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y value\n",
    "X = np.arange(-4, 4, 0.25)\n",
    "Y = np.arange(-4, 4, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)    # x-y 平面的网格\n",
    "R = np.sqrt(X ** 2 + Y ** 2)\n",
    "# height value\n",
    "Z = np.sin(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "做出一个三维曲面，并将一个 colormap rainbow 填充颜色，之后将三维图像投影到 XY 平面上做一个等高线图。 plot 3D 图像："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.get_cmap('rainbow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中，rstride 和 cstride 分别代表 row 和 column 的跨度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32.5.2 投影"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面添加 XY 平面的等高线："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.contourf(X, Y, Z, zdir='z', offset=-2, cmap=plt.get_cmap('rainbow'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果 zdir 选择了x，那么效果将会是对于 XZ 平面的投影。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "# X, Y value\n",
    "X = np.arange(-4, 4, 0.25)\n",
    "Y = np.arange(-4, 4, 0.25)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "R = np.sqrt(X ** 2 + Y ** 2)\n",
    "# height value\n",
    "Z = np.sin(R)\n",
    "\n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.get_cmap('rainbow'))\n",
    "# I think this is different from plt12_contours\n",
    "ax.contourf(X, Y, Z, zdir='z', offset=-2, cmap=plt.get_cmap('rainbow'))\n",
    "ax.set_zlim(-2, 2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33.多图合并显示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33.1 Subplot 多合一显示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.1.1 均匀图中图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib 是可以组合许多的小图, 放在一张大图里面显示的. 使用到的方法叫作 subplot.\n",
    "\n",
    "使用import导入matplotlib.pyplot模块, 并简写成plt. 使用plt.figure创建一个图像窗口."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.subplot来创建小图. plt.subplot(2,2,1)表示将整个图像窗口分为2行2列, 当前位置为1. 使用plt.plot([0,1],[0,1])在第1个位置创建一个小图."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,2,1)\n",
    "plt.plot([0,1],[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.subplot(2,2,2)表示将整个图像窗口分为2行2列, 当前位置为2. 使用plt.plot([0,1],[0,2])在第2个位置创建一个小图."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,2,2)\n",
    "plt.plot([0,1],[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.subplot(2,2,3)表示将整个图像窗口分为2行2列,当前位置为3. plt.subplot(2,2,3)可以简写成plt.subplot(223), matplotlib同样可以识别. 使用plt.plot([0,1],[0,3])在第3个位置创建一个小图."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(223)\n",
    "plt.plot([0,1],[0,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.subplot(224)表示将整个图像窗口分为2行2列, 当前位置为4. 使用plt.plot([0,1],[0,4])在第4个位置创建一个小图."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(224)\n",
    "plt.plot([0,1],[0,4])\n",
    "\n",
    "plt.show()  # 展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.1.2 不均匀图中图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果希望展示的小图的大小不相同, 应该怎么做呢? 以上面的4个小图为例, 如果把第1个小图放到第一行, 而剩下的3个小图都放到第二行.\n",
    "\n",
    "使用plt.subplot(2,1,1)将整个图像窗口分为2行1列, 当前位置为1. 使用plt.plot([0,1],[0,1])在第1个位置创建一个小图."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,1,1)\n",
    "plt.plot([0,1],[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.subplot(2,3,4)将整个图像窗口分为2行3列, 当前位置为4. 使用plt.plot([0,1],[0,2])在第4个位置创建一个小图."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2,3,4)\n",
    "plt.plot([0,1],[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里需要解释一下为什么第4个位置放第2个小图. 上一步中使用plt.subplot(2,1,1)将整个图像窗口分为2行1列, 第1个小图占用了第1个位置, 也就是整个第1行. 这一步中使用plt.subplot(2,3,4)将整个图像窗口分为2行3列, 于是整个图像窗口的第1行就变成了3列, 也就是成了3个位置, 于是第2行的第1个位置是整个图像窗口的第4个位置.\n",
    "\n",
    "使用plt.subplot(235)将整个图像窗口分为2行3列,当前位置为5. 使用plt.plot([0,1],[0,3])在第5个位置创建一个小图. 同上, 再创建plt.subplot(236)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(235)\n",
    "plt.plot([0,1],[0,3])\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.plot([0,1],[0,4])\n",
    "\n",
    "plt.show()  # 展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# example 1:\n",
    "###############################\n",
    "plt.figure(figsize=(6, 4))\n",
    "# plt.subplot(n_rows, n_cols, plot_num)\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot([0, 1], [0, 1])\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot([0, 1], [0, 2])\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot([0, 1], [0, 3])\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot([0, 1], [0, 4])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# example 2:\n",
    "###############################\n",
    "plt.figure(figsize=(6, 4))\n",
    "# plt.subplot(n_rows, n_cols, plot_num)\n",
    "plt.subplot(2, 1, 1)\n",
    "# figure splits into 2 rows, 1 col, plot to the 1st sub-fig\n",
    "plt.plot([0, 1], [0, 1])\n",
    "\n",
    "plt.subplot(234)\n",
    "# figure splits into 2 rows, 3 col, plot to the 4th sub-fig\n",
    "plt.plot([0, 1], [0, 2])\n",
    "\n",
    "plt.subplot(235)\n",
    "# figure splits into 2 rows, 3 col, plot to the 5th sub-fig\n",
    "plt.plot([0, 1], [0, 3])\n",
    "\n",
    "plt.subplot(236)\n",
    "# figure splits into 2 rows, 3 col, plot to the 6th sub-fig\n",
    "plt.plot([0, 1], [0, 4])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33.2 Subplot 分格显示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matplotlib 的 subplot 还可以是分格的,这里介绍三种方法."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.2.1 subplot2grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用import导入matplotlib.pyplot模块, 并简写成plt. 使用plt.figure()创建一个图像窗口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.subplot2grid来创建第1个小图, (3,3)表示将整个图像窗口分成3行3列, (0,0)表示从第0行第0列开始作图，colspan=3表示列的跨度为3, rowspan=1表示行的跨度为1. colspan和rowspan缺省, 默认跨度为1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)\n",
    "ax1.plot([1, 2], [1, 2])    # 画小图\n",
    "ax1.set_title('ax1_title')  # 设置小图的标题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.subplot2grid来创建第2个小图, (3,3)表示将整个图像窗口分成3行3列, (1,0)表示从第1行第0列开始作图，colspan=2表示列的跨度为2. 同上画出 ax3, (1,2)表示从第1行第2列开始作图，rowspan=2表示行的跨度为2. 再画一个 ax4 和 ax5, 使用默认 colspan, rowspan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = plt.subplot2grid((3, 3), (1, 0), colspan=2)\n",
    "ax3 = plt.subplot2grid((3, 3), (1, 2), rowspan=2)\n",
    "ax4 = plt.subplot2grid((3, 3), (2, 0))\n",
    "ax5 = plt.subplot2grid((3, 3), (2, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用ax4.scatter创建一个散点图, 使用ax4.set_xlabel和ax4.set_ylabel来对x轴和y轴命名."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax4.scatter([1, 2], [2, 2])\n",
    "ax4.set_xlabel('ax4_x')\n",
    "ax4.set_ylabel('ax4_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.2.2 gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用import导入matplotlib.pyplot模块, 并简写成plt. 使用import导入matplotlib.gridspec, 并简写成gridspec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.figure()创建一个图像窗口, 使用gridspec.GridSpec将整个图像窗口分成3行3列."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "gs = gridspec.GridSpec(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.subplot来作图, gs[0, :]表示这个图占第0行和所有列, gs[1, :2]表示这个图占第1行和第2列前的所有列, gs[1:, 2]表示这个图占第1行后的所有行和第2列, gs[-1, 0]表示这个图占倒数第1行和第0列, gs[-1, -2]表示这个图占倒数第1行和倒数第2列."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax6 = plt.subplot(gs[0, :])\n",
    "ax7 = plt.subplot(gs[1, :2])\n",
    "ax8 = plt.subplot(gs[1:, 2])\n",
    "ax9 = plt.subplot(gs[-1, 0])\n",
    "ax10 = plt.subplot(gs[-1, -2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.2.3 subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用plt.subplots建立一个2行2列的图像窗口，sharex=True表示共享x轴坐标, sharey=True表示共享y轴坐标. ((ax11, ax12), (ax13, ax14))表示第1行从左至右依次放ax11和ax12, 第2行从左至右依次放ax13和ax14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ((ax11, ax12), (ax13, ax14)) = plt.subplots(2, 2, sharex=True, sharey=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用ax11.scatter创建一个散点图."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax11.scatter([1,2], [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.tight_layout()表示紧凑显示图像, plt.show()表示显示图像."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# method 1: subplot2grid\n",
    "##########################\n",
    "plt.figure()\n",
    "ax1 = plt.subplot2grid((3, 3), (0, 0), colspan=3)  # stands for axes\n",
    "ax1.plot([1, 2], [1, 2])\n",
    "ax1.set_title('ax1_title')\n",
    "ax2 = plt.subplot2grid((3, 3), (1, 0), colspan=2)\n",
    "ax3 = plt.subplot2grid((3, 3), (1, 2), rowspan=2)\n",
    "ax4 = plt.subplot2grid((3, 3), (2, 0))\n",
    "ax4.scatter([1, 2], [2, 2])\n",
    "ax4.set_xlabel('ax4_x')\n",
    "ax4.set_ylabel('ax4_y')\n",
    "ax5 = plt.subplot2grid((3, 3), (2, 1))\n",
    "\n",
    "# method 2: gridspec\n",
    "#########################\n",
    "plt.figure()\n",
    "gs = gridspec.GridSpec(3, 3)\n",
    "# use index from 0\n",
    "ax6 = plt.subplot(gs[0, :])\n",
    "ax7 = plt.subplot(gs[1, :2])\n",
    "ax8 = plt.subplot(gs[1:, 2])\n",
    "ax9 = plt.subplot(gs[-1, 0])\n",
    "ax10 = plt.subplot(gs[-1, -2])\n",
    "\n",
    "# method 3: easy to define structure\n",
    "####################################\n",
    "f, ((ax11, ax12), (ax13, ax14)) = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "ax11.scatter([1,2], [1,2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33.3 图中图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3.1 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先是一些准备工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pyplot模块\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 初始化figure\n",
    "fig = plt.figure()\n",
    "\n",
    "# 创建数据\n",
    "x = [1, 2, 3, 4, 5, 6, 7]\n",
    "y = [1, 3, 4, 2, 5, 8, 6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3.2 大图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们来绘制大图。首先确定大图左下角的位置以及宽高："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, bottom, width, height = 0.1, 0.1, 0.8, 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，4个值都是占整个figure坐标系的百分比。在这里，假设figure的大小是10x10，那么大图就被包含在由(1, 1)开始，宽8，高8的坐标系内。\n",
    "\n",
    "将大图坐标系添加到figure中，颜色为r(red)，取名为title："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = fig.add_axes([left, bottom, width, height])\n",
    "ax1.plot(x, y, 'r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.3.3 小图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，我们来绘制左上角的小图，步骤和绘制大图一样，注意坐标系位置和大小的改变："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left, bottom, width, height = 0.2, 0.6, 0.25, 0.25\n",
    "ax2 = fig.add_axes([left, bottom, width, height])\n",
    "ax2.plot(y, x, 'b')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_title('title inside 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们来绘制右下角的小图。这里我们采用一种更简单方法，即直接往plt里添加新的坐标系："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axes([0.6, 0.2, 0.25, 0.25])\n",
    "plt.plot(y[::-1], x, 'g') # 注意对y进行了逆序处理\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('title inside 2')\n",
    "plt.shw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "x = [1, 2, 3, 4, 5, 6, 7]\n",
    "y = [1, 3, 4, 2, 5, 8, 6]\n",
    "\n",
    "# below are all percentage\n",
    "left, bottom, width, height = 0.1, 0.1, 0.8, 0.8\n",
    "ax1 = fig.add_axes([left, bottom, width, height])  # main axes\n",
    "ax1.plot(x, y, 'r')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('title')\n",
    "\n",
    "ax2 = fig.add_axes([0.2, 0.6, 0.25, 0.25])  # inside axes\n",
    "ax2.plot(y, x, 'b')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_title('title inside 1')\n",
    "\n",
    "\n",
    "# different method to add axes\n",
    "####################################\n",
    "plt.axes([0.6, 0.2, 0.25, 0.25])\n",
    "plt.plot(y[::-1], x, 'g')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('title inside 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33.4 次坐标轴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.4.1 第一个y坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有时候我们会用到次坐标轴，即在同个图上有第2个y轴存在。同样可以用matplotlib做到，而且很简单。\n",
    "\n",
    "首先，我们做一些准备工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0, 10, 0.1)\n",
    "\n",
    "y1 = 0.05 * x**2\n",
    "\n",
    "y2 = -1 * y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，y2和y1是互相倒置的。接着，获取figure默认的坐标系 ax1："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 33.4.2 第二个y坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对ax1调用twinx()方法，生成如同镜面效果后的ax2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax2 = ax1.twinx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着进行绘图, 将 y1, y2 分别画在 ax1, ax2 上："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1.plot(x, y1, 'g-')   # green, solid line\n",
    "\n",
    "ax1.set_xlabel('X data')\n",
    "\n",
    "ax1.set_ylabel('Y1 data', color='g')\n",
    "\n",
    "ax2.plot(x, y2, 'b-') # blue\n",
    "\n",
    "ax2.set_ylabel('Y2 data', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0, 10, 0.1)\n",
    "y1 = 0.05 * x**2\n",
    "y2 = -1 *y1\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()    # mirror the ax1\n",
    "ax1.plot(x, y1, 'g-')\n",
    "ax2.plot(x, y2, 'b-')\n",
    "\n",
    "ax1.set_xlabel('X data')\n",
    "ax1.set_ylabel('Y1 data', color='g')\n",
    "ax2.set_ylabel('Y2 data', color='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34.Animation 动画"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34.1 定义方程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用matplotlib做动画也是可以的，我们使用其中一种方式，function animation来说说， 具体可参考matplotlib animation api。首先，我们做一些准备工作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的数据是一个0~2π内的正弦曲线："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 2*np.pi, 0.01)\n",
    "line, = ax.plot(x, np.sin(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着，构造自定义动画函数animate，用来更新每一帧上各个x对应的y坐标值，参数表示第i帧："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate(i):\n",
    "    line.set_ydata(np.sin(x + i/10.0))\n",
    "    return line,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，构造开始帧函数init："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    line.set_ydata(np.sin(x))\n",
    "    return line,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34.2 参数设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们调用FuncAnimation函数生成动画。参数说明： \n",
    "1. fig 进行动画绘制的figure \n",
    "2. func 自定义动画函数，即传入刚定义的函数animate\n",
    "3. frames 动画长度，一次循环包含的帧数 \n",
    "4. init_func 自定义开始帧，即传入刚定义的函数init \n",
    "5. interval 更新频率，以ms计 \n",
    "6. blit 选择更新所有点，还是仅更新产生变化的点。应选择True，但mac用户请选择False，否则无法显示动画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = animation.FuncAnimation(fig=fig,\n",
    "                              func=animate,\n",
    "                              frames=100,\n",
    "                              init_func=init,\n",
    "                              interval=20,\n",
    "                              blit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显示动画："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然，你也可以将动画以mp4格式保存下来，但首先要保证你已经安装了ffmpeg 或者mencoder， 更多信息参考matplotlib animation api："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('basic_animation.mp4', fps=30, extra_args=['-vcodec', 'libx264'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x = np.arange(0, 2*np.pi, 0.01)\n",
    "line, = ax.plot(x, np.sin(x))\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    line.set_ydata(np.sin(x + i/10.0))  # update the data\n",
    "    return line,\n",
    "\n",
    "\n",
    "# Init only required for blitting to give a clean slate.\n",
    "def init():\n",
    "    line.set_ydata(np.sin(x))\n",
    "    return line,\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "# blit=True dose not work on Mac, set blit=False\n",
    "# interval= update frequency\n",
    "ani = animation.FuncAnimation(fig=fig, func=animate, frames=100, init_func=init,\n",
    "                              interval=20, blit=False)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "# anim.save('basic_animation.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五部分：爬虫基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35.爬虫简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为什么要做爬虫教程？（——莫烦老师）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个教程提供了你一次入门的机会, 当然网上还有很多很好的入门教程, 比如:\n",
    "\n",
    " 1. 崔庆才 的Python爬虫学习系列教程\n",
    " 2. 知乎问答中的各种推荐\n",
    " 3. 孔淼 的一看就明白的爬虫入门讲解\n",
    "\n",
    "这些都是非常好的参考资料, 你的学习请不要只限于一个网站. 因为像机器学习一样, 爬虫也囊括的东西绝非不止一点点. 而你为什么要看看我的爬虫教程呢? 因为我只关注基础, 我认为入门是最重要的, 能帮你成功引上路子, 我想你会轻松很多. 而且搭配视频讲解的形式, 也会更加容易理解. 是为初学者定制的. 如果你已经入过门, 想着如何商业化爬虫, 这个教程应该不能满足你的需求了.\n",
    "\n",
    "当我第一次接触爬虫的时候, 其实很陌生, 完全不知道从何开始. 在网上自己搜一些介绍, 但是他们的介绍都太笼统了, 给你丢几个关键词, 让你自己解决. 当时我就懵逼了, 看着那些关键词 (requests, urllib, beautifulsoup, scrapy) 不知道从何下手, 我估计你也会有这种感觉. 当时, 我花了大把的精力, 想弄懂这些东西和爬虫的关系. 而且分清如果只想入门, 我们需要掌握哪些? 毕竟商业化和入门还是有很大不同的. 有些关键词或者模块是为了商业化而用的. 所以我花了很多时间, 整理网上的这些信息. 总结出一条入门爬虫的便捷之路."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这系列教程按照上面的逻辑来教会你爬虫, 我们会从网页的基本结构开始讲述, 慢慢使用一些简单的工具, 做一些简单的爬虫. 还会有一些小练习, 让你爬爬真正的互联网. 下载美图, 逛逛百度百科, 全网爬取等等. 当你懂得了爬虫的概念, 我们在深入一些, 谈谈如何加速你那和蠕虫(爬的慢)一样的爬虫, 把它升级为一只小飞虫(多进程,异步爬取). 当然这些内容都不会特别深入, 重点是把你带入门. 但是我会在每节内容里加一些链接, 提供给想要深入了解的朋友们."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "莫烦python学习爬虫地址：https://www.bilibili.com/video/BV1MW411B7rv?spm_id_from=333.999.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六部分：写在最后的话"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到这里，恭喜你！你的python已经算是正式入门了！有同学就会问，我学校的课程只学了第一部分的内容难道不是入门吗？说实话，那只是让你了解了python的语法，很多实际问题都无法解决。而学到这里，你已经可以解决很多实际问题了，并且在学习python的其他模块的时候也会很快了。最后，希望大家都能够通过编程、通过python来解决你所遇到的问题！后续我将会在知乎、CSDN等平台更新更多知识，欢迎大家关注。\n",
    "<p align=\"right\">——王海诺"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f31b5846fe4d0e510ff280a80fa1fd1567c5c662c3b99a86eb737e0309da4a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
